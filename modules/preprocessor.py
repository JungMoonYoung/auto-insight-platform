"""
Data Preprocessor Module
ë°ì´í„° í´ë Œì§• ë° ì „ì²˜ë¦¬ ê¸°ëŠ¥
"""

import pandas as pd
import numpy as np
from typing import List, Tuple, Optional
from datetime import datetime


class DataPreprocessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ ë° í´ë Œì§•"""
    
    def __init__(self, df: pd.DataFrame):
        """
        Args:
            df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        """
        self.df = df.copy()
        self.original_shape = df.shape
        self.preprocessing_log = []
    
    def handle_missing_values(self, strategy: str = 'auto') -> 'DataPreprocessor':
        """
        ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        
        Args:
            strategy: 'auto', 'drop', 'fill_mean', 'fill_median', 'fill_mode'
        
        Returns:
            self: ì²´ì´ë‹ì„ ìœ„í•œ ìê¸° ìì‹  ë°˜í™˜
        """
        initial_missing = self.df.isnull().sum().sum()
        
        if strategy == 'auto':
            # ê° ì»¬ëŸ¼ë³„ë¡œ ì ì ˆí•œ ì „ëµ ìë™ ì„ íƒ
            for col in self.df.columns:
                missing_pct = self.df[col].isnull().sum() / len(self.df) * 100

                # ê²°ì¸¡ì¹˜ê°€ 100%ì´ë©´ ê±´ë„ˆë›°ê¸°
                if missing_pct == 100:
                    self.preprocessing_log.append(
                        f"âš ï¸  '{col}' ì»¬ëŸ¼ì€ 100% ê²°ì¸¡ì¹˜ì…ë‹ˆë‹¤. ì»¬ëŸ¼ ì‚­ì œë¥¼ ê³ ë ¤í•˜ì„¸ìš”."
                    )
                    continue

                # ê²°ì¸¡ì¹˜ê°€ 50% ì´ìƒì´ë©´ ê²½ê³  ë¡œê·¸
                if missing_pct > 50:
                    self.preprocessing_log.append(
                        f"âš ï¸  '{col}' ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ {missing_pct:.1f}%ë¡œ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤."
                    )

                # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                if self.df[col].isnull().any():
                    if pd.api.types.is_numeric_dtype(self.df[col]):
                        # ìˆ«ìí˜•: ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´
                        median_value = self.df[col].median()
                        if pd.notna(median_value):
                            self.df[col].fillna(median_value, inplace=True)
                    else:
                        # ë²”ì£¼í˜•: ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´
                        mode_value = self.df[col].mode()
                        if len(mode_value) > 0:
                            self.df[col].fillna(mode_value[0], inplace=True)
                        else:
                            self.df[col].fillna('Unknown', inplace=True)
        
        elif strategy == 'drop':
            self.df.dropna(inplace=True)
        
        final_missing = self.df.isnull().sum().sum()
        self.preprocessing_log.append(
            f"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬: {initial_missing}ê°œ â†’ {final_missing}ê°œ"
        )
        
        return self
    
    def remove_duplicates(self) -> 'DataPreprocessor':
        """ì¤‘ë³µ í–‰ ì œê±°"""
        initial_rows = len(self.df)
        self.df.drop_duplicates(inplace=True)
        removed = initial_rows - len(self.df)
        
        if removed > 0:
            self.preprocessing_log.append(f"âœ… ì¤‘ë³µ í–‰ ì œê±°: {removed}ê°œ")
        
        return self
    
    def handle_outliers(self, columns: Optional[List[str]] = None, 
                       method: str = 'IQR', multiplier: float = 1.5) -> 'DataPreprocessor':
        """
        ì´ìƒì¹˜ ì²˜ë¦¬
        
        Args:
            columns: ì²˜ë¦¬í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ìˆ«ìí˜• ì»¬ëŸ¼)
            method: 'IQR' or 'zscore'
            multiplier: IQR ë°©ì‹ì˜ ê²½ìš° ì‚¬ìš©í•  ë°°ìˆ˜
        
        Returns:
            self
        """
        if columns is None:
            columns = self.df.select_dtypes(include=[np.number]).columns.tolist()
        
        for col in columns:
            if col not in self.df.columns or not pd.api.types.is_numeric_dtype(self.df[col]):
                continue
            
            initial_count = len(self.df)
            
            if method == 'IQR':
                Q1 = self.df[col].quantile(0.25)
                Q3 = self.df[col].quantile(0.75)
                IQR = Q3 - Q1

                # IQRì´ 0ì¸ ê²½ìš° (ëª¨ë“  ê°’ì´ ë™ì¼)
                if IQR == 0:
                    self.preprocessing_log.append(
                        f"â„¹ï¸  '{col}' ì»¬ëŸ¼ì˜ IQRì´ 0ì…ë‹ˆë‹¤ (ëª¨ë“  ê°’ì´ ìœ ì‚¬). ì´ìƒì¹˜ ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
                    )
                    continue

                lower_bound = Q1 - multiplier * IQR
                upper_bound = Q3 + multiplier * IQR

                # ì´ìƒì¹˜ í”Œë˜ê¹…
                outliers = (self.df[col] < lower_bound) | (self.df[col] > upper_bound)
                outlier_count = outliers.sum()

                if outlier_count > 0:
                    # Winsorization (ê·¹ë‹¨ê°’ì„ ê²½ê³„ê°’ìœ¼ë¡œ ëŒ€ì²´)
                    self.df.loc[self.df[col] < lower_bound, col] = lower_bound
                    self.df.loc[self.df[col] > upper_bound, col] = upper_bound

                    self.preprocessing_log.append(
                        f"âœ… '{col}' ì´ìƒì¹˜ ì²˜ë¦¬ (IQR): {outlier_count}ê°œ ì¡°ì •"
                    )
            
            elif method == 'zscore':
                z_scores = np.abs((self.df[col] - self.df[col].mean()) / self.df[col].std())
                outliers = z_scores > 3
                outlier_count = outliers.sum()
                
                if outlier_count > 0:
                    # 3 ì‹œê·¸ë§ˆë¥¼ ë²—ì–´ë‚˜ëŠ” ê°’ ì œê±°
                    self.df = self.df[~outliers]
                    
                    self.preprocessing_log.append(
                        f"âœ… '{col}' ì´ìƒì¹˜ ì œê±° (Z-score): {outlier_count}ê°œ"
                    )
        
        return self
    
    def convert_date_columns(self, date_columns: List[str]) -> 'DataPreprocessor':
        """
        ë‚ ì§œ ì»¬ëŸ¼ì„ datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        
        Args:
            date_columns: ë‚ ì§œ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            self
        """
        for col in date_columns:
            if col in self.df.columns:
                try:
                    self.df[col] = pd.to_datetime(self.df[col])
                    self.preprocessing_log.append(f"âœ… '{col}' ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì™„ë£Œ")
                except Exception as e:
                    self.preprocessing_log.append(f"âš ï¸  '{col}' ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
        
        return self
    
    def create_date_features(self, date_column: str) -> 'DataPreprocessor':
        """
        ë‚ ì§œ ì»¬ëŸ¼ìœ¼ë¡œë¶€í„° íŒŒìƒ ë³€ìˆ˜ ìƒì„±
        
        Args:
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
        
        Returns:
            self
        """
        if date_column not in self.df.columns:
            self.preprocessing_log.append(f"âš ï¸  '{date_column}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return self
        
        # datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        if self.df[date_column].dtype != 'datetime64[ns]':
            self.df[date_column] = pd.to_datetime(self.df[date_column])
        
        # íŒŒìƒ ë³€ìˆ˜ ìƒì„±
        self.df[f'{date_column}_year'] = self.df[date_column].dt.year
        self.df[f'{date_column}_month'] = self.df[date_column].dt.month
        self.df[f'{date_column}_day'] = self.df[date_column].dt.day
        self.df[f'{date_column}_dayofweek'] = self.df[date_column].dt.dayofweek
        self.df[f'{date_column}_is_weekend'] = self.df[date_column].dt.dayofweek.isin([5, 6]).astype(int)
        
        # ê³„ì ˆ ì •ë³´
        def get_season(month):
            if month in [3, 4, 5]:
                return 'Spring'
            elif month in [6, 7, 8]:
                return 'Summer'
            elif month in [9, 10, 11]:
                return 'Fall'
            else:
                return 'Winter'
        
        self.df[f'{date_column}_season'] = self.df[f'{date_column}_month'].apply(get_season)
        
        self.preprocessing_log.append(f"âœ… '{date_column}'ì—ì„œ ë‚ ì§œ íŒŒìƒ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ")
        
        return self
    
    def normalize_column_names(self) -> 'DataPreprocessor':
        """ì»¬ëŸ¼ëª… ì •ê·œí™” (ì†Œë¬¸ì ë³€í™˜, ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)"""
        old_columns = self.df.columns.tolist()
        new_columns = [col.strip().lower().replace(' ', '_').replace('-', '_') for col in old_columns]
        self.df.columns = new_columns

        if old_columns != new_columns:
            self.preprocessing_log.append("âœ… ì»¬ëŸ¼ëª… ì •ê·œí™” ì™„ë£Œ (ì†Œë¬¸ì ë³€í™˜)")

        return self
    
    def filter_by_condition(self, condition: str) -> 'DataPreprocessor':
        """
        ì¡°ê±´ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
        
        Args:
            condition: í•„í„°ë§ ì¡°ê±´ (ì˜ˆ: "Quantity > 0")
        
        Returns:
            self
        """
        initial_rows = len(self.df)
        self.df = self.df.query(condition)
        removed = initial_rows - len(self.df)
        
        if removed > 0:
            self.preprocessing_log.append(f"âœ… ì¡°ê±´ í•„í„°ë§ ('{condition}'): {removed}ê°œ í–‰ ì œê±°")
        
        return self
    
    def get_processed_data(self) -> Tuple[pd.DataFrame, List[str]]:
        """
        ì „ì²˜ë¦¬ëœ ë°ì´í„°ì™€ ë¡œê·¸ ë°˜í™˜
        
        Returns:
            (pd.DataFrame, List[str]): (ì „ì²˜ë¦¬ëœ ë°ì´í„°, ë¡œê·¸ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸)
        """
        final_shape = self.df.shape
        summary = f"\nğŸ“Š ì „ì²˜ë¦¬ ìš”ì•½: {self.original_shape} â†’ {final_shape}"
        self.preprocessing_log.append(summary)
        
        return self.df, self.preprocessing_log


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("DataPreprocessor ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_df = pd.DataFrame({
        'CustomerID': [1, 2, 3, None, 5, 1],  # ê²°ì¸¡ì¹˜, ì¤‘ë³µ
        'InvoiceDate': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-01-05', '2024-01-01'],
        'Quantity': [10, 20, None, 15, 1000, 10],  # ê²°ì¸¡ì¹˜, ì´ìƒì¹˜
        'UnitPrice': [100, 200, 300, 400, 500, 100]
    })
    
    print("\nì›ë³¸ ë°ì´í„°:")
    print(sample_df)
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    preprocessor = DataPreprocessor(sample_df)
    processed_df, logs = (preprocessor
                          .normalize_column_names()
                          .handle_missing_values()
                          .remove_duplicates()
                          .handle_outliers(method='IQR')
                          .convert_date_columns(['InvoiceDate'])
                          .create_date_features('InvoiceDate')
                          .get_processed_data())
    
    print("\nì „ì²˜ë¦¬ëœ ë°ì´í„°:")
    print(processed_df)
    
    print("\nì „ì²˜ë¦¬ ë¡œê·¸:")
    for log in logs:
        print(log)
