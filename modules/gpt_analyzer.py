"""
GPT API Analyzer Module
OpenAI GPTë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ í…ìŠ¤íŠ¸ ë¶„ì„
DAY 27: ë¶€ì • ë¦¬ë·° í•„í„°ë§ + Rate Limit í•¸ë“¤ë§ ì¶”ê°€
"""

import pandas as pd
import json
import time
import logging
from typing import Dict, List, Optional
import os

logger = logging.getLogger(__name__)

try:
    import openai
    from openai import RateLimitError, APIError
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("WARNING openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openai")


class GPTAnalyzer:
    """GPTë¥¼ í™œìš©í•œ ê³ ê¸‰ ë¦¬ë·° ë¶„ì„"""

    # Rate Limit ì„¤ì •
    MAX_RETRIES = 5
    INITIAL_DELAY = 1.0  # ì´ˆ
    MAX_DELAY = 60.0  # ìµœëŒ€ 60ì´ˆ
    BATCH_DELAY = 0.5  # ë°°ì¹˜ ê°„ ë”œë ˆì´

    # ëª¨ë¸ë³„ ê°€ê²© (2025ë…„ 1ì›” ê¸°ì¤€, USD per 1M tokens)
    # ì¶œì²˜: https://openai.com/pricing
    PRICING = {
        'gpt-4o-mini': {'input': 0.15, 'output': 0.6},
        'gpt-4o': {'input': 2.50, 'output': 10.0},
        'gpt-4-turbo': {'input': 10.0, 'output': 30.0},
        'gpt-4': {'input': 30.0, 'output': 60.0},
        'gpt-3.5-turbo': {'input': 0.50, 'output': 1.50},
    }

    def __init__(self, api_key: str = None, model: str = "gpt-4o-mini"):
        """
        Args:
            api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
            model: ì‚¬ìš©í•  ëª¨ë¸ (gpt-4o-mini ê¶Œì¥ - ì €ë ´í•˜ê³  ë¹ ë¦„)
        """
        if not OPENAI_AVAILABLE:
            raise ImportError("openai íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”: pip install openai")

        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. api_key íŒŒë¼ë¯¸í„°ë‚˜ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

        self.model = model
        self.client = openai.OpenAI(api_key=self.api_key)
        self.total_tokens = 0
        self.total_cost = 0.0

        # ëª¨ë¸ë³„ ê°€ê²© ì„¤ì •
        if model in self.PRICING:
            self.input_price = self.PRICING[model]['input']
            self.output_price = self.PRICING[model]['output']
            logger.info(f"Model: {model} (${self.input_price}/M input, ${self.output_price}/M output)")
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ì€ gpt-4o-mini ê°€ê²©ìœ¼ë¡œ ê¸°ë³¸ ì„¤ì •
            logger.warning(f"Unknown model '{model}'. Using gpt-4o-mini pricing as fallback.")
            self.input_price = self.PRICING['gpt-4o-mini']['input']
            self.output_price = self.PRICING['gpt-4o-mini']['output']

    def _call_with_retry(self, func, *args, **kwargs):
        """
        Exponential backoffìœ¼ë¡œ API í˜¸ì¶œ ì¬ì‹œë„

        Args:
            func: í˜¸ì¶œí•  í•¨ìˆ˜
            *args, **kwargs: í•¨ìˆ˜ ì¸ì

        Returns:
            API ì‘ë‹µ
        """
        delay = self.INITIAL_DELAY

        for attempt in range(self.MAX_RETRIES):
            try:
                response = func(*args, **kwargs)

                # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
                if hasattr(response, 'usage'):
                    self.total_tokens += response.usage.total_tokens
                    # ëª¨ë¸ë³„ ê°€ê²© ì ìš©
                    input_cost = (response.usage.prompt_tokens / 1_000_000) * self.input_price
                    output_cost = (response.usage.completion_tokens / 1_000_000) * self.output_price
                    self.total_cost += (input_cost + output_cost)

                return response

            except RateLimitError as e:
                if attempt == self.MAX_RETRIES - 1:
                    logger.error(f"Rate Limit ì´ˆê³¼: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬ ({self.MAX_RETRIES})")
                    raise

                logger.warning(f"Rate Limit ë°œìƒ. {delay:.1f}ì´ˆ í›„ ì¬ì‹œë„ ({attempt + 1}/{self.MAX_RETRIES})")
                time.sleep(delay)
                delay = min(delay * 2, self.MAX_DELAY)  # Exponential backoff

            except APIError as e:
                if attempt == self.MAX_RETRIES - 1:
                    logger.error(f"API ì˜¤ë¥˜: {str(e)}")
                    raise

                logger.warning(f"API ì˜¤ë¥˜ ë°œìƒ. {delay:.1f}ì´ˆ í›„ ì¬ì‹œë„: {str(e)}")
                time.sleep(delay)
                delay = min(delay * 2, self.MAX_DELAY)

            except Exception as e:
                logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
                raise

        raise Exception("API í˜¸ì¶œ ì‹¤íŒ¨: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
    
    def _filter_negative_reviews(self, df: pd.DataFrame, rating_column: str = 'rating',
                                  text_column: str = 'review_text', threshold: float = 3.0) -> List[str]:
        """
        ë¶€ì • ë¦¬ë·°ë§Œ í•„í„°ë§ (ë¹„ìš© ì ˆê°)

        Args:
            df: ë¦¬ë·° DataFrame
            rating_column: í‰ì  ì»¬ëŸ¼ëª…
            text_column: ë¦¬ë·° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
            threshold: ë¶€ì • ë¦¬ë·° ê¸°ì¤€ (ì´í•˜)

        Returns:
            ë¶€ì • ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        if rating_column in df.columns:
            negative_df = df[df[rating_column] <= threshold]
            logger.info(f"ë¶€ì • ë¦¬ë·° í•„í„°ë§: {len(negative_df)}/{len(df)} (í‰ì  <={threshold})")
        else:
            logger.warning(f"í‰ì  ì»¬ëŸ¼ '{rating_column}' ì—†ìŒ. ì „ì²´ ë¦¬ë·° ì‚¬ìš©")
            negative_df = df

        if text_column in negative_df.columns:
            return negative_df[text_column].dropna().tolist()
        else:
            logger.error(f"í…ìŠ¤íŠ¸ ì»¬ëŸ¼ '{text_column}' ì—†ìŒ")
            return []

    def analyze_sentiment_batch(self, reviews: List[str], max_reviews: int = 100,
                                filter_negative: bool = False,
                                df: Optional[pd.DataFrame] = None,
                                rating_column: str = 'rating',
                                text_column: str = 'review_text') -> List[Dict]:
        """
        ë¦¬ë·° ê°ì„±ì„ GPTë¡œ ì¬ë¶„ì„ (ë¬¸ë§¥ ì´í•´)

        Args:
            reviews: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            max_reviews: ìµœëŒ€ ë¶„ì„ ê°œìˆ˜ (ë¹„ìš© ì ˆê°)
            filter_negative: ë¶€ì • ë¦¬ë·°ë§Œ ë¶„ì„ (ë¹„ìš© ìµœì í™”, df í•„ìš”)
            df: DataFrame (filter_negative=Trueì¼ ë•Œ í•„ìˆ˜)
            rating_column: í‰ì  ì»¬ëŸ¼ëª… (filter_negative=Trueì¼ ë•Œ ì‚¬ìš©)
            text_column: ë¦¬ë·° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª… (filter_negative=Trueì¼ ë•Œ ì‚¬ìš©)

        Returns:
            ê°ì„± ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸

        Note:
            filter_negative=Trueë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ df íŒŒë¼ë¯¸í„°ì— DataFrameì„ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        logger.info(f"GPT ê°ì„± ë¶„ì„ ì‹œì‘ (ìµœëŒ€ {max_reviews}ê°œ, ë¶€ì • í•„í„°: {filter_negative})")

        # ë¶€ì • ë¦¬ë·° í•„í„°ë§ (df ì œê³µ ì‹œì—ë§Œ)
        if filter_negative:
            if df is not None:
                reviews = self._filter_negative_reviews(
                    df,
                    rating_column=rating_column,
                    text_column=text_column
                )
                logger.info(f"ë¶€ì • ë¦¬ë·° í•„í„°ë§ ì™„ë£Œ: {len(reviews)}ê°œ")
            else:
                logger.warning("filter_negative=True but df is None. Skipping filtering.")

        # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ë¹„ìš© ì¦ê°€)
        if len(reviews) > max_reviews:
            import random
            reviews = random.sample(reviews, max_reviews)
            logger.info(f"ë¦¬ë·° ìƒ˜í”Œë§: {len(reviews)}ê°œ")
        
        results = []

        # ë°°ì¹˜ë¡œ ë¬¶ì–´ì„œ ì²˜ë¦¬ (10ê°œì”©)
        batch_size = 10
        total_batches = (len(reviews) + batch_size - 1) // batch_size

        for i in range(0, len(reviews), batch_size):
            batch = reviews[i:i+batch_size]
            batch_num = i // batch_size + 1

            logger.debug(f"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘...")

            prompt = f"""ë‹¤ìŒ ë¦¬ë·°ë“¤ì˜ ê°ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ê° ë¦¬ë·°ì— ëŒ€í•´ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ë¦¬ë·°ë“¤:
{json.dumps(batch, ensure_ascii=False)}

ê° ë¦¬ë·°ì— ëŒ€í•´ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "results": [
    {{
      "sentiment": "positive" or "neutral" or "negative",
      "confidence": 0.0 ~ 1.0,
      "reason": "ì§§ì€ ì´ìœ  ì„¤ëª…"
    }}
  ]
}}

ë¬¸ë§¥ì„ ì •í™•íˆ ì´í•´í•˜ì„¸ìš”. ì˜ˆ: "ë³„ë¡œ ë‚˜ì˜ì§€ ì•Šë‹¤" = neutral/positive"""

            try:
                # Retry ë˜í¼ë¡œ API í˜¸ì¶œ
                response = self._call_with_retry(
                    self.client.chat.completions.create,
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¦¬ë·° ê°ì„± ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    response_format={"type": "json_object"},
                    temperature=0.3
                )

                batch_results = json.loads(response.choices[0].message.content)
                results.extend(batch_results.get('results', []))

                # ë°°ì¹˜ ê°„ ë”œë ˆì´ (Rate Limit ë°©ì§€)
                if i + batch_size < len(reviews):
                    time.sleep(self.BATCH_DELAY)
                
            except (json.JSONDecodeError, KeyError) as e:
                logger.error(f"GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ (ë°°ì¹˜ {batch_num}/{total_batches}): {str(e)}")
                # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’
                results.extend([{"sentiment": "neutral", "confidence": 0.5, "reason": "ë¶„ì„ ì‹¤íŒ¨"}] * len(batch))
            except Exception as e:
                logger.error(f"GPT ë¶„ì„ ì˜¤ë¥˜ (ë°°ì¹˜ {batch_num}/{total_batches}): {str(e)}")
                # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’
                results.extend([{"sentiment": "neutral", "confidence": 0.5, "reason": "ë¶„ì„ ì‹¤íŒ¨"}] * len(batch))

        logger.info(f"ê°ì„± ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ë¦¬ë·°, ë¹„ìš©: ${self.total_cost:.4f}, í† í°: {self.total_tokens}")
        return results

    def get_cost_info(self) -> Dict[str, float]:
        """
        API ì‚¬ìš© ë¹„ìš© ì •ë³´ ë°˜í™˜

        Returns:
            {'total_tokens': int, 'total_cost': float}
        """
        return {
            'total_tokens': self.total_tokens,
            'total_cost': round(self.total_cost, 4)
        }

    def reset_cost_tracking(self):
        """ë¹„ìš© ì¶”ì  ì´ˆê¸°í™”"""
        self.total_tokens = 0
        self.total_cost = 0.0
        logger.info("ë¹„ìš© ì¶”ì  ì´ˆê¸°í™”ë¨")
    
    def generate_summary(self, reviews: List[str], max_reviews: int = 50) -> str:
        """
        ë¦¬ë·° ì „ì²´ë¥¼ 3-5ì¤„ë¡œ ìš”ì•½
        
        Args:
            reviews: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            max_reviews: ìµœëŒ€ ë¶„ì„ ê°œìˆ˜
        
        Returns:
            ìš”ì•½ í…ìŠ¤íŠ¸
        """
        # Generating summary with GPT
        
        if len(reviews) > max_reviews:
            import random
            reviews = random.sample(reviews, max_reviews)
        
        reviews_text = "\n".join([f"- {r}" for r in reviews[:50]])
        
        prompt = f"""ë‹¤ìŒ ë¦¬ë·°ë“¤ì„ 3-5ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì£¼ì„¸ìš”:

{reviews_text}

ìš”ì•½ ì‹œ í¬í•¨í•  ë‚´ìš©:
1. ê³ ê°ë“¤ì˜ ì „ë°˜ì ì¸ ë§Œì¡±ë„
2. ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ì¥ì 
3. ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ë‹¨ì 
4. íŠ¹ì´ì‚¬í•­ì´ë‚˜ íŠ¸ë Œë“œ

ê°„ê²°í•˜ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=500
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"GPT ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    def detect_issues(self, reviews: List[str], max_reviews: int = 50) -> Dict:
        """
        ì£¼ìš” ì´ìŠˆ ìë™ ê°ì§€
        
        Args:
            reviews: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            max_reviews: ìµœëŒ€ ë¶„ì„ ê°œìˆ˜
        
        Returns:
            ì´ìŠˆ ë”•ì…”ë„ˆë¦¬
        """
        # Detecting issues with GPT
        
        if len(reviews) > max_reviews:
            import random
            reviews = random.sample(reviews, max_reviews)
        
        reviews_text = "\n".join([f"- {r}" for r in reviews[:50]])
        
        prompt = f"""ë‹¤ìŒ ë¦¬ë·°ë“¤ì—ì„œ ì£¼ìš” ì´ìŠˆë‚˜ ë¬¸ì œì ì„ ì°¾ì•„ì£¼ì„¸ìš”:

{reviews_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "critical_issues": [
    {{
      "issue": "ì´ìŠˆ ì œëª©",
      "severity": "high" or "medium" or "low",
      "description": "ìƒì„¸ ì„¤ëª…",
      "affected_count": "ëŒ€ëµì ì¸ ì˜í–¥ ë°›ì€ ê³ ê° ìˆ˜"
    }}
  ],
  "positive_highlights": [
    "ê¸ì •ì ì¸ íŠ¹ì§• 1",
    "ê¸ì •ì ì¸ íŠ¹ì§• 2"
  ],
  "recommendations": [
    "ê°œì„  ì œì•ˆ 1",
    "ê°œì„  ì œì•ˆ 2"
  ]
}}"""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê³ ê° í”¼ë“œë°± ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=1000
            )

            return json.loads(response.choices[0].message.content)

        except Exception as e:
            logger.error(f"GPT issues detection error: {str(e)}")
            return {
                "critical_issues": [],
                "positive_highlights": [],
                "recommendations": []
            }
    
    def categorize_reviews(self, reviews: List[str], max_reviews: int = 50) -> Dict:
        """
        ë¦¬ë·°ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìë™ ë¶„ë¥˜
        
        Args:
            reviews: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            max_reviews: ìµœëŒ€ ë¶„ì„ ê°œìˆ˜
        
        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ê²°ê³¼
        """
        # Categorizing reviews with GPT
        
        if len(reviews) > max_reviews:
            import random
            reviews = random.sample(reviews, max_reviews)
        
        reviews_text = "\n".join([f"- {r}" for r in reviews[:50]])
        
        prompt = f"""ë‹¤ìŒ ë¦¬ë·°ë“¤ì„ ì£¼ì œë³„ë¡œ ë¶„ë¥˜í•˜ê³ , ê° ì¹´í…Œê³ ë¦¬ë³„ ë¹„ìœ¨ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”:

{reviews_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{
  "categories": {{
    "ì œí’ˆí’ˆì§ˆ": {{"percentage": 45, "keywords": ["ì¢‹ë‹¤", "í›Œë¥­"]}},
    "ë°°ì†¡": {{"percentage": 30, "keywords": ["ë¹ ë¥´ë‹¤", "ëŠ¦ë‹¤"]}},
    "ê³ ê°ì„œë¹„ìŠ¤": {{"percentage": 15, "keywords": [...]}},
    "ê°€ê²©": {{"percentage": 10, "keywords": [...]}}
  }}
}}

ì£¼ìš” ì¹´í…Œê³ ë¦¬: ì œí’ˆí’ˆì§ˆ, ë°°ì†¡, ê³ ê°ì„œë¹„ìŠ¤, ê°€ê²©, í¬ì¥, ê¸°íƒ€"""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¦¬ë·° ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3,
                max_tokens=800
            )

            return json.loads(response.choices[0].message.content)

        except Exception as e:
            logger.error(f"GPT categorization error: {str(e)}")
            return {"categories": {}}
    
    def generate_advanced_insights(self, reviews: List[str], 
                                   sentiment_summary: Dict,
                                   max_reviews: int = 50) -> str:
        """
        ê³ ê¸‰ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        
        Args:
            reviews: ë¦¬ë·° í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            sentiment_summary: ê¸°ë³¸ ê°ì„± ë¶„ì„ ê²°ê³¼
            max_reviews: ìµœëŒ€ ë¶„ì„ ê°œìˆ˜
        
        Returns:
            ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸
        """
        # Generating advanced insights with GPT
        
        if len(reviews) > max_reviews:
            import random
            reviews = random.sample(reviews, max_reviews)
        
        reviews_text = "\n".join([f"- {r}" for r in reviews[:30]])
        
        prompt = f"""ë‹¤ìŒ ë¦¬ë·°ë“¤ê³¼ í†µê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

í†µê³„:
- ì „ì²´ ë¦¬ë·°: {sentiment_summary.get('total_reviews', 0)}ê°œ
- ê¸ì •: {sentiment_summary.get('positive_ratio', 0):.1f}%
- ë¶€ì •: {sentiment_summary.get('negative_ratio', 0):.1f}%

ìƒ˜í”Œ ë¦¬ë·°:
{reviews_text}

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ê°€ì¥ ì‹œê¸‰í•œ ê°œì„  í¬ì¸íŠ¸ (ìš°ì„ ìˆœìœ„ë³„)
2. ê²½ìŸ ìš°ìœ„ ìš”ì†Œ
3. ê³ ê° ë§Œì¡±ë„ í–¥ìƒ ì „ëµ
4. ì˜ˆìƒë˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥

ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì œì•ˆì„ í•´ì£¼ì„¸ìš”."""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.error(f"GPT ì¸ì‚¬ì´íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return "ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

    # ===== E-commerce RFM ë¶„ì„ ë©”ì„œë“œ =====

    def analyze_rfm_insights(self, rfm_df: pd.DataFrame, cluster_summary: pd.DataFrame) -> str:
        """
        RFM ë¶„ì„ ê²°ê³¼ë¥¼ GPTë¡œ í•´ì„

        Args:
            rfm_df: RFM ë°ì´í„°í”„ë ˆì„
            cluster_summary: êµ°ì§‘ ìš”ì•½ ë°ì´í„°

        Returns:
            str: GPTì˜ RFM ë¶„ì„ í•´ì„
        """
        print("ğŸ¤– GPTë¡œ RFM ë¶„ì„ í•´ì„ ì¤‘...")

        # ë°ì´í„° ìš”ì•½
        total_customers = len(rfm_df)
        total_revenue = cluster_summary['Monetary_ì´í•©'].sum()
        avg_recency = rfm_df['Recency'].mean()
        avg_frequency = rfm_df['Frequency'].mean()
        avg_monetary = rfm_df['Monetary'].mean()

        # êµ°ì§‘ë³„ ì •ë³´
        cluster_info = []
        for _, row in cluster_summary.iterrows():
            cluster_info.append({
                'ì„¸ê·¸ë¨¼íŠ¸': row['cluster_name'],
                'ê³ ê°ìˆ˜': int(row['ê³ ê° ìˆ˜']),
                'ë¹„ìœ¨': f"{row['ê³ ê° ë¹„ìœ¨(%)']}%",
                'í‰ê· _Recency': round(row['Recency_í‰ê· '], 1),
                'í‰ê· _Frequency': round(row['Frequency_í‰ê· '], 1),
                'í‰ê· _Monetary': round(row['Monetary_í‰ê· '], 0),
                'ì´ë§¤ì¶œ': round(row['Monetary_ì´í•©'], 0)
            })

        prompt = f"""ë‹¤ìŒì€ E-commerce ê³ ê° RFM ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì „ë¬¸ê°€ ê´€ì ì—ì„œ í•´ì„í•´ì£¼ì„¸ìš”.

**ì „ì²´ í†µê³„:**
- ì´ ê³ ê° ìˆ˜: {total_customers:,}ëª…
- ì´ ë§¤ì¶œ: â‚©{total_revenue:,.0f}
- í‰ê·  Recency: {avg_recency:.1f}ì¼ (ë§ˆì§€ë§‰ êµ¬ë§¤ í›„ ê²½ê³¼ ì¼ìˆ˜)
- í‰ê·  Frequency: {avg_frequency:.1f}íšŒ
- í‰ê·  Monetary: â‚©{avg_monetary:,.0f}

**êµ°ì§‘ë³„ ìƒì„¸ ì •ë³´:**
{json.dumps(cluster_info, ensure_ascii=False, indent=2)}

**ìš”ì²­ì‚¬í•­:**
1. ì „ì²´ì ì¸ ê³ ê° í¬íŠ¸í´ë¦¬ì˜¤ ê±´ê°•ë„ í‰ê°€
2. ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ íŠ¹ì§• ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸
3. ì£¼ëª©í•´ì•¼ í•  ìœ„í—˜ ì‹ í˜¸ ë˜ëŠ” ê¸°íšŒ
4. ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ì„¸ê·¸ë¨¼íŠ¸ì™€ ê·¸ ì´ìœ 
5. ë°ì´í„°ì—ì„œ ë°œê²¬ë˜ëŠ” íŠ¹ì´ì‚¬í•­

í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. êµ¬ì²´ì ì¸ ìˆ«ìë¥¼ ì¸ìš©í•˜ì„¸ìš”."""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ E-commerce ë°ì´í„° ë¶„ì„ ë° CRM ì „ëµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"GPT RFM í•´ì„ ì˜¤ë¥˜: {str(e)}")
            return f"ë¶„ì„ í•´ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def generate_segment_strategy(self, cluster_summary: pd.DataFrame) -> str:
        """
        ê° ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ

        Args:
            cluster_summary: êµ°ì§‘ ìš”ì•½ ë°ì´í„°

        Returns:
            str: ì„¸ê·¸ë¨¼íŠ¸ë³„ ì „ëµ ì œì•ˆ
        """
        print("ğŸ¤– GPTë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì „ëµ ìƒì„± ì¤‘...")

        # êµ°ì§‘ë³„ ì •ë³´
        cluster_info = []
        for _, row in cluster_summary.iterrows():
            cluster_info.append({
                'ì„¸ê·¸ë¨¼íŠ¸': row['cluster_name'],
                'ê³ ê°ìˆ˜': int(row['ê³ ê° ìˆ˜']),
                'ë¹„ìœ¨': f"{row['ê³ ê° ë¹„ìœ¨(%)']}%",
                'í‰ê· _Recency': round(row['Recency_í‰ê· '], 1),
                'í‰ê· _Frequency': round(row['Frequency_í‰ê· '], 1),
                'í‰ê· _Monetary': round(row['Monetary_í‰ê· '], 0),
                'ì´ë§¤ì¶œê¸°ì—¬ë„': round(row['Monetary_ì´í•©'] / cluster_summary['Monetary_ì´í•©'].sum() * 100, 1)
            })

        prompt = f"""ë‹¤ìŒ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ… ì „ëµì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

**ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´:**
{json.dumps(cluster_info, ensure_ascii=False, indent=2)}

**ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”:**
1. **ëª©í‘œ**: ì´ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ í•µì‹¬ ëª©í‘œ (ì˜ˆ: ì¬êµ¬ë§¤ ìœ ë„, ì¶©ì„±ë„ ê°•í™”, ì¬í™œì„±í™” ë“±)
2. **ì¶”ì²œ ì•¡ì…˜**: êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ… ì•¡ì…˜ 3-5ê°œ (ì˜ˆ: ì¿ í°, ì´ë©”ì¼, VIP í”„ë¡œê·¸ë¨ ë“±)
3. **ë©”ì‹œì§€ í†¤**: ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ë°©ì‹ ë° ë©”ì‹œì§€ ì˜ˆì‹œ
4. **ì˜ˆìƒ íš¨ê³¼**: ì´ ì „ëµì˜ ê¸°ëŒ€ íš¨ê³¼
5. **ì˜ˆì‚° ìš°ì„ ìˆœìœ„**: High/Medium/Low

ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”. í•œêµ­ E-commerce ì‹œì¥ íŠ¹ì„±ì„ ê³ ë ¤í•˜ì„¸ìš”."""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ E-commerce ë§ˆì¼€íŒ… ì „ëµ ë° CRM ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"GPT ì „ëµ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì „ëµ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def simulate_revenue_growth(self, rfm_df: pd.DataFrame, cluster_summary: pd.DataFrame) -> str:
        """
        ì‹œë‚˜ë¦¬ì˜¤ë³„ ë§¤ì¶œ ì„±ì¥ ì‹œë®¬ë ˆì´ì…˜

        Args:
            rfm_df: RFM ë°ì´í„°í”„ë ˆì„
            cluster_summary: êµ°ì§‘ ìš”ì•½ ë°ì´í„°

        Returns:
            str: ë§¤ì¶œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        """
        print("ğŸ¤– GPTë¡œ ë§¤ì¶œ ì‹œë®¬ë ˆì´ì…˜ ì¤‘...")

        # í˜„ì¬ ìƒíƒœ
        current_revenue = cluster_summary['Monetary_ì´í•©'].sum()
        total_customers = len(rfm_df)

        # êµ°ì§‘ë³„ ì •ë³´
        cluster_info = []
        for _, row in cluster_summary.iterrows():
            cluster_info.append({
                'ì„¸ê·¸ë¨¼íŠ¸': row['cluster_name'],
                'ê³ ê°ìˆ˜': int(row['ê³ ê° ìˆ˜']),
                'í‰ê· _êµ¬ë§¤ì•¡': round(row['Monetary_í‰ê· '], 0),
                'í‰ê· _êµ¬ë§¤ë¹ˆë„': round(row['Frequency_í‰ê· '], 1),
                'ì´ë§¤ì¶œ': round(row['Monetary_ì´í•©'], 0),
                'ë§¤ì¶œê¸°ì—¬ë„': round(row['Monetary_ì´í•©'] / current_revenue * 100, 1)
            })

        prompt = f"""ë‹¤ìŒ RFM ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ë³„ ë§¤ì¶œ ì„±ì¥ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ì„¸ìš”.

**í˜„ì¬ ìƒíƒœ:**
- ì´ ê³ ê°: {total_customers:,}ëª…
- í˜„ì¬ ì´ë§¤ì¶œ: â‚©{current_revenue:,.0f}

**ì„¸ê·¸ë¨¼íŠ¸ë³„ í˜„í™©:**
{json.dumps(cluster_info, ensure_ascii=False, indent=2)}

**ì‹œë®¬ë ˆì´ì…˜ ì‹œë‚˜ë¦¬ì˜¤:**

1. **ë³´ìˆ˜ì  ì‹œë‚˜ë¦¬ì˜¤** (í˜„ì‹¤ì , ë‹¬ì„± ê°€ëŠ¥ì„± ë†’ìŒ):
   - VIP/ì¶©ì„± ê³ ê°: êµ¬ë§¤ ë¹ˆë„ +10% ì¦ê°€
   - ì´íƒˆ ìœ„í—˜ ê³ ê°: 30% ì¬í™œì„±í™”
   - ì‹ ê·œ ê³ ê°: 20% ì¬êµ¬ë§¤ ì „í™˜

2. **ì¤‘ë¦½ì  ì‹œë‚˜ë¦¬ì˜¤** (ì¼ë°˜ì ì¸ ë§ˆì¼€íŒ… ì„±ê³¼):
   - VIP/ì¶©ì„± ê³ ê°: êµ¬ë§¤ ë¹ˆë„ +20%, êµ¬ë§¤ì•¡ +15% ì¦ê°€
   - ì´íƒˆ ìœ„í—˜ ê³ ê°: 50% ì¬í™œì„±í™”
   - ì‹ ê·œ ê³ ê°: 40% ì¬êµ¬ë§¤ ì „í™˜
   - íœ´ë©´ ê³ ê°: 10% ì¬í™œì„±í™”

3. **ë‚™ê´€ì  ì‹œë‚˜ë¦¬ì˜¤** (ê³µê²©ì  ë§ˆì¼€íŒ… + ë†’ì€ íˆ¬ì):
   - VIP/ì¶©ì„± ê³ ê°: êµ¬ë§¤ ë¹ˆë„ +30%, êµ¬ë§¤ì•¡ +25% ì¦ê°€
   - ì´íƒˆ ìœ„í—˜ ê³ ê°: 70% ì¬í™œì„±í™”
   - ì‹ ê·œ ê³ ê°: 60% ì¬êµ¬ë§¤ ì „í™˜, êµ¬ë§¤ì•¡ +20%
   - íœ´ë©´ ê³ ê°: 25% ì¬í™œì„±í™”

**ìš”ì²­ì‚¬í•­:**
ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ:
1. ì˜ˆìƒ ì´ë§¤ì¶œ (êµ¬ì²´ì  ê¸ˆì•¡)
2. ë§¤ì¶œ ì¦ê°€ìœ¨ (%)
3. ì„¸ê·¸ë¨¼íŠ¸ë³„ ê¸°ì—¬ë„ ë³€í™”
4. ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ í•µì‹¬ ì¡°ê±´
5. í•„ìš”í•œ ì˜ˆìƒ ë§ˆì¼€íŒ… ë¹„ìš© (ë§¤ì¶œ ëŒ€ë¹„ %)

ê³„ì‚° ê³¼ì •ì„ ëª…í™•íˆ ë³´ì—¬ì£¼ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”."""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ ì „ëµ ë° ì¬ë¬´ ì‹œë®¬ë ˆì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"GPT ë§¤ì¶œ ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}")
            return f"ë§¤ì¶œ ì‹œë®¬ë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def analyze_portfolio_risk(self, rfm_df: pd.DataFrame, cluster_summary: pd.DataFrame) -> str:
        """
        ê³ ê° í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ë¶„ì„

        Args:
            rfm_df: RFM ë°ì´í„°í”„ë ˆì„
            cluster_summary: êµ°ì§‘ ìš”ì•½ ë°ì´í„°

        Returns:
            str: ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼
        """
        print("ğŸ¤– GPTë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ ë¶„ì„ ì¤‘...")

        # ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
        total_revenue = cluster_summary['Monetary_ì´í•©'].sum()
        total_customers = len(rfm_df)

        # ìƒìœ„ 20% ê³ ê° ë§¤ì¶œ ì§‘ì¤‘ë„ (íŒŒë ˆí†  ë²•ì¹™)
        rfm_sorted = rfm_df.sort_values('Monetary', ascending=False)
        top_20_pct_customers = int(len(rfm_sorted) * 0.2)
        top_20_revenue = rfm_sorted.head(top_20_pct_customers)['Monetary'].sum()
        concentration_ratio = (top_20_revenue / total_revenue * 100) if total_revenue > 0 else 0

        # ì´íƒˆ ìœ„í—˜ ê³ ê° ë¹„ìœ¨
        churn_segments = cluster_summary[cluster_summary['cluster_name'].str.contains('ì´íƒˆ|íœ´ë©´', na=False)]
        churn_customers = churn_segments['ê³ ê° ìˆ˜'].sum() if not churn_segments.empty else 0
        churn_ratio = (churn_customers / total_customers * 100) if total_customers > 0 else 0
        churn_revenue = churn_segments['Monetary_ì´í•©'].sum() if not churn_segments.empty else 0

        # ì‹ ê·œ ê³ ê° ë¹„ìœ¨
        new_segments = cluster_summary[cluster_summary['cluster_name'].str.contains('ì‹ ê·œ', na=False)]
        new_customers = new_segments['ê³ ê° ìˆ˜'].sum() if not new_segments.empty else 0
        new_ratio = (new_customers / total_customers * 100) if total_customers > 0 else 0

        # í‰ê·  recency
        avg_recency = rfm_df['Recency'].mean()

        # êµ°ì§‘ë³„ ì •ë³´
        cluster_info = []
        for _, row in cluster_summary.iterrows():
            cluster_info.append({
                'ì„¸ê·¸ë¨¼íŠ¸': row['cluster_name'],
                'ê³ ê°ìˆ˜': int(row['ê³ ê° ìˆ˜']),
                'ë¹„ìœ¨': f"{row['ê³ ê° ë¹„ìœ¨(%)']}%",
                'ë§¤ì¶œê¸°ì—¬ë„': round(row['Monetary_ì´í•©'] / total_revenue * 100, 1),
                'í‰ê· _Recency': round(row['Recency_í‰ê· '], 1)
            })

        prompt = f"""ë‹¤ìŒ E-commerce ê³ ê° í¬íŠ¸í´ë¦¬ì˜¤ì˜ ë¦¬ìŠ¤í¬ë¥¼ ë¶„ì„í•˜ê³  ê²½ê³  ì‹ í˜¸ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

**ì „ì²´ ì§€í‘œ:**
- ì´ ê³ ê°: {total_customers:,}ëª…
- ì´ ë§¤ì¶œ: â‚©{total_revenue:,.0f}
- ìƒìœ„ 20% ê³ ê° ë§¤ì¶œ ì§‘ì¤‘ë„: {concentration_ratio:.1f}%
- ì´íƒˆ ìœ„í—˜/íœ´ë©´ ê³ ê° ë¹„ìœ¨: {churn_ratio:.1f}% ({churn_customers}ëª…, ë§¤ì¶œ â‚©{churn_revenue:,.0f})
- ì‹ ê·œ ê³ ê° ë¹„ìœ¨: {new_ratio:.1f}%
- í‰ê·  ë§ˆì§€ë§‰ êµ¬ë§¤ í›„ ê²½ê³¼ì¼: {avg_recency:.1f}ì¼

**ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶„í¬:**
{json.dumps(cluster_info, ensure_ascii=False, indent=2)}

**ìš”ì²­ì‚¬í•­:**
1. **ì£¼ìš” ë¦¬ìŠ¤í¬ ìš”ì¸ (3-5ê°œ)**: í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì·¨ì•½ì 
2. **ë¦¬ìŠ¤í¬ ìš°ì„ ìˆœìœ„**: High/Medium/Lowë¡œ ë¶„ë¥˜í•˜ê³  ì´ìœ  ì„¤ëª…
3. **ê²½ê³  ì‹ í˜¸**: ì¦‰ì‹œ ëŒ€ì‘ì´ í•„ìš”í•œ ì§€í‘œ
4. **ì¬ë¬´ì  ì˜í–¥**: ê° ë¦¬ìŠ¤í¬ê°€ ë§¤ì¶œì— ë¯¸ì¹  ìˆ˜ ìˆëŠ” ì˜í–¥ (ê¸ˆì•¡ ì¶”ì •)
5. **ë¦¬ìŠ¤í¬ ì™„í™” ì „ëµ**: êµ¬ì²´ì ì¸ ëŒ€ì‘ ë°©ì•ˆ 3-5ê°œ
6. **ëª¨ë‹ˆí„°ë§ ì§€í‘œ**: ì •ê¸°ì ìœ¼ë¡œ ì¶”ì í•´ì•¼ í•  KPI

ë¹„ì¦ˆë‹ˆìŠ¤ ì—°ì†ì„±ê³¼ ì„±ì¥ ê°€ëŠ¥ì„± ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”."""

        try:
            response = self._call_with_retry(
                self.client.chat.completions.create,
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ E-commerce ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë° ì¬ë¬´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4
            )

            return response.choices[0].message.content

        except Exception as e:
            logger.error(f"GPT ë¦¬ìŠ¤í¬ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
            return f"ë¦¬ìŠ¤í¬ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}"


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("GPT Analyzer ëª¨ë“ˆ")
    print("ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    print("ì‚¬ìš©ë²•:")
    print("""
    from modules.gpt_analyzer import GPTAnalyzer
    
    analyzer = GPTAnalyzer(api_key="your-api-key")
    
    # ë¦¬ë·° ìš”ì•½
    summary = analyzer.generate_summary(reviews)
    
    # ì´ìŠˆ ê°ì§€
    issues = analyzer.detect_issues(reviews)
    
    # ê³ ê¸‰ ì¸ì‚¬ì´íŠ¸
    insights = analyzer.generate_advanced_insights(reviews, sentiment_summary)
    """)
