"""
Auto-Insight Platform - Multi-Page Version
AI ê¸°ë°˜ ìë™ ë°ì´í„° ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ

DAY 20: ë©€í‹° í˜ì´ì§€ êµ¬ì¡°ë¡œ ì „í™˜ (4ê°œ í˜ì´ì§€)
"""

import streamlit as st
import pandas as pd
import yaml
from pathlib import Path
import os
from dotenv import load_dotenv

# ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
from utils.session_manager import SessionManager
from utils.environment import Environment

# ëª¨ë“ˆ
from modules.data_loader import DataLoader
from modules.preprocessor import DataPreprocessor
from modules.rfm_analyzer import RFMAnalyzer
from modules.text_analyzer import TextAnalyzer
from modules.visualizer import Visualizer
from modules.report_generator import HTMLReportGenerator
from modules.insight_generator import InsightGenerator

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Auto-Insight Platform",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== CSS ìŠ¤íƒ€ì¼ ====================
def load_custom_css():
    """ì»¤ìŠ¤í…€ CSS ë¡œë“œ"""
    st.markdown("""
    <style>
        /* ë©”ì¸ ë°°ê²½ - ë‹¤í¬ */
        .main {
            background: #0a0e27;
            background-image:
                radial-gradient(at 47% 33%, hsl(240, 70%, 15%) 0, transparent 59%),
                radial-gradient(at 82% 65%, hsl(260, 50%, 20%) 0, transparent 55%);
            background-attachment: fixed;
        }

        /* ì»¨í…ì¸  ì˜ì—­ */
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
            background: rgba(20, 25, 45, 0.95);
            border-radius: 20px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.5);
            margin: 20px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        /* ì œëª© ìŠ¤íƒ€ì¼ */
        h1 {
            background: linear-gradient(135deg, #00f2fe 0%, #4facfe 50%, #f093fb 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 800;
            font-size: 3em !important;
            text-align: center;
            margin-bottom: 1rem;
        }

        h2 {
            color: #00f2fe;
            font-weight: 700;
            border-left: 5px solid #00f2fe;
            padding-left: 15px;
            margin-top: 2rem;
        }

        /* í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
        p, label, .stMarkdown {
            color: rgba(255, 255, 255, 0.9) !important;
        }

        /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        .stButton>button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-weight: 600;
            border: none;
            border-radius: 10px;
            padding: 0.75rem 1.5rem;
            transition: all 0.3s ease;
        }

        .stButton>button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);
        }

        /* íƒ­ ìŠ¤íƒ€ì¼ */
        .stTabs [data-baseweb="tab-list"] {
            gap: 8px;
        }

        .stTabs [data-baseweb="tab"] {
            background-color: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
            color: rgba(255, 255, 255, 0.7);
            font-weight: 600;
        }

        .stTabs [aria-selected="true"] {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
    </style>
    """, unsafe_allow_html=True)


# ==================== í˜ì´ì§€ í•¨ìˆ˜ë“¤ ====================

def page_start():
    """í˜ì´ì§€ 1: ì‹œì‘í•˜ê¸° (ë°ì´í„° ì—…ë¡œë“œ & í¬ë¡¤ë§)"""
    st.title("ğŸ  ì‹œì‘í•˜ê¸°")
    st.markdown("### ë¶„ì„í•  ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”")

    # íƒ­ ìƒì„±
    tabs = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸŒ ì›¹ í¬ë¡¤ë§", "ğŸ“¦ ìƒ˜í”Œ ë°ì´í„°"])

    # Tab 1: íŒŒì¼ ì—…ë¡œë“œ
    with tabs[0]:
        render_file_upload()

    # Tab 2: ì›¹ í¬ë¡¤ë§
    with tabs[1]:
        render_crawling_ui()

    # Tab 3: ìƒ˜í”Œ ë°ì´í„°
    with tabs[2]:
        render_sample_data()

    # í•˜ë‹¨: ë°ì´í„° ì •ë³´ í‘œì‹œ
    if SessionManager.has_data():
        st.markdown("---")
        show_data_info()


def render_file_upload():
    """íŒŒì¼ ì—…ë¡œë“œ UI"""
    st.markdown("#### ğŸ“ CSV ë˜ëŠ” Excel íŒŒì¼ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=['csv', 'xlsx', 'xls'],
        key="file_uploader"
    )

    if uploaded_file is not None:
        try:
            with st.spinner("ğŸ“‚ íŒŒì¼ì„ ì½ëŠ” ì¤‘..."):
                # íŒŒì¼ ë¡œë“œ (Streamlit UploadedFile ê°ì²´ëŠ” pandasë¡œ ì§ì ‘ ì½ê¸°)
                if uploaded_file.name.endswith('.csv'):
                    # CSV íŒŒì¼: ì¸ì½”ë”© ìë™ ê°ì§€
                    try:
                        df = pd.read_csv(uploaded_file, encoding='utf-8')
                    except UnicodeDecodeError:
                        uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                        df = pd.read_csv(uploaded_file, encoding='cp949')
                else:
                    # Excel íŒŒì¼
                    df = pd.read_excel(uploaded_file)

                # ì„¸ì…˜ì— ì €ì¥
                SessionManager.save_data(
                    data=df,
                    source='upload',
                    file_name=uploaded_file.name
                )

                st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: {uploaded_file.name}")

                # ë¯¸ë¦¬ë³´ê¸°
                st.markdown("##### ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)")
                st.dataframe(df.head(), use_container_width=True)

                # ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸
                with st.expander("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸"):
                    quality_report = DataLoader.get_data_quality_report(df)

                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("ì´ í–‰ ìˆ˜", f"{quality_report['total_rows']:,}")
                    col2.metric("ì´ ì»¬ëŸ¼ ìˆ˜", f"{quality_report['total_columns']:,}")
                    col3.metric("ê²°ì¸¡ì¹˜", f"{quality_report['total_missing']:,}")
                    col4.metric("ì¤‘ë³µ í–‰", f"{quality_report['duplicate_rows']:,}")

                    st.markdown("**ì»¬ëŸ¼ë³„ ì •ë³´**")
                    st.dataframe(quality_report['column_info'], use_container_width=True)

                st.info("ğŸ’¡ 'ìë™ ë¶„ì„' í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")

        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    else:
        st.info("ğŸ“¤ CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")


def render_crawling_ui():
    """í¬ë¡¤ë§ UI (í™˜ê²½ë³„ ë¶„ê¸°)"""
    st.markdown("#### ğŸŒ ì›¹ í¬ë¡¤ë§")

    if Environment.is_local():
        # ë¡œì»¬ í™˜ê²½: ì‹¤ì œ í¬ë¡¤ë§
        st.info("ğŸ’» ë¡œì»¬ í™˜ê²½: ì‹¤ì œ í¬ë¡¤ë§ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥")

        # í¬ë¡¤ë§ ì†ŒìŠ¤ ì„ íƒ
        crawl_source = st.selectbox(
            "í¬ë¡¤ë§ ì†ŒìŠ¤ ì„ íƒ",
            ["ë„¤ì´ë²„ ì˜í™” ë¦¬ë·°", "ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·°"],
            key="crawl_source"
        )

        if crawl_source == "ë„¤ì´ë²„ ì˜í™” ë¦¬ë·°":
            render_movie_crawling()
        else:
            render_place_crawling()

    else:
        # ë°°í¬ í™˜ê²½: í¬ë¡¤ë§ ë¹„í™œì„±í™”
        st.warning("â˜ï¸ ë°°í¬ í™˜ê²½: í¬ë¡¤ë§ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.info("ğŸ’¡ 'ìƒ˜í”Œ ë°ì´í„°' íƒ­ì—ì„œ ë¯¸ë¦¬ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")


def render_movie_crawling():
    """ë„¤ì´ë²„ ì˜í™” í¬ë¡¤ë§ UI"""
    st.markdown("##### ğŸ¬ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° í¬ë¡¤ë§")

    col1, col2 = st.columns([3, 1])

    with col1:
        movie_url = st.text_input(
            "ì˜í™” URL ë˜ëŠ” ID",
            placeholder="https://movie.naver.com/movie/bi/mi/basic.nhn?code=215095",
            key="movie_url"
        )

    with col2:
        max_reviews = st.number_input(
            "ìˆ˜ì§‘í•  ë¦¬ë·° ìˆ˜",
            min_value=10,
            max_value=1000,
            value=100,
            step=10,
            key="max_reviews_movie"
        )

    if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", key="start_movie_crawl", use_container_width=True):
        if not movie_url:
            st.error("âŒ URL ë˜ëŠ” ì˜í™” IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        try:
            # URLì—ì„œ ì˜í™” ID ì¶”ì¶œ
            import re

            if 'code=' in movie_url:
                match = re.search(r'code=(\d+)', movie_url)
                movie_id = match.group(1) if match else None
            elif movie_url.isdigit():
                movie_id = movie_url
            else:
                st.error("âŒ ì˜¬ë°”ë¥¸ URL ë˜ëŠ” ì˜í™” IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                return

            if not movie_id:
                st.error("âŒ URLì—ì„œ ì˜í™” IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return

            st.info(f"ğŸ¬ ì˜í™” ID: {movie_id}")

            with st.spinner(f"ğŸ¤– ë„¤ì´ë²„ ì˜í™”ì—ì„œ {max_reviews}ê°œ ë¦¬ë·°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” ì¤‘..."):
                # ë²„ê·¸ #36 ìˆ˜ì •: í¬ë¡¤ëŸ¬ import ì‹¤íŒ¨ ì²˜ë¦¬
                try:
                    import sys
                    crawler_path = Path(__file__).parent / 'crawlers'
                    if str(crawler_path) not in sys.path:
                        sys.path.insert(0, str(crawler_path))

                    from naver_movie_crawler import NaverMovieCrawler
                except ImportError as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ğŸ’¡ crawlers/ í´ë”ì™€ naver_movie_crawler.py íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.info("ğŸ’¡ ë˜ëŠ” `pip install selenium webdriver-manager` ëª…ë ¹ìœ¼ë¡œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”.")
                    return
                except Exception as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    return

                # í¬ë¡¤ë§ ì‹¤í–‰
                crawler = NaverMovieCrawler(headless=True, delay=0.5)

                try:
                    df = crawler.crawl_reviews(movie_id, max_reviews=max_reviews)

                    if df is not None and len(df) > 0:
                        # ì»¬ëŸ¼ëª… ë§¤í•‘
                        df_mapped = df.rename(columns={
                            'review': 'text',
                            'score': 'rating'
                        })

                        # ì„¸ì…˜ì— ì €ì¥
                        SessionManager.save_data(
                            data=df_mapped,
                            data_type='review',
                            source='crawl_movie',
                            file_name=f'movie_{movie_id}_reviews.csv'
                        )

                        st.success(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
                        st.balloons()
                        # ë²„ê·¸ #35 ìˆ˜ì •: ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
                        import time
                        time.sleep(0.1)
                        st.rerun()
                    else:
                        st.error("âŒ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

                finally:
                    crawler.close()

        except Exception as e:
            st.error(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
            st.exception(e)


def render_place_crawling():
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ í¬ë¡¤ë§ UI"""
    st.markdown("##### ğŸª ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° í¬ë¡¤ë§")

    col1, col2 = st.columns([3, 1])

    with col1:
        place_url = st.text_input(
            "í”Œë ˆì´ìŠ¤ URL ë˜ëŠ” ID",
            placeholder="https://m.place.naver.com/restaurant/1234567890/review",
            key="place_url"
        )

    with col2:
        max_reviews = st.number_input(
            "ìˆ˜ì§‘í•  ë¦¬ë·° ìˆ˜",
            min_value=10,
            max_value=500,
            value=100,
            step=10,
            key="max_reviews_place"
        )

    if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", key="start_place_crawl", use_container_width=True):
        if not place_url:
            st.error("âŒ URL ë˜ëŠ” í”Œë ˆì´ìŠ¤ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        try:
            # URLì—ì„œ í”Œë ˆì´ìŠ¤ ID ì¶”ì¶œ
            import re

            patterns = [
                r'place\.naver\.com/[^/]+/(\d+)',
                r'pcmap\.place\.naver\.com/[^/]+/(\d+)',
                r'map\.naver\.com/[^/]+/place/(\d+)',
                r'/place/(\d+)',
                r'(\d{10,})',
            ]

            place_id = None
            for pattern in patterns:
                match = re.search(pattern, place_url)
                if match:
                    place_id = match.group(1)
                    break

            if not place_id and place_url.isdigit():
                place_id = place_url

            if not place_id:
                st.error("âŒ ì˜¬ë°”ë¥¸ URL ë˜ëŠ” í”Œë ˆì´ìŠ¤ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                return

            st.info(f"ğŸª í”Œë ˆì´ìŠ¤ ID: {place_id}")

            with st.spinner(f"ğŸ¤– ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ì—ì„œ {max_reviews}ê°œ ë¦¬ë·°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” ì¤‘..."):
                # ë²„ê·¸ #36 ìˆ˜ì •: í¬ë¡¤ëŸ¬ import ì‹¤íŒ¨ ì²˜ë¦¬
                try:
                    import sys
                    crawler_path = Path(__file__).parent / 'crawlers'
                    if str(crawler_path) not in sys.path:
                        sys.path.insert(0, str(crawler_path))

                    from naver_place_crawler import NaverPlaceCrawler
                except ImportError as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ğŸ’¡ crawlers/ í´ë”ì™€ naver_place_crawler.py íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.info("ğŸ’¡ ë˜ëŠ” `pip install selenium webdriver-manager` ëª…ë ¹ìœ¼ë¡œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”.")
                    return
                except Exception as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    return

                # í¬ë¡¤ë§ ì‹¤í–‰
                crawler = NaverPlaceCrawler(headless=True, delay=0.5)

                try:
                    df = crawler.crawl_reviews(place_id, max_reviews=max_reviews)

                    if df is not None and len(df) > 0:
                        # ì»¬ëŸ¼ëª… ë§¤í•‘
                        df_mapped = df.rename(columns={
                            'review': 'text',
                            'rating': 'rating'
                        })

                        # ì„¸ì…˜ì— ì €ì¥
                        SessionManager.save_data(
                            data=df_mapped,
                            data_type='review',
                            source='crawl_place',
                            file_name=f'place_{place_id}_reviews.csv'
                        )

                        st.success(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
                        st.balloons()
                        # ë²„ê·¸ #35 ìˆ˜ì •: ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
                        import time
                        time.sleep(0.1)
                        st.rerun()
                    else:
                        st.error("âŒ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

                finally:
                    crawler.close()

        except Exception as e:
            st.error(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
            st.exception(e)


def render_sample_data():
    """ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ UI"""
    st.markdown("#### ğŸ“¦ ìƒ˜í”Œ ë°ì´í„°")

    if Environment.is_deployed():
        st.info("â˜ï¸ ë°°í¬ í™˜ê²½: ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í”Œë«í¼ì„ ì²´í—˜í•˜ì„¸ìš”")

    # ìƒ˜í”Œ ë°ì´í„° ëª©ë¡
    sample_files = Environment.list_sample_data()

    if not sample_files:
        st.warning("âš ï¸ ìƒ˜í”Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. sample_data/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # ìƒ˜í”Œ ë°ì´í„° ì„¤ëª…
    sample_descriptions = {
        'ecommerce_sample.csv': 'ğŸ›’ E-commerce ê±°ë˜ ë°ì´í„° (RFM ë¶„ì„ìš©)',
        'naver_movie_reviews.csv': 'ğŸ¬ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°',
        'naver_place_reviews.csv': 'ğŸ“ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° ë°ì´í„°',
        'sales_sample.csv': 'ğŸ“Š íŒë§¤ ë°ì´í„° (ì‹œê³„ì—´ ë¶„ì„ìš©)'
    }

    # ì„ íƒ UI
    selected_file = st.selectbox(
        "ìƒ˜í”Œ ë°ì´í„° ì„ íƒ",
        sample_files,
        format_func=lambda x: sample_descriptions.get(x, x),
        key="sample_file"
    )

    if st.button("ğŸ“‚ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ", key="load_sample"):
        try:
            with st.spinner(f"ğŸ“‚ {selected_file} ë¡œë“œ ì¤‘..."):
                sample_path = os.path.join(Environment.get_sample_data_path(), selected_file)

                # DataLoader.load_file()ì„ ì‚¬ìš©í•˜ì—¬ CSV/Excel ìë™ ì²˜ë¦¬
                df = DataLoader.load_file(sample_path)

                # ë°ì´í„° íƒ€ì… ìë™ ê°ì§€
                if 'ecommerce' in selected_file:
                    data_type = 'ecommerce'
                elif 'movie' in selected_file or 'place' in selected_file:
                    data_type = 'review'
                elif 'sales' in selected_file:
                    data_type = 'sales'
                else:
                    data_type = None

                # ì„¸ì…˜ì— ì €ì¥
                SessionManager.save_data(
                    data=df,
                    data_type=data_type,
                    source='sample',
                    file_name=selected_file
                )

                st.success(f"âœ… ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {selected_file}")
                # ë²„ê·¸ #35 ìˆ˜ì •: ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
                import time
                time.sleep(0.1)
                st.rerun()

        except Exception as e:
            st.error(f"âŒ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


def show_data_info():
    """ë°ì´í„° ì •ë³´ í‘œì‹œ"""
    info = SessionManager.get_data_info()

    st.success("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("íŒŒì¼ëª…", info['file_name'] or 'N/A')
    col2.metric("ë°ì´í„° ì†ŒìŠ¤", info['source'] or 'N/A')
    col3.metric("í–‰ ìˆ˜", f"{info['rows']:,}")
    col4.metric("ì»¬ëŸ¼ ìˆ˜", f"{info['columns']:,}")

    if info['data_type']:
        type_emoji = {
            'ecommerce': 'ğŸ›’',
            'review': 'ğŸ’¬',
            'sales': 'ğŸ“Š'
        }
        st.info(f"{type_emoji.get(info['data_type'], 'ğŸ“„')} ê°ì§€ëœ ë°ì´í„° íƒ€ì…: **{info['data_type']}**")


def page_auto_analysis():
    """í˜ì´ì§€ 2: ìë™ ë¶„ì„"""
    st.title("ğŸ¤– ìë™ ë¶„ì„")

    # ë°ì´í„° ì²´í¬
    if not SessionManager.has_data():
        st.warning("âš ï¸ ë¨¼ì € 'ì‹œì‘í•˜ê¸°' í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”")
        st.info("ğŸ’¡ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ  ì‹œì‘í•˜ê¸°' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”")
        return

    st.markdown("### ğŸ“Š ë°ì´í„° ê°œìš”")
    show_data_info()

    st.markdown("---")
    st.markdown("### ğŸ”§ ë¶„ì„ ì„¤ì •")

    # ë¶„ì„ íƒ€ì… ì„ íƒ (ìë™ ê°ì§€ or ìˆ˜ë™ ì„ íƒ)
    detected_type = SessionManager.get_data_type()

    if detected_type:
        type_names = {
            'ecommerce': 'E-commerce (RFM ë¶„ì„)',
            'review': 'ë¦¬ë·° ë¶„ì„ (ê°ì„± ë¶„ì„, í‚¤ì›Œë“œ ì¶”ì¶œ)',
            'sales': 'íŒë§¤ ë¶„ì„ (ì‹œê³„ì—´ ë¶„ì„)'
        }
        st.success(f"âœ… ìë™ ê°ì§€: **{type_names.get(detected_type)}**")
        analysis_type = detected_type
    else:
        analysis_type = st.radio(
            "ë¶„ì„ íƒ€ì… ì„ íƒ",
            ['ecommerce', 'review', 'sales'],
            format_func=lambda x: {
                'ecommerce': 'ğŸ›’ E-commerce (RFM ë¶„ì„)',
                'review': 'ğŸ’¬ ë¦¬ë·° ë¶„ì„ (ê°ì„± ë¶„ì„)',
                'sales': 'ğŸ“Š íŒë§¤ ë¶„ì„ (ì‹œê³„ì—´ ë¶„ì„)'
            }[x],
            horizontal=True
        )

    SessionManager.set_analysis_type(analysis_type)

    # GPT ì˜µì…˜ (ë¦¬ë·° ë¶„ì„ì¼ ë•Œë§Œ í‘œì‹œ)
    use_gpt = False
    if analysis_type == 'review':
        st.markdown("---")
        st.markdown("### ğŸ¤– GPT ê³ ê¸‰ ë¶„ì„ (ì„ íƒ)")

        # API í‚¤ ìƒíƒœ í™•ì¸
        from utils.api_key_manager import APIKeyManager
        api_status = APIKeyManager.get_api_key_status()

        if api_status['available'] and api_status['valid']:
            st.success(f"âœ… API í‚¤ ê°ì§€ë¨ (ì†ŒìŠ¤: {api_status['source']})")

            col1, col2 = st.columns([3, 1])
            with col1:
                use_gpt = st.checkbox(
                    "GPTë¡œ ê³ ê¸‰ ê°ì„± ë¶„ì„ ìˆ˜í–‰ (ë¶€ì • ë¦¬ë·° ì¤‘ì‹¬)",
                    value=False,
                    help="GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (ë¹„ìš© ë°œìƒ)"
                )
            with col2:
                if use_gpt:
                    # ì˜ˆìƒ ë¹„ìš© í‘œì‹œ
                    data = SessionManager.get_data()
                    est_reviews = min(len(data), 100)  # ìµœëŒ€ 100ê°œ
                    est_tokens = est_reviews * 100  # ë¦¬ë·°ë‹¹ ì•½ 100 í† í°
                    est_cost = APIKeyManager.estimate_cost(est_tokens, 'gpt-4o-mini')
                    st.info(f"ì˜ˆìƒ: ~${est_cost:.4f}")

        else:
            st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            with st.expander("ğŸ“– API í‚¤ ì„¤ì • ë°©ë²•"):
                st.markdown("""
**API í‚¤ë¥¼ ì–»ëŠ” ë°©ë²•:**
1. [OpenAI Platform](https://platform.openai.com/api-keys)ì— ì ‘ì†
2. API í‚¤ ìƒì„±
3. ë‹¤ìŒ ì¤‘ í•œ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ì„¤ì •:

**ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ (ê¶Œì¥)**
```bash
export OPENAI_API_KEY='sk-...'
```

**ë°©ë²• 2: .env íŒŒì¼**
```
OPENAI_API_KEY=sk-...
```

**ë°©ë²• 3: Streamlit Secrets (ë°°í¬ìš©)**
`.streamlit/secrets.toml` íŒŒì¼ ìƒì„±:
```toml
OPENAI_API_KEY = "sk-..."
```
                """)

    st.markdown("---")

    # ë¶„ì„ ì‹¤í–‰
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        run_analysis(analysis_type, use_gpt=use_gpt)

    # ê²°ê³¼ í‘œì‹œ
    if SessionManager.has_results():
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ë¶„ì„ ê²°ê³¼")
        show_analysis_results(analysis_type)


def run_analysis(analysis_type: str, use_gpt: bool = False):
    """ë¶„ì„ ì‹¤í–‰"""
    import time

    data = SessionManager.get_data()

    if analysis_type == 'ecommerce':
        run_ecommerce_analysis(data)
    elif analysis_type == 'review':
        run_review_analysis(data, use_gpt=use_gpt)
    elif analysis_type == 'sales':
        run_sales_analysis(data)


def run_ecommerce_analysis(df: pd.DataFrame):
    """E-commerce RFM ë¶„ì„ ì‹¤í–‰"""
    import time

    try:
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['customerid', 'invoicedate', 'quantity', 'unitprice']
        df_cols_lower = [col.lower() for col in df.columns]

        missing_cols = [col for col in required_cols if col not in df_cols_lower]

        if missing_cols:
            st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_cols)}")
            st.info("ğŸ’¡ í•„ìš”í•œ ì»¬ëŸ¼: CustomerID, InvoiceDate, Quantity, UnitPrice")
            return

        # Progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()

        # 1. ì „ì²˜ë¦¬
        status_text.text("1/5 ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        progress_bar.progress(20)
        preprocessor = DataPreprocessor(df)
        processed_df, logs = (preprocessor
                             .normalize_column_names()
                             .handle_missing_values(strategy='drop')
                             .remove_duplicates()
                             .convert_date_columns(['invoicedate'])
                             .get_processed_data())

        # 2. RFM ë¶„ì„
        status_text.text("2/5 RFM ë¶„ì„ ì¤‘...")
        progress_bar.progress(40)
        rfm_analyzer = RFMAnalyzer(
            processed_df,
            customer_col='customerid',
            date_col='invoicedate',
            amount_col=None,
            quantity_col='quantity',
            price_col='unitprice'
        )
        rfm_df = rfm_analyzer.calculate_rfm()

        # 3. êµ°ì§‘í™”
        status_text.text("3/5 ê³ ê° ì„¸ë¶„í™” ì¤‘...")
        progress_bar.progress(60)
        optimal_k, metrics = rfm_analyzer.find_optimal_clusters()
        clustered_df = rfm_analyzer.perform_clustering()
        cluster_summary = rfm_analyzer.get_cluster_summary()

        # 4. ì‹œê°í™” ì¤€ë¹„
        status_text.text("4/5 ì‹œê°í™” ìƒì„± ì¤‘...")
        progress_bar.progress(80)

        # 5. ê²°ê³¼ ì €ì¥
        results = {
            'type': 'ecommerce',
            'rfm_df': rfm_df,
            'clustered_df': clustered_df,
            'cluster_summary': cluster_summary,
            'optimal_k': optimal_k,
            'metrics': metrics,
            'analyzer': rfm_analyzer
        }

        SessionManager.save_results(results)

        # ì™„ë£Œ
        progress_bar.progress(100)
        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
        # ë²„ê·¸ #35 ìˆ˜ì •: UI ì—…ë°ì´íŠ¸ ë° ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()

        st.success("ğŸ‰ E-commerce ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.balloons()
        st.rerun()

    except Exception as e:
        # ë²„ê·¸ #45 ìˆ˜ì •: ë¶„ì„ ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ ê²°ê³¼ ì‚­ì œ
        SessionManager.clear_analysis()
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.exception(e)


def run_review_analysis(df: pd.DataFrame, use_gpt: bool = False):
    """ë¦¬ë·° ê°ì„± ë¶„ì„ ì‹¤í–‰"""
    import time

    try:
        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°
        text_col = None
        rating_col = None

        for col in df.columns:
            col_lower = col.lower()
            if 'review' in col_lower or 'text' in col_lower or 'comment' in col_lower:
                text_col = col
            if 'rating' in col_lower or 'score' in col_lower or 'point' in col_lower:
                rating_col = col

        if not text_col:
            st.error("âŒ ë¦¬ë·° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ í•„ìš”í•œ ì»¬ëŸ¼: review, text, comment ì¤‘ í•˜ë‚˜")
            return

        st.info(f"ğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼: **{text_col}**" + (f" | í‰ì  ì»¬ëŸ¼: **{rating_col}**" if rating_col else ""))

        # Progress bar
        total_steps = 6 if use_gpt else 5
        progress_bar = st.progress(0)
        status_text = st.empty()

        # 1. í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
        status_text.text(f"1/{total_steps} í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 1))
        analyzer = TextAnalyzer(df, text_column=text_col, rating_column=rating_col)

        # 2. ì „ì²˜ë¦¬
        status_text.text(f"2/{total_steps} í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 2))
        analyzer.preprocess_text()

        # 3. ê°ì„± ë¶„ì„
        status_text.text(f"3/{total_steps} ê°ì„± ë¶„ì„ ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 3))
        analyzer.analyze_sentiment_simple()

        # 4. í‚¤ì›Œë“œ ì¶”ì¶œ
        status_text.text(f"4/{total_steps} í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 4))
        keywords = analyzer.extract_keywords(top_n=20)

        # 5. GPT ê³ ê¸‰ ë¶„ì„ (ì„ íƒ)
        gpt_results = None
        if use_gpt:
            status_text.text(f"5/{total_steps} GPTë¡œ ê³ ê¸‰ ê°ì„± ë¶„ì„ ì¤‘... (ë¶€ì • ë¦¬ë·° ìš°ì„ )")
            progress_bar.progress(int(100 / total_steps * 5))

            try:
                from modules.gpt_analyzer import GPTAnalyzer
                from utils.api_key_manager import get_api_key

                api_key = get_api_key()
                if api_key:
                    gpt = GPTAnalyzer(api_key=api_key)

                    # ë¶€ì • ë¦¬ë·° í•„í„°ë§ + ë¶„ì„
                    gpt_sentiment = gpt.analyze_sentiment_batch(
                        reviews=[],  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ (DataFrameì—ì„œ ì§ì ‘ í•„í„°ë§)
                        max_reviews=100,
                        filter_negative=True,
                        df=analyzer.df,
                        rating_column=rating_col if rating_col else 'rating',
                        text_column=text_col
                    )

                    # ë¹„ìš© ì •ë³´
                    cost_info = gpt.get_cost_info()

                    gpt_results = {
                        'sentiment': gpt_sentiment,
                        'cost': cost_info
                    }

                    st.success(f"âœ… GPT ë¶„ì„ ì™„ë£Œ! (ë¹„ìš©: ${cost_info['total_cost']:.4f}, í† í°: {cost_info['total_tokens']:,})")
                else:
                    st.warning("âš ï¸ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ GPT ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

            except Exception as e:
                st.warning(f"âš ï¸ GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                traceback.print_exc()

        # 6. ê²°ê³¼ ì €ì¥
        results = {
            'type': 'review',
            'analyzer': analyzer,
            'text_col': text_col,
            'rating_col': rating_col,
            'keywords': keywords,
            'gpt_results': gpt_results,
            'use_gpt': use_gpt
        }

        SessionManager.save_results(results)

        # ì™„ë£Œ
        progress_bar.progress(100)
        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
        # ë²„ê·¸ #35 ìˆ˜ì •: UI ì—…ë°ì´íŠ¸ ë° ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()

        st.success("ğŸ‰ ë¦¬ë·° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.balloons()
        st.rerun()

    except Exception as e:
        # ë²„ê·¸ #45 ìˆ˜ì •: ë¶„ì„ ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ ê²°ê³¼ ì‚­ì œ
        SessionManager.clear_analysis()
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.exception(e)


def run_sales_analysis(df: pd.DataFrame):
    """íŒë§¤ ë¶„ì„ ì‹¤í–‰"""
    st.info("ğŸš§ íŒë§¤ ë¶„ì„ ê¸°ëŠ¥ì€ DAY 29-31ì— êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")


def show_analysis_results(analysis_type: str):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    results = SessionManager.get_results()

    if results.get('type') == 'ecommerce':
        show_ecommerce_results(results)
    elif results.get('type') == 'review':
        show_review_results(results)
    elif results.get('type') == 'sales':
        show_sales_results(results)


def show_ecommerce_results(results: dict):
    """E-commerce ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    clustered_df = results['clustered_df']
    cluster_summary = results['cluster_summary']
    optimal_k = results['optimal_k']

    # ë©”íŠ¸ë¦­ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ê³ ê° ìˆ˜", f"{len(clustered_df):,}")
    with col2:
        st.metric("êµ°ì§‘ ê°œìˆ˜", optimal_k)
    with col3:
        # ë²„ê·¸ #37 ìˆ˜ì •: cluster_name ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        if 'cluster_name' in clustered_df.columns:
            vip_count = len(clustered_df[clustered_df['cluster_name'].str.contains('VIP|ì¶©ì„±', na=False)])
        else:
            vip_count = 0
        st.metric("VIP/ì¶©ì„± ê³ ê°", f"{vip_count:,}")
    with col4:
        # ë²„ê·¸ #37 ìˆ˜ì •: cluster_name ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
        if 'cluster_name' in clustered_df.columns:
            risk_count = len(clustered_df[clustered_df['cluster_name'].str.contains('ì´íƒˆ|íœ´ë©´', na=False)])
        else:
            risk_count = 0
        st.metric("ì´íƒˆ ìœ„í—˜", f"{risk_count:,}")

    st.markdown("---")

    # ì‹œê°í™”
    visualizer = Visualizer()
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š RFM íˆíŠ¸ë§µ", "ğŸ“ˆ ê³ ê° ë¶„í¬", "ğŸ“‹ ë°ì´í„°"])

    with tab1:
        st.markdown("### RFM íˆíŠ¸ë§µ")
        fig_heatmap = visualizer.plot_rfm_heatmap(cluster_summary)
        st.plotly_chart(fig_heatmap, use_container_width=True)

        st.markdown("### êµ°ì§‘ë³„ ì§€í‘œ")
        fig_bar = visualizer.plot_cluster_bar_chart(cluster_summary)
        st.plotly_chart(fig_bar, use_container_width=True)

    with tab2:
        st.markdown("### ê³ ê° ê°€ì¹˜ í”¼ë¼ë¯¸ë“œ")
        fig_pyramid = visualizer.plot_customer_value_pyramid(cluster_summary)
        st.plotly_chart(fig_pyramid, use_container_width=True)

        st.markdown("### êµ°ì§‘ë³„ ê³ ê° ë¶„í¬")
        fig_pie = visualizer.plot_cluster_distribution_pie(cluster_summary)
        st.plotly_chart(fig_pie, use_container_width=True)

    with tab3:
        st.markdown("### êµ°ì§‘ë³„ ìƒì„¸ í†µê³„")
        st.dataframe(cluster_summary, use_container_width=True)

        st.markdown("### ê³ ê° ì„¸ë¶„í™” ë°ì´í„°")
        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ
        display_cols = []
        for check_col in ['customerid']:
            if check_col in clustered_df.columns:
                display_cols.append(check_col)

        # RFM ì»¬ëŸ¼ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        for col in clustered_df.columns:
            col_lower = col.lower()
            if col_lower in ['recency', 'frequency', 'monetary'] and col not in display_cols:
                display_cols.append(col)

        # cluster ê´€ë ¨ ì»¬ëŸ¼
        for check_col in ['cluster', 'cluster_name']:
            if check_col in clustered_df.columns and check_col not in display_cols:
                display_cols.append(check_col)

        st.dataframe(
            clustered_df[display_cols] if display_cols else clustered_df,
            use_container_width=True
        )

    # ì¸ì‚¬ì´íŠ¸
    st.markdown("---")
    st.markdown("### ğŸ’¡ ì¸ì‚¬ì´íŠ¸")

    generator = InsightGenerator()
    insights = generator.generate_rfm_insights(results['rfm_df'], cluster_summary)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**ì£¼ìš” ë°œê²¬ì‚¬í•­**")
        for finding in insights['key_findings']:
            st.info(finding)

    with col2:
        st.markdown("**ì•¡ì…˜ ì•„ì´í…œ**")
        for action in insights['action_items']:
            st.warning(action)


def show_review_results(results: dict):
    """ë¦¬ë·° ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    analyzer = results['analyzer']
    text_col = results['text_col']

    # ê°ì„± ë¶„í¬
    sentiment_counts = analyzer.df['sentiment'].value_counts()

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ ë¦¬ë·° ìˆ˜", f"{len(analyzer.df):,}")
    with col2:
        positive_pct = (sentiment_counts.get('positive', 0) / len(analyzer.df) * 100)
        st.metric("ê¸ì • ë¹„ìœ¨", f"{positive_pct:.1f}%")
    with col3:
        negative_pct = (sentiment_counts.get('negative', 0) / len(analyzer.df) * 100)
        st.metric("ë¶€ì • ë¹„ìœ¨", f"{negative_pct:.1f}%")

    st.markdown("---")

    # ì‹œê°í™”
    visualizer = Visualizer()
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ê°ì„± ë¶„ì„", "â˜ï¸ ì›Œë“œ í´ë¼ìš°ë“œ", "ğŸ“‹ ë°ì´í„°"])

    with tab1:
        st.markdown("### ê°ì„± ë¶„í¬")
        fig_sentiment = visualizer.plot_sentiment_distribution(analyzer.df)
        st.plotly_chart(fig_sentiment, use_container_width=True)

        st.markdown("### ê°ì„±ë³„ í‚¤ì›Œë“œ (Top 15)")
        keywords = results.get('keywords', {})
        if keywords:
            fig_keywords = visualizer.plot_keywords_comparison(keywords)
            st.plotly_chart(fig_keywords, use_container_width=True)
        else:
            st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        st.markdown("### ì „ì²´ ì›Œë“œ í´ë¼ìš°ë“œ")
        try:
            # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
            from collections import Counter
            all_words = []
            if hasattr(analyzer, 'processed_texts') and analyzer.processed_texts:
                for tokens in analyzer.processed_texts:
                    if tokens:
                        all_words.extend(tokens.split())

            if all_words:
                word_freq = Counter(all_words).most_common(50)
                wordcloud_fig = visualizer.plot_word_cloud_data(word_freq, top_n=50)
                st.plotly_chart(wordcloud_fig, use_container_width=True)
            else:
                st.info("ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

    with tab3:
        st.markdown("### ë¦¬ë·° ë°ì´í„°")
        display_cols = [text_col, 'sentiment']
        if 'rating' in analyzer.df.columns:
            display_cols.insert(1, 'rating')
        st.dataframe(analyzer.df[display_cols], use_container_width=True)


def show_sales_results(results: dict):
    """íŒë§¤ ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    st.info("ğŸš§ íŒë§¤ ë¶„ì„ ê²°ê³¼ í‘œì‹œ ê¸°ëŠ¥ì€ DAY 29-31ì— êµ¬í˜„ ì˜ˆì •ì…ë‹ˆë‹¤.")


def page_explore():
    """í˜ì´ì§€ 3: ìƒì„¸ íƒìƒ‰"""
    st.title("ğŸ” ìƒì„¸ íƒìƒ‰")

    # ê²°ê³¼ ì²´í¬
    if not SessionManager.has_results():
        st.warning("âš ï¸ ë¨¼ì € 'ìë™ ë¶„ì„' í˜ì´ì§€ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”")
        st.info("ğŸ’¡ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ¤– ìë™ ë¶„ì„' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”")
        return

    results = SessionManager.get_results()
    analysis_type = results.get('type')

    st.markdown("### ğŸ”§ í•„í„°ë§ ë° ê²€ìƒ‰")

    if analysis_type == 'ecommerce':
        render_ecommerce_filters(results)
    elif analysis_type == 'review':
        render_review_filters(results)
    elif analysis_type == 'sales':
        st.info("ğŸš§ íŒë§¤ ë¶„ì„ í•„í„°ë§ì€ DAY 29-31ì— ì¶”ê°€ë©ë‹ˆë‹¤")


def render_ecommerce_filters(results: dict):
    """E-commerce í•„í„°ë§ UI"""
    clustered_df = results.get('clustered_df')
    rfm_df = results.get('rfm_df')
    cluster_summary = results.get('cluster_summary')

    # RFM ë°ì´í„° ìš°ì„  ì‚¬ìš© (Recency, Frequency, Monetary ì»¬ëŸ¼ í¬í•¨)
    if rfm_df is not None and not rfm_df.empty:
        display_df = rfm_df
    elif clustered_df is not None and not clustered_df.empty:
        display_df = clustered_df
    else:
        st.error("âŒ ë¶„ì„ ê²°ê³¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì‚¬ì´ë“œë°” í•„í„°
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ” í•„í„° ì˜µì…˜")

        # êµ°ì§‘ ì„ íƒ (cluster_nameì´ ìˆëŠ” ê²½ìš°ë§Œ)
        if 'cluster_name' in display_df.columns:
            all_clusters = sorted(display_df['cluster_name'].unique())
            selected_clusters = st.multiselect(
                "êµ°ì§‘ ì„ íƒ",
                options=all_clusters,
                default=all_clusters,
                key="cluster_filter"
            )
        else:
            selected_clusters = None

        # RFM ë²”ìœ„ ìŠ¬ë¼ì´ë”
        st.markdown("**Recency ë²”ìœ„ (ì¼)**")
        # ë²„ê·¸ #34 ìˆ˜ì •: min == max ì²´í¬
        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì»¬ëŸ¼ ì°¾ê¸°
        recency_col = None
        for col in display_df.columns:
            if col.lower() == 'recency':
                recency_col = col
                break

        if recency_col is None:
            st.warning("âš ï¸ Recency ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            r_min, r_max = 0, 0
        else:
            r_min_val = int(display_df[recency_col].min())
            r_max_val = int(display_df[recency_col].max())
            if r_min_val < r_max_val:
                r_min, r_max = st.slider(
                    "Recency",
                    min_value=r_min_val,
                    max_value=r_max_val,
                    value=(r_min_val, r_max_val),
                    key="r_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ê³ ê°ì˜ Recency: {r_min_val}ì¼")
                r_min, r_max = r_min_val, r_max_val

        st.markdown("**Frequency ë²”ìœ„ (ê±´)**")
        # ë²„ê·¸ #34 ìˆ˜ì •: min == max ì²´í¬
        frequency_col = None
        for col in display_df.columns:
            if col.lower() == 'frequency':
                frequency_col = col
                break

        if frequency_col is None:
            st.warning("âš ï¸ Frequency ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            f_min, f_max = 0, 0
        else:
            f_min_val = int(display_df[frequency_col].min())
            f_max_val = int(display_df[frequency_col].max())
            if f_min_val < f_max_val:
                f_min, f_max = st.slider(
                    "Frequency",
                    min_value=f_min_val,
                    max_value=f_max_val,
                    value=(f_min_val, f_max_val),
                    key="f_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ê³ ê°ì˜ Frequency: {f_min_val}ê±´")
                f_min, f_max = f_min_val, f_max_val

        st.markdown("**Monetary ë²”ìœ„ (ì›)**")
        # ë²„ê·¸ #34 ìˆ˜ì •: min == max ì²´í¬
        monetary_col = None
        for col in display_df.columns:
            if col.lower() == 'monetary':
                monetary_col = col
                break

        if monetary_col is None:
            st.warning("âš ï¸ Monetary ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            m_min, m_max = 0, 0
        else:
            m_min_val = float(display_df[monetary_col].min())
            m_max_val = float(display_df[monetary_col].max())
            if m_min_val < m_max_val:
                m_min, m_max = st.slider(
                    "Monetary",
                    min_value=m_min_val,
                    max_value=m_max_val,
                    value=(m_min_val, m_max_val),
                    key="m_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ê³ ê°ì˜ Monetary: â‚©{m_min_val:,.0f}")
                m_min, m_max = m_min_val, m_max_val

    # í•„í„° ì ìš© (ë²„ê·¸ #38 ìˆ˜ì •: .copy() ì¶”ê°€)
    # RFM ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
    if recency_col is None or frequency_col is None or monetary_col is None:
        st.error("âŒ RFM ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        filtered_df = display_df.copy()
    elif selected_clusters is not None and 'cluster_name' in display_df.columns:
        # êµ°ì§‘ + RFM í•„í„°ë§
        filtered_df = display_df[
            (display_df['cluster_name'].isin(selected_clusters)) &
            (display_df[recency_col].between(r_min, r_max)) &
            (display_df[frequency_col].between(f_min, f_max)) &
            (display_df[monetary_col].between(m_min, m_max))
        ].copy()
    else:
        # RFMë§Œ í•„í„°ë§
        filtered_df = display_df[
            (display_df[recency_col].between(r_min, r_max)) &
            (display_df[frequency_col].between(f_min, f_max)) &
            (display_df[monetary_col].between(m_min, m_max))
        ].copy()

    # ê²€ìƒ‰
    search_query = st.text_input(
        "ğŸ” ê³ ê° ID ê²€ìƒ‰",
        placeholder="ê³ ê° ID ì…ë ¥...",
        key="customer_search"
    )

    if search_query:
        # ë²„ê·¸ #39 ìˆ˜ì •: regex ì´ìŠ¤ì¼€ì´í•‘ ì¶”ê°€
        import re
        escaped_query = re.escape(search_query)
        filtered_df = filtered_df[
            filtered_df['customerid'].astype(str).str.contains(escaped_query, case=False, na=False)
        ]

    # ê²°ê³¼ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    col1.metric("í•„í„°ë§ëœ ê³ ê° ìˆ˜", f"{len(filtered_df):,}")

    # ë²„ê·¸ #32, #33 ìˆ˜ì •: ZeroDivisionErrorì™€ ë¹ˆ DataFrame ì²´í¬
    if len(display_df) > 0:
        ratio = len(filtered_df) / len(display_df) * 100
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", f"{ratio:.1f}%")
    else:
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", "N/A")

    if len(filtered_df) > 0 and monetary_col and monetary_col in filtered_df.columns:
        col3.metric("ì´ ë§¤ì¶œì•¡", f"â‚©{filtered_df[monetary_col].sum():,.0f}")
    else:
        col3.metric("ì´ ë§¤ì¶œì•¡", "â‚©0")

    st.markdown("---")

    # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬
    if len(filtered_df) == 0:
        st.warning("âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ ë³´ì„¸ìš”.")
    else:
        # ë°ì´í„° í…Œì´ë¸” - ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ
        display_cols = []
        for col in ['customerid']:
            if col in filtered_df.columns:
                display_cols.append(col)

        if recency_col and recency_col in filtered_df.columns:
            display_cols.append(recency_col)
        if frequency_col and frequency_col in filtered_df.columns:
            display_cols.append(frequency_col)
        if monetary_col and monetary_col in filtered_df.columns:
            display_cols.append(monetary_col)

        if 'cluster_name' in filtered_df.columns:
            display_cols.append('cluster_name')
        elif 'cluster' in filtered_df.columns:
            display_cols.append('cluster')

        st.dataframe(
            filtered_df[display_cols] if display_cols else filtered_df,
            use_container_width=True,
            height=400
        )

        # CSV ë‹¤ìš´ë¡œë“œ
        csv = filtered_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ í•„í„°ë§ëœ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"filtered_customers_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )


def render_review_filters(results: dict):
    """ë¦¬ë·° í•„í„°ë§ UI"""
    analyzer = results['analyzer']
    text_col = results['text_col']

    # ì‚¬ì´ë“œë°” í•„í„°
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ” í•„í„° ì˜µì…˜")

        # ê°ì„± í•„í„°
        all_sentiments = sorted(analyzer.df['sentiment'].unique())
        selected_sentiments = st.multiselect(
            "ê°ì„± ì„ íƒ",
            options=all_sentiments,
            default=all_sentiments,
            key="sentiment_filter"
        )

        # í‰ì  ë²”ìœ„ (ìˆì„ ê²½ìš°)
        if 'rating' in analyzer.df.columns:
            st.markdown("**í‰ì  ë²”ìœ„**")
            # ë²„ê·¸ #34 ìˆ˜ì •: min == max ì²´í¬
            rating_min_val = float(analyzer.df['rating'].min())
            rating_max_val = float(analyzer.df['rating'].max())
            if rating_min_val < rating_max_val:
                rating_min, rating_max = st.slider(
                    "Rating",
                    min_value=rating_min_val,
                    max_value=rating_max_val,
                    value=(rating_min_val, rating_max_val),
                    key="rating_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ë¦¬ë·°ì˜ í‰ì : {rating_min_val:.1f}")
                rating_min, rating_max = rating_min_val, rating_max_val

    # í•„í„° ì ìš© (ë²„ê·¸ #38 ìˆ˜ì •: .copy() ì¶”ê°€)
    filtered_df = analyzer.df[analyzer.df['sentiment'].isin(selected_sentiments)].copy()

    if 'rating' in analyzer.df.columns:
        filtered_df = filtered_df[filtered_df['rating'].between(rating_min, rating_max)]

    # ê²€ìƒ‰
    search_query = st.text_input(
        "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰",
        placeholder="ë¦¬ë·° ë‚´ìš© ê²€ìƒ‰...",
        key="review_search"
    )

    if search_query:
        # ë²„ê·¸ #39 ìˆ˜ì •: regex ì´ìŠ¤ì¼€ì´í•‘ ì¶”ê°€
        import re
        escaped_query = re.escape(search_query)
        filtered_df = filtered_df[
            filtered_df[text_col].astype(str).str.contains(escaped_query, case=False, na=False)
        ]

    # ê²°ê³¼ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    col1.metric("í•„í„°ë§ëœ ë¦¬ë·° ìˆ˜", f"{len(filtered_df):,}")

    # ë²„ê·¸ #32, #33 ìˆ˜ì •: ZeroDivisionErrorì™€ ë¹ˆ DataFrame ì²´í¬
    if len(analyzer.df) > 0:
        ratio = len(filtered_df) / len(analyzer.df) * 100
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", f"{ratio:.1f}%")
    else:
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", "N/A")

    if 'rating' in analyzer.df.columns:
        if len(filtered_df) > 0:
            avg_rating = filtered_df['rating'].mean()
            col3.metric("í‰ê·  í‰ì ", f"{avg_rating:.2f}")
        else:
            col3.metric("í‰ê·  í‰ì ", "N/A")

    st.markdown("---")

    # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬
    if len(filtered_df) == 0:
        st.warning("âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ ë³´ì„¸ìš”.")
    else:
        # ë°ì´í„° í…Œì´ë¸”
        display_cols = [text_col, 'sentiment']
        if 'rating' in analyzer.df.columns:
            display_cols.insert(1, 'rating')

        st.dataframe(
            filtered_df[display_cols],
            use_container_width=True,
            height=400
        )

        # CSV ë‹¤ìš´ë¡œë“œ
        csv = filtered_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ í•„í„°ë§ëœ ë¦¬ë·° CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"filtered_reviews_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )


def page_export():
    """í˜ì´ì§€ 4: ë‚´ë³´ë‚´ê¸°"""
    st.title("ğŸ“¥ ë‚´ë³´ë‚´ê¸°")

    # ê²°ê³¼ ì²´í¬
    if not SessionManager.has_results():
        st.warning("âš ï¸ ë¨¼ì € 'ìë™ ë¶„ì„' í˜ì´ì§€ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”")
        st.info("ğŸ’¡ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ¤– ìë™ ë¶„ì„' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”")
        return

    results = SessionManager.get_results()
    analysis_type = results.get('type')

    st.markdown("### ğŸ“¦ ë‹¤ìš´ë¡œë“œ ì˜µì…˜")

    col1, col2 = st.columns(2)

    # CSV ë‹¤ìš´ë¡œë“œ
    with col1:
        st.markdown("#### ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ")

        if analysis_type == 'ecommerce':
            # E-commerce: ê³ ê° ì„¸ë¶„í™” ë°ì´í„°
            clustered_df = results['clustered_df']
            csv = clustered_df.to_csv(index=False, encoding='utf-8-sig')

            st.download_button(
                label="ğŸ“Š ê³ ê° ì„¸ë¶„í™” CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"rfm_analysis_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )

            st.info(f"ì´ {len(clustered_df):,}ê°œ ê³ ê° ë°ì´í„°")

        elif analysis_type == 'review':
            # ë¦¬ë·°: ê°ì„± ë¶„ì„ ê²°ê³¼
            analyzer = results['analyzer']
            text_col = results['text_col']

            display_cols = [text_col, 'sentiment']
            if 'rating' in analyzer.df.columns:
                display_cols.insert(1, 'rating')

            csv = analyzer.df[display_cols].to_csv(index=False, encoding='utf-8-sig')

            st.download_button(
                label="ğŸ’¬ ë¦¬ë·° ê°ì„± ë¶„ì„ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"review_analysis_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )

            st.info(f"ì´ {len(analyzer.df):,}ê°œ ë¦¬ë·°")

        elif analysis_type == 'sales':
            st.info("ğŸš§ íŒë§¤ ë¶„ì„ CSVëŠ” DAY 29-31ì— ì¶”ê°€ë©ë‹ˆë‹¤")

    # HTML ë¦¬í¬íŠ¸
    with col2:
        st.markdown("#### ğŸ“Š HTML ë¦¬í¬íŠ¸")

        if st.button("ğŸ“‘ ë¦¬í¬íŠ¸ ìƒì„±", use_container_width=True):
            with st.spinner("ğŸ“Š HTML ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                try:
                    generator = HTMLReportGenerator()

                    if analysis_type == 'ecommerce':
                        # E-commerce ë¦¬í¬íŠ¸
                        # ê°„ë‹¨í•œ ë¦¬í¬íŠ¸ ìƒì„± (ë©”ì„œë“œ ë¯¸êµ¬í˜„ìœ¼ë¡œ ì„ì‹œ ì²˜ë¦¬)
                        from modules.insight_generator import InsightGenerator
                        insight_gen = InsightGenerator()
                        insights = insight_gen.generate_rfm_insights(
                            results['rfm_df'],
                            results['cluster_summary']
                        )

                        html_report = generator.generate_report(
                            analysis_type='ecommerce',
                            data_info={
                                'rows': len(results['clustered_df']),
                                'columns': len(results['clustered_df'].columns),
                                'customers': len(results['clustered_df'])
                            },
                            insights=insights,
                            charts=[]
                        )

                        st.download_button(
                            label="ğŸ“¥ E-commerce ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                            data=html_report,
                            file_name=f"ecommerce_report_{pd.Timestamp.now().strftime('%Y%m%d')}.html",
                            mime="text/html",
                            use_container_width=True
                        )

                        st.success("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")

                    elif analysis_type == 'review':
                        # ë¦¬ë·° ë¦¬í¬íŠ¸
                        analyzer = results['analyzer']
                        sentiment_counts = analyzer.df['sentiment'].value_counts().to_dict()

                        # ê°„ë‹¨í•œ ì¸ì‚¬ì´íŠ¸ ìƒì„±
                        total = len(analyzer.df)
                        positive_pct = (sentiment_counts.get('positive', 0) / total * 100) if total > 0 else 0
                        negative_pct = (sentiment_counts.get('negative', 0) / total * 100) if total > 0 else 0

                        insights = {
                            'key_findings': [
                                f"ì´ {total:,}ê°œì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
                                f"ê¸ì • ë¦¬ë·° ë¹„ìœ¨: {positive_pct:.1f}%",
                                f"ë¶€ì • ë¦¬ë·° ë¹„ìœ¨: {negative_pct:.1f}%"
                            ],
                            'action_items': [
                                "ê¸ì • ë¦¬ë·°ì˜ í‚¤ì›Œë“œë¥¼ ë§ˆì¼€íŒ…ì— í™œìš©í•˜ì„¸ìš”.",
                                "ë¶€ì • ë¦¬ë·°ì˜ ë¬¸ì œì ì„ ê°œì„ í•˜ì„¸ìš”."
                            ]
                        }

                        html_report = generator.generate_report(
                            analysis_type='review',
                            data_info={
                                'rows': len(analyzer.df),
                                'columns': len(analyzer.df.columns)
                            },
                            insights=insights,
                            charts=[]
                        )

                        st.download_button(
                            label="ğŸ“¥ ë¦¬ë·° ë¶„ì„ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                            data=html_report,
                            file_name=f"review_report_{pd.Timestamp.now().strftime('%Y%m%d')}.html",
                            mime="text/html",
                            use_container_width=True
                        )

                        st.success("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")

                    elif analysis_type == 'sales':
                        st.info("ğŸš§ íŒë§¤ ë¶„ì„ ë¦¬í¬íŠ¸ëŠ” DAY 29-31ì— ì¶”ê°€ë©ë‹ˆë‹¤")

                except Exception as e:
                    st.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    st.exception(e)


# ==================== ë©”ì¸ ====================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # CSS ë¡œë“œ
    load_custom_css()

    # ì„¸ì…˜ ì´ˆê¸°í™”
    SessionManager.init_session()

    # ì‚¬ì´ë“œë°”: ë„¤ë¹„ê²Œì´ì…˜
    with st.sidebar:
        st.markdown("## ğŸ“Š Auto-Insight")
        st.markdown("---")

        # í˜ì´ì§€ ì„ íƒ
        page = st.radio(
            "ë©”ë‰´",
            ["ğŸ  ì‹œì‘í•˜ê¸°", "ğŸ¤– ìë™ ë¶„ì„", "ğŸ” ìƒì„¸ íƒìƒ‰", "ğŸ“¥ ë‚´ë³´ë‚´ê¸°"],
            key="page_selector"
        )

        SessionManager.set_current_page(page)

        st.markdown("---")

        # ìƒˆë¡œ ì‹œì‘í•˜ê¸° ë²„íŠ¼
        if st.button("ğŸ”„ ìƒˆë¡œ ì‹œì‘í•˜ê¸°", use_container_width=True):
            SessionManager.clear_all()
            st.rerun()

        # í™˜ê²½ ì •ë³´ (ë””ë²„ê¹…ìš©)
        if st.checkbox("ğŸ”§ í™˜ê²½ ì •ë³´ í‘œì‹œ", key="show_env"):
            Environment.show_environment_info()

    # í˜ì´ì§€ ë¼ìš°íŒ…
    if page == "ğŸ  ì‹œì‘í•˜ê¸°":
        page_start()
    elif page == "ğŸ¤– ìë™ ë¶„ì„":
        page_auto_analysis()
    elif page == "ğŸ” ìƒì„¸ íƒìƒ‰":
        page_explore()
    elif page == "ğŸ“¥ ë‚´ë³´ë‚´ê¸°":
        page_export()


if __name__ == "__main__":
    main()
