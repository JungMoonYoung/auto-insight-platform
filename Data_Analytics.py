"""
Auto-Insight Platform - Multi-Page Version
AI ê¸°ë°˜ ìë™ ë°ì´í„° ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ

DAY 20: ë©€í‹° í˜ì´ì§€ êµ¬ì¡°ë¡œ ì „í™˜ (4ê°œ í˜ì´ì§€)
"""

import streamlit as st
import pandas as pd
import yaml
from pathlib import Path
import os
from dotenv import load_dotenv

# ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
from utils.session_manager import SessionManager
from utils.environment import Environment

# ëª¨ë“ˆ
from modules.data_loader import DataLoader
from modules.preprocessor import DataPreprocessor
from modules.rfm_analyzer import RFMAnalyzer
from modules.text_analyzer import TextAnalyzer
from modules.visualizer import Visualizer
from modules.report_generator import HTMLReportGenerator
from modules.insight_generator import InsightGenerator

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Auto-Insight Platform",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== CSS ìŠ¤íƒ€ì¼ ====================
def load_custom_css():
    """ì»¤ìŠ¤í…€ CSS ë¡œë“œ"""
    st.markdown("""
    <style>
        /* ë©”ì¸ ë°°ê²½ - ë‹¤í¬ */
        .main {
            background: #0a0e27;
            background-image:
                radial-gradient(at 47% 33%, hsl(240, 70%, 15%) 0, transparent 59%),
                radial-gradient(at 82% 65%, hsl(260, 50%, 20%) 0, transparent 55%);
            background-attachment: fixed;
        }

        /* ì»¨í…ì¸  ì˜ì—­ */
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
            background: rgba(20, 25, 45, 0.95);
            border-radius: 20px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.5);
            margin: 20px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }

        /* ì œëª© ìŠ¤íƒ€ì¼ */
        h1 {
            background: linear-gradient(135deg, #00f2fe 0%, #4facfe 50%, #f093fb 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 800;
            font-size: 3em !important;
            text-align: center;
            margin-bottom: 1rem;
        }

        h2 {
            color: #00f2fe;
            font-weight: 700;
            border-left: 5px solid #00f2fe;
            padding-left: 15px;
            margin-top: 2rem;
        }

        /* í…ìŠ¤íŠ¸ ìƒ‰ìƒ */
        p, label, .stMarkdown {
            color: rgba(255, 255, 255, 0.9) !important;
        }

        /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
        .stButton>button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-weight: 600;
            border: none;
            border-radius: 10px;
            padding: 0.75rem 1.5rem;
            transition: all 0.3s ease;
        }

        .stButton>button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(102, 126, 234, 0.4);
        }

        /* íƒ­ ìŠ¤íƒ€ì¼ */
        .stTabs [data-baseweb="tab-list"] {
            gap: 8px;
        }

        .stTabs [data-baseweb="tab"] {
            background-color: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
            color: rgba(255, 255, 255, 0.7);
            font-weight: 600;
        }

        .stTabs [aria-selected="true"] {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
    </style>
    """, unsafe_allow_html=True)


# ==================== í˜ì´ì§€ í•¨ìˆ˜ë“¤ ====================

def page_start():
    """í˜ì´ì§€ 1: ì‹œì‘í•˜ê¸° (ë°ì´í„° ì—…ë¡œë“œ & í¬ë¡¤ë§)"""
    st.markdown("### ë¶„ì„í•  ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”")

    # íƒ­ ìƒì„±
    tabs = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸŒ ì›¹ í¬ë¡¤ë§", "ğŸ“¦ ìƒ˜í”Œ ë°ì´í„°"])

    # Tab 1: íŒŒì¼ ì—…ë¡œë“œ
    with tabs[0]:
        render_file_upload()

    # Tab 2: ì›¹ í¬ë¡¤ë§
    with tabs[1]:
        render_crawling_ui()

    # Tab 3: ìƒ˜í”Œ ë°ì´í„°
    with tabs[2]:
        render_sample_data()

    # í•˜ë‹¨: ë°ì´í„° ì •ë³´ í‘œì‹œ
    if SessionManager.has_data():
        st.markdown("---")
        show_data_info()


def render_file_upload():
    """íŒŒì¼ ì—…ë¡œë“œ UI"""
    st.markdown("#### ğŸ“ CSV ë˜ëŠ” Excel íŒŒì¼ ì—…ë¡œë“œ")

    uploaded_file = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=['csv', 'xlsx', 'xls'],
        key="file_uploader"
    )

    if uploaded_file is not None:
        try:
            with st.spinner("ğŸ“‚ íŒŒì¼ì„ ì½ëŠ” ì¤‘..."):
                # íŒŒì¼ ë¡œë“œ (Streamlit UploadedFile ê°ì²´ëŠ” pandasë¡œ ì§ì ‘ ì½ê¸°)
                if uploaded_file.name.endswith('.csv'):
                    # CSV íŒŒì¼: ì¸ì½”ë”© ìë™ ê°ì§€
                    try:
                        df = pd.read_csv(uploaded_file, encoding='utf-8')
                    except UnicodeDecodeError:
                        uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                        df = pd.read_csv(uploaded_file, encoding='cp949')
                else:
                    # Excel íŒŒì¼
                    df = pd.read_excel(uploaded_file)

                # ì„¸ì…˜ì— ì €ì¥
                SessionManager.save_data(
                    data=df,
                    source='upload',
                    file_name=uploaded_file.name
                )

                st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: {uploaded_file.name}")

                # ë¯¸ë¦¬ë³´ê¸°
                st.markdown("##### ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)")
                st.dataframe(df.head(), use_container_width=True)

                # ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸
                with st.expander("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸"):
                    quality_report = DataLoader.get_data_quality_report(df)

                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("ì´ í–‰ ìˆ˜", f"{quality_report['total_rows']:,}")
                    col2.metric("ì´ ì»¬ëŸ¼ ìˆ˜", f"{quality_report['total_columns']:,}")
                    col3.metric("ê²°ì¸¡ì¹˜", f"{quality_report['total_missing']:,}")
                    col4.metric("ì¤‘ë³µ í–‰", f"{quality_report['duplicate_rows']:,}")

                    st.markdown("**ì»¬ëŸ¼ë³„ ì •ë³´**")
                    st.dataframe(quality_report['column_info'], use_container_width=True)

                st.info("ğŸ’¡ 'ìë™ ë¶„ì„' í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")

        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    else:
        st.info("ğŸ“¤ CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")


def render_crawling_ui():
    """í¬ë¡¤ë§ UI (í™˜ê²½ë³„ ë¶„ê¸°)"""
    st.markdown("#### ğŸŒ ì›¹ í¬ë¡¤ë§")

    if Environment.is_local():
        # ë¡œì»¬ í™˜ê²½: ì‹¤ì œ í¬ë¡¤ë§
        st.info("ğŸ’» ë¡œì»¬ í™˜ê²½: ì‹¤ì œ í¬ë¡¤ë§ ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥")

        # í¬ë¡¤ë§ ì†ŒìŠ¤ ì„ íƒ
        crawl_source = st.selectbox(
            "í¬ë¡¤ë§ ì†ŒìŠ¤ ì„ íƒ",
            ["ë„¤ì´ë²„ ì˜í™” ë¦¬ë·°", "ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·°"],
            key="crawl_source"
        )

        if crawl_source == "ë„¤ì´ë²„ ì˜í™” ë¦¬ë·°":
            render_movie_crawling()
        else:
            render_place_crawling()

    else:
        # ë°°í¬ í™˜ê²½: í¬ë¡¤ë§ ë¹„í™œì„±í™”
        st.warning("â˜ï¸ ë°°í¬ í™˜ê²½: í¬ë¡¤ë§ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.info("ğŸ’¡ 'ìƒ˜í”Œ ë°ì´í„°' íƒ­ì—ì„œ ë¯¸ë¦¬ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")


def render_movie_crawling():
    """ë„¤ì´ë²„ ì˜í™” í¬ë¡¤ë§ UI"""
    st.markdown("##### ğŸ¬ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° í¬ë¡¤ë§")

    col1, col2 = st.columns([3, 1])

    with col1:
        movie_url = st.text_input(
            "ì˜í™” URL ë˜ëŠ” ID",
            placeholder="https://movie.naver.com/movie/bi/mi/basic.nhn?code=215095",
            key="movie_url"
        )

    with col2:
        max_reviews = st.number_input(
            "ìˆ˜ì§‘í•  ë¦¬ë·° ìˆ˜",
            min_value=10,
            max_value=1000,
            value=100,
            step=10,
            key="max_reviews_movie"
        )

    if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", key="start_movie_crawl", use_container_width=True):
        if not movie_url:
            st.error("âŒ URL ë˜ëŠ” ì˜í™” IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        try:
            # URLì—ì„œ ì˜í™” ID ì¶”ì¶œ
            import re

            if 'code=' in movie_url:
                match = re.search(r'code=(\d+)', movie_url)
                movie_id = match.group(1) if match else None
            elif movie_url.isdigit():
                movie_id = movie_url
            else:
                st.error("âŒ ì˜¬ë°”ë¥¸ URL ë˜ëŠ” ì˜í™” IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                return

            if not movie_id:
                st.error("âŒ URLì—ì„œ ì˜í™” IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return

            st.info(f"ğŸ¬ ì˜í™” ID: {movie_id}")

            with st.spinner(f"ğŸ¤– ë„¤ì´ë²„ ì˜í™”ì—ì„œ {max_reviews}ê°œ ë¦¬ë·°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” ì¤‘..."):
                # ë²„ê·¸ #36 ìˆ˜ì •: í¬ë¡¤ëŸ¬ import ì‹¤íŒ¨ ì²˜ë¦¬
                try:
                    import sys
                    crawler_path = Path(__file__).parent / 'crawlers'
                    if str(crawler_path) not in sys.path:
                        sys.path.insert(0, str(crawler_path))

                    from naver_movie_crawler import NaverMovieCrawler
                except ImportError as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ğŸ’¡ crawlers/ í´ë”ì™€ naver_movie_crawler.py íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.info("ğŸ’¡ ë˜ëŠ” `pip install selenium webdriver-manager` ëª…ë ¹ìœ¼ë¡œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”.")
                    return
                except Exception as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    return

                # í¬ë¡¤ë§ ì‹¤í–‰
                crawler = NaverMovieCrawler(headless=True, delay=0.5)

                try:
                    df = crawler.crawl_reviews(movie_id, max_reviews=max_reviews)

                    if df is not None and len(df) > 0:
                        # ì»¬ëŸ¼ëª… ë§¤í•‘
                        df_mapped = df.rename(columns={
                            'review': 'text',
                            'score': 'rating'
                        })

                        # ì„¸ì…˜ì— ì €ì¥
                        SessionManager.save_data(
                            data=df_mapped,
                            data_type='review',
                            source='crawl_movie',
                            file_name=f'movie_{movie_id}_reviews.csv'
                        )

                        st.success(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
                        st.balloons()
                        # ë²„ê·¸ #35 ìˆ˜ì •: ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
                        import time
                        time.sleep(0.1)
                        st.rerun()
                    else:
                        st.error("âŒ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

                finally:
                    crawler.close()

        except Exception as e:
            st.error(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
            st.exception(e)


def render_place_crawling():
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ í¬ë¡¤ë§ UI"""
    st.markdown("##### ğŸª ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° í¬ë¡¤ë§")

    col1, col2 = st.columns([3, 1])

    with col1:
        place_url = st.text_input(
            "í”Œë ˆì´ìŠ¤ URL ë˜ëŠ” ID",
            placeholder="https://m.place.naver.com/restaurant/1234567890/review",
            key="place_url"
        )

    with col2:
        max_reviews = st.number_input(
            "ìˆ˜ì§‘í•  ë¦¬ë·° ìˆ˜",
            min_value=10,
            max_value=500,
            value=100,
            step=10,
            key="max_reviews_place"
        )

    if st.button("ğŸš€ í¬ë¡¤ë§ ì‹œì‘", key="start_place_crawl", use_container_width=True):
        if not place_url:
            st.error("âŒ URL ë˜ëŠ” í”Œë ˆì´ìŠ¤ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            return

        try:
            # URLì—ì„œ í”Œë ˆì´ìŠ¤ ID ì¶”ì¶œ
            import re

            patterns = [
                r'place\.naver\.com/[^/]+/(\d+)',
                r'pcmap\.place\.naver\.com/[^/]+/(\d+)',
                r'map\.naver\.com/[^/]+/place/(\d+)',
                r'/place/(\d+)',
                r'(\d{10,})',
            ]

            place_id = None
            for pattern in patterns:
                match = re.search(pattern, place_url)
                if match:
                    place_id = match.group(1)
                    break

            if not place_id and place_url.isdigit():
                place_id = place_url

            if not place_id:
                st.error("âŒ ì˜¬ë°”ë¥¸ URL ë˜ëŠ” í”Œë ˆì´ìŠ¤ IDë¥¼ ì…ë ¥í•˜ì„¸ìš”")
                return

            st.info(f"ğŸª í”Œë ˆì´ìŠ¤ ID: {place_id}")

            with st.spinner(f"ğŸ¤– ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ì—ì„œ {max_reviews}ê°œ ë¦¬ë·°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” ì¤‘..."):
                # ë²„ê·¸ #36 ìˆ˜ì •: í¬ë¡¤ëŸ¬ import ì‹¤íŒ¨ ì²˜ë¦¬
                try:
                    import sys
                    crawler_path = Path(__file__).parent / 'crawlers'
                    if str(crawler_path) not in sys.path:
                        sys.path.insert(0, str(crawler_path))

                    from naver_place_crawler import NaverPlaceCrawler
                except ImportError as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ğŸ’¡ crawlers/ í´ë”ì™€ naver_place_crawler.py íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.info("ğŸ’¡ ë˜ëŠ” `pip install selenium webdriver-manager` ëª…ë ¹ìœ¼ë¡œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•˜ì„¸ìš”.")
                    return
                except Exception as e:
                    st.error(f"âŒ í¬ë¡¤ëŸ¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    return

                # í¬ë¡¤ë§ ì‹¤í–‰
                crawler = NaverPlaceCrawler(headless=True, delay=0.5)

                try:
                    df = crawler.crawl_reviews(place_id, max_reviews=max_reviews)

                    if df is not None and len(df) > 0:
                        # ì»¬ëŸ¼ëª… ë§¤í•‘
                        df_mapped = df.rename(columns={
                            'review': 'text',
                            'rating': 'rating'
                        })

                        # ì„¸ì…˜ì— ì €ì¥
                        SessionManager.save_data(
                            data=df_mapped,
                            data_type='review',
                            source='crawl_place',
                            file_name=f'place_{place_id}_reviews.csv'
                        )

                        st.success(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
                        st.balloons()
                        # ë²„ê·¸ #35 ìˆ˜ì •: ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
                        import time
                        time.sleep(0.1)
                        st.rerun()
                    else:
                        st.error("âŒ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤")

                finally:
                    crawler.close()

        except Exception as e:
            st.error(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
            st.exception(e)


def render_sample_data():
    """ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ UI"""
    st.markdown("#### ğŸ“¦ ìƒ˜í”Œ ë°ì´í„°")

    if Environment.is_deployed():
        st.info("â˜ï¸ ë°°í¬ í™˜ê²½: ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í”Œë«í¼ì„ ì²´í—˜í•˜ì„¸ìš”")

    # ìƒ˜í”Œ ë°ì´í„° ëª©ë¡
    sample_files = Environment.list_sample_data()

    if not sample_files:
        st.warning("âš ï¸ ìƒ˜í”Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. sample_data/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # ìƒ˜í”Œ ë°ì´í„° ì„¤ëª…
    sample_descriptions = {
        'ecommerce_sample.csv': 'ğŸ›’ E-commerce ê±°ë˜ ë°ì´í„° (RFM ë¶„ì„ìš©)',
        'naver_movie_reviews.csv': 'ğŸ¬ ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°',
        'naver_place_reviews.csv': 'ğŸ“ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° ë°ì´í„°',
        'sales_sample.csv': 'ğŸ“Š íŒë§¤ ë°ì´í„° (ì‹œê³„ì—´ ë¶„ì„ìš©)'
    }

    # ì„ íƒ UI
    selected_file = st.selectbox(
        "ìƒ˜í”Œ ë°ì´í„° ì„ íƒ",
        sample_files,
        format_func=lambda x: sample_descriptions.get(x, x),
        key="sample_file"
    )

    if st.button("ğŸ“‚ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ", key="load_sample"):
        try:
            with st.spinner(f"ğŸ“‚ {selected_file} ë¡œë“œ ì¤‘..."):
                sample_path = os.path.join(Environment.get_sample_data_path(), selected_file)

                # DataLoader.load_file()ì„ ì‚¬ìš©í•˜ì—¬ CSV/Excel ìë™ ì²˜ë¦¬
                df = DataLoader.load_file(sample_path)

                # ë°ì´í„° íƒ€ì… ìë™ ê°ì§€
                if 'ecommerce' in selected_file:
                    data_type = 'ecommerce'
                elif 'movie' in selected_file or 'place' in selected_file:
                    data_type = 'review'
                elif 'sales' in selected_file:
                    data_type = 'sales'
                else:
                    data_type = None

                # ì„¸ì…˜ì— ì €ì¥
                SessionManager.save_data(
                    data=df,
                    data_type=data_type,
                    source='sample',
                    file_name=selected_file
                )

                st.success(f"âœ… ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {selected_file}")
                # ë²„ê·¸ #35 ìˆ˜ì •: ì„¸ì…˜ ìƒíƒœ ì €ì¥ ì™„ë£Œ ëŒ€ê¸°
                import time
                time.sleep(0.1)
                st.rerun()

        except Exception as e:
            st.error(f"âŒ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


def show_data_info():
    """ë°ì´í„° ì •ë³´ í‘œì‹œ"""
    info = SessionManager.get_data_info()

    st.success("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("íŒŒì¼ëª…", info['file_name'] or 'N/A')
    col2.metric("ë°ì´í„° ì†ŒìŠ¤", info['source'] or 'N/A')
    col3.metric("í–‰ ìˆ˜", f"{info['rows']:,}")
    col4.metric("ì»¬ëŸ¼ ìˆ˜", f"{info['columns']:,}")

    if info['data_type']:
        type_emoji = {
            'ecommerce': 'ğŸ›’',
            'review': 'ğŸ’¬',
            'sales': 'ğŸ“Š'
        }
        st.info(f"{type_emoji.get(info['data_type'], 'ğŸ“„')} ê°ì§€ëœ ë°ì´í„° íƒ€ì…: **{info['data_type']}**")


def page_auto_analysis():
    """í˜ì´ì§€ 2: ìë™ ë¶„ì„"""
    st.title("ğŸ¤– ìë™ ë¶„ì„")

    # ë°ì´í„° ì²´í¬
    if not SessionManager.has_data():
        st.warning("âš ï¸ ë¨¼ì € 'ì‹œì‘í•˜ê¸°' í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”")
        st.info("ğŸ’¡ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ  ì‹œì‘í•˜ê¸°' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”")
        return

    st.markdown("### ğŸ“Š ë°ì´í„° ê°œìš”")
    show_data_info()

    st.markdown("---")
    st.markdown("### ğŸ”§ ë¶„ì„ ì„¤ì •")

    # ë¶„ì„ íƒ€ì… ì„ íƒ (ìë™ ê°ì§€ or ìˆ˜ë™ ì„ íƒ)
    detected_type = SessionManager.get_data_type()

    if detected_type:
        type_names = {
            'ecommerce': 'E-commerce (RFM ë¶„ì„)',
            'review': 'ë¦¬ë·° ë¶„ì„ (ê°ì„± ë¶„ì„, í‚¤ì›Œë“œ ì¶”ì¶œ)',
            'sales': 'íŒë§¤ ë¶„ì„ (ì‹œê³„ì—´ ë¶„ì„)'
        }
        st.success(f"âœ… ìë™ ê°ì§€: **{type_names.get(detected_type)}**")
        analysis_type = detected_type
    else:
        analysis_type = st.radio(
            "ë¶„ì„ íƒ€ì… ì„ íƒ",
            ['ecommerce', 'review', 'sales'],
            format_func=lambda x: {
                'ecommerce': 'ğŸ›’ E-commerce (RFM ë¶„ì„)',
                'review': 'ğŸ’¬ ë¦¬ë·° ë¶„ì„ (ê°ì„± ë¶„ì„)',
                'sales': 'ğŸ“Š íŒë§¤ ë¶„ì„ (ì‹œê³„ì—´ ë¶„ì„)'
            }[x],
            horizontal=True
        )

    SessionManager.set_analysis_type(analysis_type)

    # GPT ì˜µì…˜ (ë¦¬ë·° ë¶„ì„ì¼ ë•Œë§Œ í‘œì‹œ)
    use_gpt = False
    if analysis_type == 'review':
        st.markdown("---")
        st.markdown("### ğŸ¤– GPT ê³ ê¸‰ ë¶„ì„ (ì„ íƒ)")

        # API í‚¤ ìƒíƒœ í™•ì¸
        from utils.api_key_manager import APIKeyManager
        api_status = APIKeyManager.get_api_key_status()

        if api_status['available'] and api_status['valid']:
            st.success(f"âœ… API í‚¤ ê°ì§€ë¨ (ì†ŒìŠ¤: {api_status['source']})")

            col1, col2 = st.columns([3, 1])
            with col1:
                use_gpt = st.checkbox(
                    "GPTë¡œ ê³ ê¸‰ ê°ì„± ë¶„ì„ ìˆ˜í–‰ (ë¶€ì • ë¦¬ë·° ì¤‘ì‹¬)",
                    value=False,
                    help="GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ ê°ì„± ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (ë¹„ìš© ë°œìƒ)"
                )
            with col2:
                if use_gpt:
                    # ì˜ˆìƒ ë¹„ìš© í‘œì‹œ
                    data = SessionManager.get_data()
                    est_reviews = min(len(data), 100)  # ìµœëŒ€ 100ê°œ
                    est_tokens = est_reviews * 100  # ë¦¬ë·°ë‹¹ ì•½ 100 í† í°
                    est_cost = APIKeyManager.estimate_cost(est_tokens, 'gpt-4o-mini')
                    st.info(f"ì˜ˆìƒ: ~${est_cost:.4f}")

        else:
            st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            with st.expander("ğŸ“– API í‚¤ ì„¤ì • ë°©ë²•"):
                st.markdown("""
**API í‚¤ë¥¼ ì–»ëŠ” ë°©ë²•:**
1. [OpenAI Platform](https://platform.openai.com/api-keys)ì— ì ‘ì†
2. API í‚¤ ìƒì„±
3. ë‹¤ìŒ ì¤‘ í•œ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ì„¤ì •:

**ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ (ê¶Œì¥)**
```bash
export OPENAI_API_KEY='sk-...'
```

**ë°©ë²• 2: .env íŒŒì¼**
```
OPENAI_API_KEY=sk-...
```

**ë°©ë²• 3: Streamlit Secrets (ë°°í¬ìš©)**
`.streamlit/secrets.toml` íŒŒì¼ ìƒì„±:
```toml
OPENAI_API_KEY = "sk-..."
```
                """)

    st.markdown("---")

    # ë¶„ì„ ì‹¤í–‰
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        run_analysis(analysis_type, use_gpt=use_gpt)

    # ê²°ê³¼ í‘œì‹œ
    if SessionManager.has_results():
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ë¶„ì„ ê²°ê³¼")
        show_analysis_results(analysis_type)


def run_analysis(analysis_type: str, use_gpt: bool = False):
    """ë¶„ì„ ì‹¤í–‰"""
    import time

    data = SessionManager.get_data()

    if analysis_type == 'ecommerce':
        run_ecommerce_analysis(data)
    elif analysis_type == 'review':
        run_review_analysis(data, use_gpt=use_gpt)
    elif analysis_type == 'sales':
        run_sales_analysis(data)


def run_ecommerce_analysis(df: pd.DataFrame):
    """E-commerce RFM ë¶„ì„ ì‹¤í–‰ (ìˆ˜ì •ë¨: ì´ì „ GPT ê²°ê³¼ ì´ˆê¸°í™” ì¶”ê°€)"""
    import time

    # [ì¶”ê°€ëœ ë¶€ë¶„] ìƒˆë¡œìš´ ë¶„ì„ ì‹œì‘ ì‹œ ì´ì „ GPT ê²°ê³¼ ì‚­ì œ
    if 'rfm_strategy' in st.session_state: del st.session_state['rfm_strategy']
    if 'rfm_simulation' in st.session_state: del st.session_state['rfm_simulation']

    try:
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['customerid', 'invoicedate', 'quantity', 'unitprice']
        df_cols_lower = [col.lower() for col in df.columns]

        missing_cols = [col for col in required_cols if col not in df_cols_lower]

        if missing_cols:
            st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_cols)}")
            st.info("ğŸ’¡ í•„ìš”í•œ ì»¬ëŸ¼: CustomerID, InvoiceDate, Quantity, UnitPrice")
            return

        # Progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()

        # 1. ì „ì²˜ë¦¬
        status_text.text("1/5 ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        progress_bar.progress(20)
        preprocessor = DataPreprocessor(df)
        processed_df, logs = (preprocessor
                             .normalize_column_names()
                             .handle_missing_values(strategy='drop')
                             .remove_duplicates()
                             .convert_date_columns(['invoicedate'])
                             .get_processed_data())

        # 2. RFM ë¶„ì„
        status_text.text("2/5 RFM ë¶„ì„ ì¤‘...")
        progress_bar.progress(40)
        rfm_analyzer = RFMAnalyzer(
            processed_df,
            customer_col='customerid',
            date_col='invoicedate',
            amount_col=None,
            quantity_col='quantity',
            price_col='unitprice'
        )
        rfm_df = rfm_analyzer.calculate_rfm()

        # 3. êµ°ì§‘í™”
        status_text.text("3/5 ê³ ê° ì„¸ë¶„í™” ì¤‘...")
        progress_bar.progress(60)
        optimal_k, metrics = rfm_analyzer.find_optimal_clusters()
        clustered_df = rfm_analyzer.perform_clustering()
        cluster_summary = rfm_analyzer.get_cluster_summary()

        # 4. ì‹œê°í™” ì¤€ë¹„
        status_text.text("4/5 ì‹œê°í™” ìƒì„± ì¤‘...")
        progress_bar.progress(80)

        # 5. ê²°ê³¼ ì €ì¥
        results = {
            'type': 'ecommerce',
            'rfm_df': rfm_df,
            'clustered_df': clustered_df,
            'cluster_summary': cluster_summary,
            'optimal_k': optimal_k,
            'metrics': metrics,
            'analyzer': rfm_analyzer
        }

        SessionManager.save_results(results)

        # ì™„ë£Œ
        progress_bar.progress(100)
        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()

        st.success("ğŸ‰ E-commerce ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.balloons()
        st.rerun()

    except Exception as e:
        SessionManager.clear_analysis()
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.exception(e)

def run_review_analysis(df: pd.DataFrame, use_gpt: bool = False):
    """ë¦¬ë·° ê°ì„± ë¶„ì„ ì‹¤í–‰ (ìˆ˜ì •ë¨: GPT ê²°ê³¼ ë³‘í•© ë¡œì§ ì¶”ê°€)"""
    import time
    import random

    try:
        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°
        text_col = None
        rating_col = None

        for col in df.columns:
            col_lower = col.lower()
            if 'review' in col_lower or 'text' in col_lower or 'comment' in col_lower:
                text_col = col
            if 'rating' in col_lower or 'score' in col_lower or 'point' in col_lower:
                rating_col = col

        if not text_col:
            st.error("âŒ ë¦¬ë·° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ í•„ìš”í•œ ì»¬ëŸ¼: review, text, comment ì¤‘ í•˜ë‚˜")
            return

        st.info(f"ğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼: **{text_col}**" + (f" | í‰ì  ì»¬ëŸ¼: **{rating_col}**" if rating_col else ""))

        # Progress bar
        total_steps = 6 if use_gpt else 5
        progress_bar = st.progress(0)
        status_text = st.empty()

        # 1. í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ì´ˆê¸°í™”
        status_text.text(f"1/{total_steps} í…ìŠ¤íŠ¸ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 1))
        analyzer = TextAnalyzer(df, text_column=text_col, rating_column=rating_col)

        # 2. ì „ì²˜ë¦¬
        status_text.text(f"2/{total_steps} í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 2))
        analyzer.preprocess_text()

        # 3. ê°ì„± ë¶„ì„ (ê¸°ë³¸ 1ì°¨ ë¶„ì„)
        status_text.text(f"3/{total_steps} ê¸°ë³¸ ê°ì„± ë¶„ì„ ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 3))
        analyzer.analyze_sentiment_simple()

        # 4. í‚¤ì›Œë“œ ì¶”ì¶œ
        status_text.text(f"4/{total_steps} í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        progress_bar.progress(int(100 / total_steps * 4))
        keywords = analyzer.extract_keywords(top_n=20)

        # 5. GPT ê³ ê¸‰ ë¶„ì„ (ì„ íƒ)
        gpt_results = None
        if use_gpt:
            status_text.text(f"5/{total_steps} GPTë¡œ ì •ë°€ ë¶„ì„ ë° ê²°ê³¼ ë³‘í•© ì¤‘...")
            progress_bar.progress(int(100 / total_steps * 5))

            try:
                from modules.gpt_analyzer import GPTAnalyzer
                from utils.api_key_manager import get_api_key

                api_key = get_api_key()
                if api_key:
                    gpt = GPTAnalyzer(api_key=api_key)

                    # --- [ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘] ë°ì´í„° ì¶”ì¶œ ë° ë§¤í•‘ ë¡œì§ ---
                    
                    # 1. ë¶„ì„ ëŒ€ìƒ ì„ ì • (ì—¬ê¸°ì„œ ì§ì ‘ ìƒ˜í”Œë§í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ë³´ì¡´í•¨)
                    # ë¶€ì •(negative)ì´ë‚˜ ì¤‘ë¦½(neutral)ì¸ ê²ƒë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ì¬ë¶„ì„
                    target_mask = analyzer.df['sentiment'].isin(['negative', 'neutral'])
                    target_indices = analyzer.df[target_mask].index.tolist()
                    
                    # ëŒ€ìƒì´ ë„ˆë¬´ ì ìœ¼ë©´ ì „ì²´ì—ì„œ ìƒ˜í”Œë§
                    if len(target_indices) < 10:
                         target_indices = analyzer.df.index.tolist()

                    # ìµœëŒ€ 50ê°œë¡œ ì œí•œ (ë¹„ìš© ê´€ë¦¬)
                    max_gpt_reviews = 500
                    if len(target_indices) > max_gpt_reviews:
                        target_indices = random.sample(target_indices, max_gpt_reviews)
                    
                    # ì„ íƒëœ ì¸ë±ìŠ¤ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    target_reviews_text = analyzer.df.loc[target_indices, text_col].astype(str).tolist()
                    
                    # 2. GPT ë¶„ì„ ìš”ì²­ (max_reviewsë¥¼ í…ìŠ¤íŠ¸ ê¸¸ì´ë§Œí¼ ì„¤ì •í•˜ì—¬ ë‚´ë¶€ ìƒ˜í”Œë§ ë°©ì§€)
                    gpt_sentiment_list = gpt.analyze_sentiment_batch(
                        reviews=target_reviews_text,
                        max_reviews=len(target_reviews_text), # ì´ë¯¸ ìœ„ì—ì„œ ì˜ëìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‹¤ ë¶„ì„
                        filter_negative=False # ìœ„ì—ì„œ ì´ë¯¸ í•„í„°ë§í–ˆìœ¼ë¯€ë¡œ False
                    )

                    # 3. ê²°ê³¼ë¥¼ ì›ë³¸ DataFrameì— ë³‘í•© (ë§¤ìš° ì¤‘ìš”!)
                    # GPT ë¶„ì„ ê²°ê³¼ ë“±ì„ ë‹´ì„ ì»¬ëŸ¼ ì´ˆê¸°í™”
                    if 'gpt_reason' not in analyzer.df.columns:
                        analyzer.df['gpt_reason'] = None
                    
                    update_count = 0
                    for idx, result in zip(target_indices, gpt_sentiment_list):
                        new_sentiment = result.get('sentiment')
                        reason = result.get('reason')
                        
                        if new_sentiment in ['positive', 'negative', 'neutral']:
                            # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ì—…ë°ì´íŠ¸
                            analyzer.df.loc[idx, 'sentiment'] = new_sentiment
                            analyzer.df.loc[idx, 'gpt_reason'] = reason
                            update_count += 1
                    
                    # --- [ìˆ˜ì •ëœ ë¶€ë¶„ ë] ---

                    # ë¹„ìš© ì •ë³´
                    cost_info = gpt.get_cost_info()
                    gpt_results = {
                        'sentiment': gpt_sentiment_list,
                        'cost': cost_info
                    }

                    st.success(f"âœ… GPT ë¶„ì„ ì™„ë£Œ! {update_count}ê°œ ë¦¬ë·° ì¬í‰ê°€ë¨ (ë¹„ìš©: ${cost_info['total_cost']:.4f})")
                else:
                    st.warning("âš ï¸ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ GPT ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

            except Exception as e:
                st.warning(f"âš ï¸ GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                traceback.print_exc()

        # 6. ê²°ê³¼ ì €ì¥
        results = {
            'type': 'review',
            'analyzer': analyzer, # ì—…ë°ì´íŠ¸ëœ dfê°€ í¬í•¨ëœ analyzer ê°ì²´ ì €ì¥
            'text_col': text_col,
            'rating_col': rating_col,
            'keywords': keywords,
            'gpt_results': gpt_results,
            'use_gpt': use_gpt
        }

        SessionManager.save_results(results)

        # ì™„ë£Œ
        progress_bar.progress(100)
        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()

        st.success("ğŸ‰ ë¦¬ë·° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.balloons()
        st.rerun()

    except Exception as e:
        SessionManager.clear_analysis()
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.exception(e)


def run_sales_analysis(df: pd.DataFrame):
    """íŒë§¤ ë¶„ì„ ì‹¤í–‰ (DAY 29-31 êµ¬í˜„)"""
    import time

    try:
        # í•„ìˆ˜ ì»¬ëŸ¼ ì°¾ê¸°
        date_col = None
        product_col = None
        quantity_col = None
        price_col = None

        for col in df.columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ['date', 'ë‚ ì§œ', 'ì¼ì']):
                date_col = col
            if any(keyword in col_lower for keyword in ['product', 'ìƒí’ˆ', 'ì œí’ˆ', 'item']):
                product_col = col
            if any(keyword in col_lower for keyword in ['quantity', 'ìˆ˜ëŸ‰', 'qty', 'amount']):
                quantity_col = col
            if any(keyword in col_lower for keyword in ['price', 'ê°€ê²©', 'ë‹¨ê°€', 'cost']):
                price_col = col

        # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
        missing_cols = []
        if not date_col: missing_cols.append('ë‚ ì§œ(date)')
        if not product_col: missing_cols.append('ìƒí’ˆëª…(product)')
        if not quantity_col: missing_cols.append('ìˆ˜ëŸ‰(quantity)')
        if not price_col: missing_cols.append('ê°€ê²©(price)')

        if missing_cols:
            st.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing_cols)}")
            st.info("ğŸ’¡ íŒë§¤ ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼: ë‚ ì§œ, ìƒí’ˆëª…, ìˆ˜ëŸ‰, ê°€ê²©")
            return

        st.info(f"ğŸ“Š ë¶„ì„ ì»¬ëŸ¼: ë‚ ì§œ={date_col}, ìƒí’ˆ={product_col}, ìˆ˜ëŸ‰={quantity_col}, ê°€ê²©={price_col}")

        # Progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()

        # 1. SalesAnalyzer ì´ˆê¸°í™”
        status_text.text("1/5 íŒë§¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")
        progress_bar.progress(20)
        from modules.sales_analyzer import SalesAnalyzer
        analyzer = SalesAnalyzer(
            df,
            date_column=date_col,
            product_column=product_col,
            quantity_column=quantity_col,
            price_column=price_col
        )

        # 2. ì¼ë³„/ì£¼ë³„/ì›”ë³„ ì§‘ê³„
        status_text.text("2/5 ì‹œê³„ì—´ ì§‘ê³„ ì¤‘...")
        progress_bar.progress(40)
        daily = analyzer.aggregate_by_period('D')
        weekly = analyzer.aggregate_by_period('W')
        monthly = analyzer.aggregate_by_period('M')

        # 3. ì´ë™í‰ê·  ê³„ì‚°
        status_text.text("3/5 ì´ë™í‰ê·  ê³„ì‚° ì¤‘...")
        progress_bar.progress(60)
        daily_ma = analyzer.calculate_moving_average(daily, 'sales', [7, 30])
        weekly_ma = analyzer.calculate_moving_average(weekly, 'sales', [4])
        monthly_ma = analyzer.calculate_moving_average(monthly, 'sales', [3])

        # 4. ì„±ì¥ë¥  ê³„ì‚°
        status_text.text("4/5 ì„±ì¥ë¥  ê³„ì‚° ì¤‘...")
        progress_bar.progress(80)
        daily_growth = analyzer.calculate_growth_rate(daily, 'sales', shift_periods=1)
        weekly_growth = analyzer.calculate_growth_rate(weekly, 'sales', shift_periods=1)
        monthly_growth = analyzer.calculate_growth_rate(monthly, 'sales', shift_periods=1)

        # 5. ìƒí’ˆ ë¶„ì„ (TOP 20, Pareto)
        status_text.text("5/5 ìƒí’ˆ ë¶„ì„ ì¤‘...")
        progress_bar.progress(90)
        top_products = analyzer.get_top_products(20, 'sales')
        pareto_df, pareto_summary = analyzer.analyze_pareto('sales')

        # ê²°ê³¼ ì €ì¥
        results = {
            'type': 'sales',
            'analyzer': analyzer,
            'daily': daily_ma,
            'weekly': weekly_ma,
            'monthly': monthly_ma,
            'daily_growth': daily_growth,
            'weekly_growth': weekly_growth,
            'monthly_growth': monthly_growth,
            'top_products': top_products,
            'pareto_df': pareto_df,
            'pareto_summary': pareto_summary,
            'columns': {
                'date': date_col,
                'product': product_col,
                'quantity': quantity_col,
                'price': price_col
            }
        }

        SessionManager.save_results(results)

        # ì™„ë£Œ
        progress_bar.progress(100)
        status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
        time.sleep(0.5)
        progress_bar.empty()
        status_text.empty()

        st.success("ğŸ‰ íŒë§¤ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.balloons()
        st.rerun()

    except ValueError as ve:
        SessionManager.clear_analysis()
        st.error(f"âŒ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {str(ve)}")
        st.info("ğŸ’¡ ë°ì´í„° í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš” (ë‚ ì§œ í˜•ì‹, ìˆ«ì í˜•ì‹ ë“±)")
    except Exception as e:
        SessionManager.clear_analysis()
        st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.exception(e)


def show_analysis_results(analysis_type: str):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    results = SessionManager.get_results()

    if results.get('type') == 'ecommerce':
        show_ecommerce_results(results)
    elif results.get('type') == 'review':
        show_review_results(results)
    elif results.get('type') == 'sales':
        show_sales_results(results)


def show_ecommerce_results(results):
    """E-commerce ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ìˆ˜ì •ë¨: ê¸°ì¡´ ê¸°ëŠ¥ + GPT ì „ëµ ê¸°ëŠ¥ í†µí•©)"""
    clustered_df = results['clustered_df']
    cluster_summary = results['cluster_summary']
    optimal_k = results['optimal_k']

    # 1. ìƒë‹¨ ë©”íŠ¸ë¦­ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ ê³ ê° ìˆ˜", f"{len(clustered_df):,}")
    with col2:
        st.metric("êµ°ì§‘ ê°œìˆ˜", optimal_k)
    with col3:
        if 'cluster_name' in clustered_df.columns:
            vip_count = len(clustered_df[clustered_df['cluster_name'].str.contains('VIP|ì¶©ì„±', na=False)])
        else:
            vip_count = 0
        st.metric("VIP/ì¶©ì„± ê³ ê°", f"{vip_count:,}")
    with col4:
        if 'cluster_name' in clustered_df.columns:
            risk_count = len(clustered_df[clustered_df['cluster_name'].str.contains('ì´íƒˆ|íœ´ë©´', na=False)])
        else:
            risk_count = 0
        st.metric("ì´íƒˆ ìœ„í—˜", f"{risk_count:,}")

    st.markdown("---")

    # 2. ì‹œê°í™” íƒ­
    visualizer = Visualizer()
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š RFM íˆíŠ¸ë§µ", "ğŸ“ˆ ê³ ê° ë¶„í¬", "ğŸ“‹ ë°ì´í„°"])

    with tab1:
        st.markdown("### RFM íˆíŠ¸ë§µ")
        fig_heatmap = visualizer.plot_rfm_heatmap(cluster_summary)
        st.plotly_chart(fig_heatmap, use_container_width=True)

        st.markdown("### êµ°ì§‘ë³„ ì§€í‘œ")
        fig_bar = visualizer.plot_cluster_bar_chart(cluster_summary)
        st.plotly_chart(fig_bar, use_container_width=True)

    with tab2:
        st.markdown("### ê³ ê° ê°€ì¹˜ í”¼ë¼ë¯¸ë“œ")
        fig_pyramid = visualizer.plot_customer_value_pyramid(cluster_summary)
        st.plotly_chart(fig_pyramid, use_container_width=True)

        st.markdown("### êµ°ì§‘ë³„ ê³ ê° ë¶„í¬")
        fig_pie = visualizer.plot_cluster_distribution_pie(cluster_summary)
        st.plotly_chart(fig_pie, use_container_width=True)

    with tab3:
        st.markdown("### êµ°ì§‘ë³„ ìƒì„¸ í†µê³„")
        st.dataframe(cluster_summary, use_container_width=True)

        st.markdown("### ê³ ê° ì„¸ë¶„í™” ë°ì´í„°")
        display_cols = []
        for check_col in ['customerid', 'cluster', 'cluster_name', 'Recency', 'Frequency', 'Monetary']:
            for col in clustered_df.columns:
                if col.lower() == check_col.lower() and col not in display_cols:
                    display_cols.append(col)
        
        st.dataframe(
            clustered_df[display_cols] if display_cols else clustered_df,
            use_container_width=True
        )

    # 3. [ê¸°ì¡´] ê·œì¹™ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ (ìœ ì§€ë¨)
    st.markdown("---")
    st.markdown("### ğŸ’¡ ê¸°ë³¸ ë¶„ì„ ì¸ì‚¬ì´íŠ¸")

    from modules.insight_generator import InsightGenerator
    generator = InsightGenerator()
    insights = generator.generate_rfm_insights(results['rfm_df'], cluster_summary)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**ì£¼ìš” ë°œê²¬ì‚¬í•­**")
        for finding in insights['key_findings']:
            st.info(finding)

    with col2:
        st.markdown("**ì•¡ì…˜ ì•„ì´í…œ**")
        for action in insights['action_items']:
            st.warning(action)

    # 4. [NEW] GPT ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ ì„¹ì…˜ (ì¶”ê°€ë¨)
    st.markdown("---")
    st.markdown("### ğŸ¤– GPT ë§ˆì¼€íŒ… ì „ëµ ì»¨ì„¤íŒ…")

    from utils.api_key_manager import get_api_key
    api_key = get_api_key()

    if api_key:
        m_col1, m_col2 = st.columns(2)
        
        with m_col1:
            if st.button("ğŸ“¢ ì„¸ê·¸ë¨¼íŠ¸ë³„ ë§ì¶¤ ì „ëµ ìƒì„±", use_container_width=True):
                with st.spinner("GPTê°€ ê³ ê° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë§ˆì¼€íŒ… ì „ëµì„ ìˆ˜ë¦½ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        from modules.gpt_analyzer import GPTAnalyzer
                        gpt = GPTAnalyzer(api_key=api_key)
                        strategy_text = gpt.generate_segment_strategy(results['cluster_summary'])
                        st.session_state['rfm_strategy'] = strategy_text
                    except Exception as e:
                        st.error(f"ì „ëµ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        with m_col2:
            if st.button("ğŸ’° ë§¤ì¶œ ì„±ì¥ ì‹œë®¬ë ˆì´ì…˜", use_container_width=True):
                with st.spinner("GPTê°€ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì˜ˆìƒ ë§¤ì¶œì„ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        from modules.gpt_analyzer import GPTAnalyzer
                        gpt = GPTAnalyzer(api_key=api_key)
                        simulation_text = gpt.simulate_revenue_growth(
                            results['rfm_df'], results['cluster_summary']
                        )
                        st.session_state['rfm_simulation'] = simulation_text
                    except Exception as e:
                        st.error(f"ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")

        # ê²°ê³¼ ì¶œë ¥
        if 'rfm_strategy' in st.session_state:
            with st.expander("ğŸ“‹ ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆì„œ ë³´ê¸°", expanded=True):
                st.markdown(st.session_state['rfm_strategy'])
            
        if 'rfm_simulation' in st.session_state:
            with st.expander("ğŸ“ˆ ë§¤ì¶œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ë³´ê¸°", expanded=True):
                st.success("GPTê°€ ì˜ˆì¸¡í•œ ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²°ê³¼ì…ë‹ˆë‹¤.")
                st.markdown(st.session_state['rfm_simulation'])

    else:
        st.warning("âš ï¸ GPT ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")


def show_review_results(results: dict):
    """ë¦¬ë·° ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    analyzer = results['analyzer']
    text_col = results['text_col']

    # ê°ì„± ë¶„í¬
    sentiment_counts = analyzer.df['sentiment'].value_counts()

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ ë¦¬ë·° ìˆ˜", f"{len(analyzer.df):,}")
    with col2:
        positive_pct = (sentiment_counts.get('positive', 0) / len(analyzer.df) * 100)
        st.metric("ê¸ì • ë¹„ìœ¨", f"{positive_pct:.1f}%")
    with col3:
        negative_pct = (sentiment_counts.get('negative', 0) / len(analyzer.df) * 100)
        st.metric("ë¶€ì • ë¹„ìœ¨", f"{negative_pct:.1f}%")

    st.markdown("---")

    # ì‹œê°í™”
    visualizer = Visualizer()
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ê°ì„± ë¶„ì„", "â˜ï¸ ì›Œë“œ í´ë¼ìš°ë“œ", "ğŸ“‹ ë°ì´í„°"])

    with tab1:
        st.markdown("### ê°ì„± ë¶„í¬")
        fig_sentiment = visualizer.plot_sentiment_distribution(analyzer.df)
        st.plotly_chart(fig_sentiment, use_container_width=True)

        st.markdown("### ê°ì„±ë³„ í‚¤ì›Œë“œ (Top 15)")
        keywords = results.get('keywords', {})
        if keywords:
            fig_keywords = visualizer.plot_keywords_comparison(keywords)
            st.plotly_chart(fig_keywords, use_container_width=True)
        else:
            st.info("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        st.markdown("### ì „ì²´ ì›Œë“œ í´ë¼ìš°ë“œ")
        try:
            # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
            from collections import Counter
            all_words = []
            if hasattr(analyzer, 'processed_texts') and analyzer.processed_texts:
                for tokens in analyzer.processed_texts:
                    if tokens:
                        all_words.extend(tokens.split())

            if all_words:
                word_freq = Counter(all_words).most_common(50)
                wordcloud_fig = visualizer.plot_word_cloud_data(word_freq, top_n=50)
                st.plotly_chart(wordcloud_fig, use_container_width=True)
            else:
                st.info("ì›Œë“œ í´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì›Œë“œ í´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

    with tab3:
        st.markdown("### ë¦¬ë·° ë°ì´í„°")
        display_cols = [text_col, 'sentiment']
        if 'rating' in analyzer.df.columns:
            display_cols.insert(1, 'rating')
        st.dataframe(analyzer.df[display_cols], use_container_width=True)


def show_sales_results(results: dict):
    """íŒë§¤ ë¶„ì„ ê²°ê³¼ í‘œì‹œ (DAY 29-31 êµ¬í˜„)"""

    # ê¸°ê°„ ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼
    st.markdown("### ğŸ“… ë¶„ì„ ê¸°ê°„ ì„ íƒ")
    period = st.radio(
        "ì§‘ê³„ ë‹¨ìœ„",
        options=['ì¼ë³„', 'ì£¼ë³„', 'ì›”ë³„'],
        horizontal=True,
        label_visibility='collapsed'
    )

    # ê¸°ê°„ë³„ ë°ì´í„° ì„ íƒ
    period_map = {'ì¼ë³„': 'daily', 'ì£¼ë³„': 'weekly', 'ì›”ë³„': 'monthly'}
    selected_period = period_map[period]

    df_display = results[selected_period]
    df_growth = results[f'{selected_period}_growth']

    # ìƒë‹¨ ë©”íŠ¸ë¦­ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        total_sales = df_display['sales'].sum()
        st.metric("ì´ ë§¤ì¶œ", f"{total_sales:,.0f}ì›")

    with col2:
        avg_sales = df_display['sales'].mean()
        st.metric(f"{period} í‰ê· ", f"{avg_sales:,.0f}ì›")

    with col3:
        top_products = results['top_products']
        st.metric("ë¶„ì„ ìƒí’ˆ ìˆ˜", f"{len(top_products):,}ê°œ")

    with col4:
        pareto_summary = results['pareto_summary']
        top_80_count = pareto_summary.get('top_80_pct_products', 0)
        st.metric("íŒŒë ˆí†  80% ë‹¬ì„±", f"{top_80_count}ê°œ")

    st.markdown("---")

    # 3ê°œ íƒ­ êµ¬ì„±
    from modules.visualizer import Visualizer
    visualizer = Visualizer()

    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ íŠ¸ë Œë“œ", "ğŸ† ìƒí’ˆ", "ğŸ’¡ ì¸ì‚¬ì´íŠ¸"])

    # ========== TAB 1: íŠ¸ë Œë“œ ë¶„ì„ ==========
    with tab1:
        st.markdown("### ë§¤ì¶œ íŠ¸ë Œë“œ")

        # ì´ë™í‰ê·  ì»¬ëŸ¼ ì°¾ê¸°
        ma_cols = [col for col in df_display.columns if 'ma_' in col]

        # íŠ¸ë Œë“œ ì°¨íŠ¸
        try:
            fig_trend = visualizer.plot_sales_trend(
                df_display,
                date_column='date',
                sales_column='sales',
                ma_columns=ma_cols if ma_cols else None,
                title=f'{period} ë§¤ì¶œ íŠ¸ë Œë“œ' + (' (ì´ë™í‰ê·  í¬í•¨)' if ma_cols else ''),
                currency='ì›'
            )
            st.plotly_chart(fig_trend, use_container_width=True)
        except Exception as e:
            st.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

        # ì„±ì¥ë¥  í…Œì´ë¸”
        st.markdown("### ì„±ì¥ë¥  ë¶„ì„")

        # ìµœê·¼ 10ê°œ ê¸°ê°„ë§Œ í‘œì‹œ
        growth_display = df_growth.tail(10).copy()
        growth_display = growth_display.sort_values('date', ascending=False)

        # ì»¬ëŸ¼ ì´ë¦„ ë³€ê²½
        display_cols = ['date', 'sales']
        if 'sales_growth' in growth_display.columns:
            display_cols.append('sales_growth')

        rename_map = {
            'date': 'ë‚ ì§œ',
            'sales': 'ë§¤ì¶œ',
            'sales_growth': 'ì„±ì¥ë¥ (%)'
        }

        growth_display_renamed = growth_display[display_cols].rename(columns=rename_map)

        # í¬ë§·íŒ…
        st.dataframe(
            growth_display_renamed.style.format({
                'ë§¤ì¶œ': '{:,.0f}ì›',
                'ì„±ì¥ë¥ (%)': '{:.1f}%'
            }),
            use_container_width=True
        )

    # ========== TAB 2: ìƒí’ˆ ë¶„ì„ ==========
    with tab2:
        st.markdown("### ìƒí’ˆ ë§¤ì¶œ ìˆœìœ„ TOP 20")

        top_products = results['top_products']

        # ìˆœìœ„ ì°¨íŠ¸
        try:
            fig_products = visualizer.plot_top_products_bar(
                top_products,
                product_column='product',
                sales_column='sales',
                top_n=20,
                title='ìƒí’ˆë³„ ë§¤ì¶œ ìˆœìœ„ TOP 20',
                currency='ì›'
            )
            st.plotly_chart(fig_products, use_container_width=True)
        except Exception as e:
            st.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

        st.markdown("---")
        st.markdown("### íŒŒë ˆí†  ë¶„ì„ (80-20 ë²•ì¹™)")

        # íŒŒë ˆí†  ì°¨íŠ¸
        pareto_df = results['pareto_df']

        try:
            fig_pareto = visualizer.plot_pareto_chart(
                pareto_df,
                product_column='product',
                sales_column='sales',
                cumulative_pct_column='cumulative_pct',
                top_n=30,
                threshold=80.0,
                title='íŒŒë ˆí†  ë¶„ì„ - ë§¤ì¶œ ê¸°ì—¬ë„',
                currency='ì›'
            )
            st.plotly_chart(fig_pareto, use_container_width=True)
        except Exception as e:
            st.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

        # íŒŒë ˆí†  ìš”ì•½
        st.info(f"""
        **íŒŒë ˆí†  ë²•ì¹™ ë¶„ì„ ê²°ê³¼**
        - ì „ì²´ ìƒí’ˆ: {pareto_summary['total_products']}ê°œ
        - ìƒìœ„ 20%({pareto_summary['top_20_pct_products']}ê°œ) â†’ ë§¤ì¶œ {pareto_summary['top_20_pct_contribution']:.1f}% ê¸°ì—¬
        - 80% ë§¤ì¶œ ë‹¬ì„±: {pareto_summary['top_80_pct_products']}ê°œ ìƒí’ˆìœ¼ë¡œ ê°€ëŠ¥
        """)

    # ========== TAB 3: ì¸ì‚¬ì´íŠ¸ ==========
    with tab3:
        st.markdown("### ğŸ“Š ìš”ì•½ í†µê³„")

        # ìš”ì•½ í†µê³„ ì¹´ë“œ
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**ë§¤ì¶œ í†µê³„**")
            st.metric("ì´ ë§¤ì¶œ", f"{total_sales:,.0f}ì›")
            st.metric("í‰ê·  ë§¤ì¶œ", f"{avg_sales:,.0f}ì›")
            st.metric("ìµœëŒ€ ë§¤ì¶œ", f"{df_display['sales'].max():,.0f}ì›")
            st.metric("ìµœì†Œ ë§¤ì¶œ", f"{df_display['sales'].min():,.0f}ì›")

        with col2:
            st.markdown("**ìƒí’ˆ í†µê³„**")
            st.metric("ì „ì²´ ìƒí’ˆ ìˆ˜", f"{len(top_products)}ê°œ")
            st.metric("ìƒìœ„ 20% ìƒí’ˆ", f"{pareto_summary['top_20_pct_products']}ê°œ")
            st.metric("80% ë§¤ì¶œ ë‹¬ì„± ìƒí’ˆ", f"{pareto_summary['top_80_pct_products']}ê°œ")

            # ì§‘ì¤‘ë„ ê³„ì‚° (ìƒìœ„ 20% ê¸°ì—¬ë„)
            concentration = pareto_summary['top_20_pct_contribution']
            if concentration > 80:
                insight = "ë§¤ìš° ì§‘ì¤‘ë¨ (ì†Œìˆ˜ ìƒí’ˆ ì˜ì¡´ë„ ë†’ìŒ)"
            elif concentration > 60:
                insight = "ì§‘ì¤‘ë¨ (í•µì‹¬ ìƒí’ˆ ê´€ë¦¬ í•„ìš”)"
            else:
                insight = "ë¶„ì‚°ë¨ (ë‹¤ì–‘í•œ ìƒí’ˆ ê¸°ì—¬)"
            st.metric("ë§¤ì¶œ ì§‘ì¤‘ë„", insight)

        st.markdown("---")
        st.markdown("### ğŸ’¡ ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸")

        # ì„±ì¥ë¥  ë¶„ì„
        if 'sales_growth' in df_growth.columns:
            recent_growth = df_growth['sales_growth'].dropna().tail(5)
            if not recent_growth.empty:
                avg_recent_growth = recent_growth.mean()

                if avg_recent_growth > 5:
                    growth_insight = f"âœ… ìµœê·¼ ì„±ì¥ì„¸ ì–‘í˜¸ (í‰ê·  {avg_recent_growth:.1f}% ìƒìŠ¹)"
                    growth_color = "green"
                elif avg_recent_growth > 0:
                    growth_insight = f"âš ï¸ ì™„ë§Œí•œ ì„±ì¥ (í‰ê·  {avg_recent_growth:.1f}% ìƒìŠ¹)"
                    growth_color = "blue"
                elif avg_recent_growth > -5:
                    growth_insight = f"âš ï¸ ì†Œí­ í•˜ë½ (í‰ê·  {avg_recent_growth:.1f}% í•˜ë½)"
                    growth_color = "orange"
                else:
                    growth_insight = f"âŒ ê¸‰ê²©í•œ í•˜ë½ (í‰ê·  {avg_recent_growth:.1f}% í•˜ë½)"
                    growth_color = "red"

                st.markdown(f"**ì„±ì¥ë¥  ì¶”ì„¸**: :{growth_color}[{growth_insight}]")

        # íŒŒë ˆí†  ì¸ì‚¬ì´íŠ¸
        if concentration > 80:
            st.warning(f"âš ï¸ **ë§¤ì¶œ ì§‘ì¤‘ë„ ë†’ìŒ**: ìƒìœ„ 20% ìƒí’ˆì´ {concentration:.1f}% ê¸°ì—¬ â†’ ë¦¬ìŠ¤í¬ ë¶„ì‚° í•„ìš”")
        elif concentration > 60:
            st.info(f"ğŸ’¡ **ì ì • ì§‘ì¤‘ë„**: ìƒìœ„ 20% ìƒí’ˆì´ {concentration:.1f}% ê¸°ì—¬ â†’ í•µì‹¬ ìƒí’ˆ ì§‘ì¤‘ ê´€ë¦¬")
        else:
            st.success(f"âœ… **ë¶„ì‚°í˜• êµ¬ì¡°**: ìƒìœ„ 20% ìƒí’ˆì´ {concentration:.1f}% ê¸°ì—¬ â†’ ë‹¤ì–‘í•œ ìƒí’ˆ í¬íŠ¸í´ë¦¬ì˜¤")

        # ìƒí’ˆ ë‹¤ì–‘ì„±
        if len(top_products) > 50:
            st.success(f"âœ… **ìƒí’ˆ ë‹¤ì–‘ì„± ë†’ìŒ**: {len(top_products)}ê°œ ìƒí’ˆ â†’ ì‹œì¥ ë‹ˆì¦ˆ ë‹¤ì–‘í™”")
        elif len(top_products) > 20:
            st.info(f"ğŸ’¡ **ì ì • ìƒí’ˆ ìˆ˜**: {len(top_products)}ê°œ ìƒí’ˆ â†’ ê´€ë¦¬ ê°€ëŠ¥í•œ ë²”ìœ„")
        else:
            st.warning(f"âš ï¸ **ìƒí’ˆ ë‹¤ì–‘ì„± ë¶€ì¡±**: {len(top_products)}ê°œ ìƒí’ˆë§Œ ì¡´ì¬ â†’ ìƒí’ˆ ë¼ì¸ì—… í™•ëŒ€ ê²€í† ")


def page_explore():
    """í˜ì´ì§€ 3: ìƒì„¸ íƒìƒ‰"""
    st.title("ğŸ” ìƒì„¸ íƒìƒ‰")

    # ê²°ê³¼ ì²´í¬
    if not SessionManager.has_results():
        st.warning("âš ï¸ ë¨¼ì € 'ìë™ ë¶„ì„' í˜ì´ì§€ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”")
        st.info("ğŸ’¡ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ¤– ìë™ ë¶„ì„' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”")
        return

    results = SessionManager.get_results()
    analysis_type = results.get('type')

    st.markdown("### ğŸ”§ í•„í„°ë§ ë° ê²€ìƒ‰")

    if analysis_type == 'ecommerce':
        render_ecommerce_filters(results)
    elif analysis_type == 'review':
        render_review_filters(results)
    elif analysis_type == 'sales':
        render_sales_filters(results)


def render_ecommerce_filters(results: dict):
    """E-commerce í•„í„°ë§ UI"""
    clustered_df = results.get('clustered_df')
    rfm_df = results.get('rfm_df')
    cluster_summary = results.get('cluster_summary')

    # RFM ë°ì´í„° ìš°ì„  ì‚¬ìš© (Recency, Frequency, Monetary ì»¬ëŸ¼ í¬í•¨)
    if rfm_df is not None and not rfm_df.empty:
        display_df = rfm_df
    elif clustered_df is not None and not clustered_df.empty:
        display_df = clustered_df
    else:
        st.error("âŒ ë¶„ì„ ê²°ê³¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì‚¬ì´ë“œë°” í•„í„°
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ” í•„í„° ì˜µì…˜")

        # êµ°ì§‘ ì„ íƒ (cluster_nameì´ ìˆëŠ” ê²½ìš°ë§Œ)
        if 'cluster_name' in display_df.columns:
            all_clusters = sorted(display_df['cluster_name'].unique())
            selected_clusters = st.multiselect(
                "êµ°ì§‘ ì„ íƒ",
                options=all_clusters,
                default=all_clusters,
                key="cluster_filter"
            )
        else:
            selected_clusters = None

        # RFM ë²”ìœ„ ìŠ¬ë¼ì´ë”
        st.markdown("**Recency ë²”ìœ„ (ì¼)**")
        # ë²„ê·¸ #34 ìˆ˜ì •: min == max ì²´í¬
        # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ì»¬ëŸ¼ ì°¾ê¸°
        recency_col = None
        for col in display_df.columns:
            if col.lower() == 'recency':
                recency_col = col
                break

        if recency_col is None:
            st.warning("âš ï¸ Recency ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            r_min, r_max = 0, 0
        else:
            r_min_val = int(display_df[recency_col].min())
            r_max_val = int(display_df[recency_col].max())
            if r_min_val < r_max_val:
                r_min, r_max = st.slider(
                    "Recency",
                    min_value=r_min_val,
                    max_value=r_max_val,
                    value=(r_min_val, r_max_val),
                    key="r_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ê³ ê°ì˜ Recency: {r_min_val}ì¼")
                r_min, r_max = r_min_val, r_max_val

        st.markdown("**Frequency ë²”ìœ„ (ê±´)**")
        # ë²„ê·¸ #34 ìˆ˜ì •: min == max ì²´í¬
        frequency_col = None
        for col in display_df.columns:
            if col.lower() == 'frequency':
                frequency_col = col
                break

        if frequency_col is None:
            st.warning("âš ï¸ Frequency ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            f_min, f_max = 0, 0
        else:
            f_min_val = int(display_df[frequency_col].min())
            f_max_val = int(display_df[frequency_col].max())
            if f_min_val < f_max_val:
                f_min, f_max = st.slider(
                    "Frequency",
                    min_value=f_min_val,
                    max_value=f_max_val,
                    value=(f_min_val, f_max_val),
                    key="f_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ê³ ê°ì˜ Frequency: {f_min_val}ê±´")
                f_min, f_max = f_min_val, f_max_val

        st.markdown("**Monetary ë²”ìœ„ (ì›)**")
        # ë²„ê·¸ #34 ìˆ˜ì •: min == max ì²´í¬
        monetary_col = None
        for col in display_df.columns:
            if col.lower() == 'monetary':
                monetary_col = col
                break

        if monetary_col is None:
            st.warning("âš ï¸ Monetary ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            m_min, m_max = 0, 0
        else:
            m_min_val = float(display_df[monetary_col].min())
            m_max_val = float(display_df[monetary_col].max())
            if m_min_val < m_max_val:
                m_min, m_max = st.slider(
                    "Monetary",
                    min_value=m_min_val,
                    max_value=m_max_val,
                    value=(m_min_val, m_max_val),
                    key="m_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ê³ ê°ì˜ Monetary: â‚©{m_min_val:,.0f}")
                m_min, m_max = m_min_val, m_max_val

    # í•„í„° ì ìš© (ë²„ê·¸ #38 ìˆ˜ì •: .copy() ì¶”ê°€)
    # RFM ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸ (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
    if recency_col is None or frequency_col is None or monetary_col is None:
        st.error("âŒ RFM ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        filtered_df = display_df.copy()
    elif selected_clusters is not None and 'cluster_name' in display_df.columns:
        # êµ°ì§‘ + RFM í•„í„°ë§
        filtered_df = display_df[
            (display_df['cluster_name'].isin(selected_clusters)) &
            (display_df[recency_col].between(r_min, r_max)) &
            (display_df[frequency_col].between(f_min, f_max)) &
            (display_df[monetary_col].between(m_min, m_max))
        ].copy()
    else:
        # RFMë§Œ í•„í„°ë§
        filtered_df = display_df[
            (display_df[recency_col].between(r_min, r_max)) &
            (display_df[frequency_col].between(f_min, f_max)) &
            (display_df[monetary_col].between(m_min, m_max))
        ].copy()

    # ê²€ìƒ‰
    search_query = st.text_input(
        "ğŸ” ê³ ê° ID ê²€ìƒ‰",
        placeholder="ê³ ê° ID ì…ë ¥...",
        key="customer_search"
    )

    if search_query:
        # ë²„ê·¸ #39 ìˆ˜ì •: regex ì´ìŠ¤ì¼€ì´í•‘ ì¶”ê°€
        import re
        escaped_query = re.escape(search_query)
        filtered_df = filtered_df[
            filtered_df['customerid'].astype(str).str.contains(escaped_query, case=False, na=False)
        ]

    # ê²°ê³¼ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    col1.metric("í•„í„°ë§ëœ ê³ ê° ìˆ˜", f"{len(filtered_df):,}")

    # ë²„ê·¸ #32, #33 ìˆ˜ì •: ZeroDivisionErrorì™€ ë¹ˆ DataFrame ì²´í¬
    if len(display_df) > 0:
        ratio = len(filtered_df) / len(display_df) * 100
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", f"{ratio:.1f}%")
    else:
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", "N/A")

    if len(filtered_df) > 0 and monetary_col and monetary_col in filtered_df.columns:
        col3.metric("ì´ ë§¤ì¶œì•¡", f"â‚©{filtered_df[monetary_col].sum():,.0f}")
    else:
        col3.metric("ì´ ë§¤ì¶œì•¡", "â‚©0")

    st.markdown("---")

    # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬
    if len(filtered_df) == 0:
        st.warning("âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ê³ ê°ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ ë³´ì„¸ìš”.")
    else:
        # ë°ì´í„° í…Œì´ë¸” - ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ
        display_cols = []
        for col in ['customerid']:
            if col in filtered_df.columns:
                display_cols.append(col)

        if recency_col and recency_col in filtered_df.columns:
            display_cols.append(recency_col)
        if frequency_col and frequency_col in filtered_df.columns:
            display_cols.append(frequency_col)
        if monetary_col and monetary_col in filtered_df.columns:
            display_cols.append(monetary_col)

        if 'cluster_name' in filtered_df.columns:
            display_cols.append('cluster_name')
        elif 'cluster' in filtered_df.columns:
            display_cols.append('cluster')

        st.dataframe(
            filtered_df[display_cols] if display_cols else filtered_df,
            use_container_width=True,
            height=400
        )

        # CSV ë‹¤ìš´ë¡œë“œ
        csv = filtered_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ í•„í„°ë§ëœ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"filtered_customers_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )


def render_review_filters(results):
    """ë¦¬ë·° í•„í„°ë§ UI (GPT ê²°ê³¼ ì‹œê°í™” ê°•í™” ë²„ì „)"""
    analyzer = results['analyzer']
    text_col = results['text_col']

    # ì‚¬ì´ë“œë°” í•„í„°
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ” í•„í„° ì˜µì…˜")

        # [NEW] GPT ë¶„ì„ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_gpt_data = 'gpt_reason' in analyzer.df.columns and analyzer.df['gpt_reason'].notna().any()
        
        show_only_gpt = False
        if has_gpt_data:
            st.success("ğŸ¤– GPT ë¶„ì„ ë°ì´í„° ê°ì§€ë¨")
            show_only_gpt = st.checkbox("GPTê°€ ë¶„ì„í•œ ë¦¬ë·°ë§Œ ë³´ê¸°", value=False)

        # ê°ì„± í•„í„°
        if 'sentiment' in analyzer.df.columns:
            all_sentiments = sorted(analyzer.df['sentiment'].unique())
            selected_sentiments = st.multiselect(
                "ê°ì„± ì„ íƒ",
                options=all_sentiments,
                default=all_sentiments,
                key="sentiment_filter"
            )
        else:
            selected_sentiments = []

        # í‰ì  ë²”ìœ„ (ìˆì„ ê²½ìš°)
        if 'rating' in analyzer.df.columns:
            st.markdown("**í‰ì  ë²”ìœ„**")
            rating_min_val = float(analyzer.df['rating'].min())
            rating_max_val = float(analyzer.df['rating'].max())
            
            if rating_min_val < rating_max_val:
                rating_min, rating_max = st.slider(
                    "Rating",
                    min_value=rating_min_val,
                    max_value=rating_max_val,
                    value=(rating_min_val, rating_max_val),
                    key="rating_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ë¦¬ë·°ì˜ í‰ì : {rating_min_val:.1f}")
                rating_min, rating_max = rating_min_val, rating_max_val
            
    # --- í•„í„°ë§ ë¡œì§ ---
    filtered_df = analyzer.df.copy()

    # 1. GPT í•„í„° (ì²´í¬ë°•ìŠ¤ ì„ íƒ ì‹œ)
    if show_only_gpt and has_gpt_data:
        filtered_df = filtered_df[filtered_df['gpt_reason'].notna()]

    # 2. ê°ì„± í•„í„°
    filtered_df = filtered_df[filtered_df['sentiment'].isin(selected_sentiments)]

    # 3. í‰ì  í•„í„°
    if 'rating' in analyzer.df.columns:
        filtered_df = filtered_df[filtered_df['rating'].between(rating_min, rating_max)]

    # 4. ê²€ìƒ‰ í•„í„°
    search_query = st.text_input(
        "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰",
        placeholder="ë¦¬ë·° ë‚´ìš© ê²€ìƒ‰... (ì˜ˆ: ë¹„ì‹¸ìš”, ë§›ì—†ì–´)",
        key="review_search"
    )

    if search_query:
        import re
        escaped_query = re.escape(search_query)
        filtered_df = filtered_df[
            filtered_df[text_col].astype(str).str.contains(escaped_query, case=False, na=False)
        ]

    # --- ê²°ê³¼ í‘œì‹œ ---
    col1, col2, col3 = st.columns(3)
    col1.metric("í•„í„°ë§ëœ ë¦¬ë·° ìˆ˜", f"{len(filtered_df):,}")

    if len(analyzer.df) > 0:
        ratio = len(filtered_df) / len(analyzer.df) * 100
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", f"{ratio:.1f}%")
    else:
        col2.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", "N/A")

    if 'rating' in analyzer.df.columns:
        if len(filtered_df) > 0:
            avg_rating = filtered_df['rating'].mean()
            col3.metric("í‰ê·  í‰ì ", f"{avg_rating:.2f}")
        else:
            col3.metric("í‰ê·  í‰ì ", "N/A")

    st.markdown("---")

    # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬
    if len(filtered_df) == 0:
        st.warning("âš ï¸ ì¡°ê±´ì— ë§ëŠ” ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ ì»¬ëŸ¼ ì„¤ì •
        display_cols = [text_col, 'sentiment']
        
        # í‰ì  ìˆìœ¼ë©´ ì¶”ê°€
        if 'rating' in analyzer.df.columns:
            display_cols.insert(1, 'rating')
        
        # GPT ì´ìœ ê°€ ìˆìœ¼ë©´ ë§¨ ë’¤ì— ì¶”ê°€
        if has_gpt_data:
            display_cols.append('gpt_reason')

        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ (GPT ì»¬ëŸ¼ ê°•ì¡°ëŠ” Streamlit ê¸°ë³¸ ê¸°ëŠ¥ìƒ ì–´ë µì§€ë§Œ ì»¬ëŸ¼ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥)
        st.dataframe(
            filtered_df[display_cols],
            use_container_width=True,
            height=500
        )

        # CSV ë‹¤ìš´ë¡œë“œ
        csv = filtered_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ í•„í„°ë§ëœ ë¦¬ë·° CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f"filtered_reviews_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )


def render_sales_filters(results: dict):
    """íŒë§¤ ë¶„ì„ í•„í„°ë§ UI (DAY 31 êµ¬í˜„)"""

    # ê¸°ê°„ë³„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸: ì¼ë³„)
    daily = results['daily']
    top_products = results['top_products']

    # ì‚¬ì´ë“œë°” í•„í„°
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ğŸ” í•„í„° ì˜µì…˜")

        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        if not daily.empty and 'date' in daily.columns:
            min_date = daily['date'].min()
            max_date = daily['date'].max()

            st.markdown("**ë‚ ì§œ ë²”ìœ„**")
            date_range = st.date_input(
                "ê¸°ê°„ ì„ íƒ",
                value=(min_date, max_date),
                min_value=min_date,
                max_value=max_date,
                key="date_range",
                label_visibility="collapsed"
            )

            if len(date_range) == 2:
                start_date, end_date = date_range
            else:
                start_date, end_date = min_date, max_date
        else:
            start_date, end_date = None, None

        # ë§¤ì¶œ ë²”ìœ„ ìŠ¬ë¼ì´ë”
        st.markdown("**ë§¤ì¶œ ë²”ìœ„**")
        if not daily.empty and 'sales' in daily.columns:
            sales_min = int(daily['sales'].min())
            sales_max = int(daily['sales'].max())

            if sales_min < sales_max:
                sales_range = st.slider(
                    "ë§¤ì¶œ",
                    min_value=sales_min,
                    max_value=sales_max,
                    value=(sales_min, sales_max),
                    format="â‚©%d",
                    key="sales_range",
                    label_visibility="collapsed"
                )
            else:
                st.info(f"ëª¨ë“  ë‚ ì§œì˜ ë§¤ì¶œ: {sales_min:,}ì›")
                sales_range = (sales_min, sales_max)
        else:
            sales_range = (0, 0)

    # í•„í„°ë§ ë¡œì§
    filtered_daily = daily.copy()

    # ë‚ ì§œ í•„í„°ë§
    if start_date and end_date and 'date' in filtered_daily.columns:
        filtered_daily = filtered_daily[
            (filtered_daily['date'].dt.date >= start_date) &
            (filtered_daily['date'].dt.date <= end_date)
        ]

    # ë§¤ì¶œ í•„í„°ë§
    if 'sales' in filtered_daily.columns:
        filtered_daily = filtered_daily[
            filtered_daily['sales'].between(sales_range[0], sales_range[1])
        ]

    # ìƒí’ˆ ê²€ìƒ‰
    search_query = st.text_input(
        "ğŸ” ìƒí’ˆ ê²€ìƒ‰",
        placeholder="ìƒí’ˆëª… ì…ë ¥... (ì˜ˆ: ë…¸íŠ¸ë¶)",
        key="product_search"
    )

    filtered_products = top_products.copy()
    if search_query:
        import re
        escaped_query = re.escape(search_query)
        filtered_products = filtered_products[
            filtered_products['product'].astype(str).str.contains(escaped_query, case=False, na=False)
        ]

    # ê²°ê³¼ ë©”íŠ¸ë¦­
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("í•„í„°ë§ëœ ê¸°ê°„", f"{len(filtered_daily):,}ì¼")

    with col2:
        if len(daily) > 0:
            ratio = len(filtered_daily) / len(daily) * 100
            st.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", f"{ratio:.1f}%")
        else:
            st.metric("ì „ì²´ ëŒ€ë¹„ ë¹„ìœ¨", "N/A")

    with col3:
        if not filtered_daily.empty and 'sales' in filtered_daily.columns:
            total_sales = filtered_daily['sales'].sum()
            st.metric("ì´ ë§¤ì¶œ", f"{total_sales:,.0f}ì›")
        else:
            st.metric("ì´ ë§¤ì¶œ", "0ì›")

    st.markdown("---")

    # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬
    if len(filtered_daily) == 0:
        st.warning("âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # íƒ­ìœ¼ë¡œ êµ¬ë¶„ í‘œì‹œ
        tab1, tab2 = st.tabs(["ğŸ“… ì¼ë³„ ë°ì´í„°", "ğŸ“¦ ìƒí’ˆ ë°ì´í„°"])

        with tab1:
            st.markdown("### ì¼ë³„ ë§¤ì¶œ ë°ì´í„°")
            # ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            display_daily = filtered_daily.sort_values('date', ascending=False)

            # ì»¬ëŸ¼ ì„ íƒ (date, sales, ì´ë™í‰ê· )
            display_cols = ['date', 'sales']
            for col in display_daily.columns:
                if 'ma_' in col:
                    display_cols.append(col)

            st.dataframe(
                display_daily[display_cols].style.format({
                    'sales': '{:,.0f}ì›',
                    **{col: '{:,.0f}ì›' for col in display_cols if 'ma_' in col}
                }),
                use_container_width=True
            )

        with tab2:
            st.markdown("### ìƒí’ˆë³„ ë§¤ì¶œ ë°ì´í„°")

            if len(filtered_products) == 0:
                st.warning(f"âš ï¸ '{search_query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(
                    filtered_products.style.format({
                        'sales': '{:,.0f}ì›',
                        'quantity': '{:,.0f}ê°œ'
                    }),
                    use_container_width=True
                )


def page_export():
    """í˜ì´ì§€ 4: ë‚´ë³´ë‚´ê¸° (ìˆ˜ì •ë¨: ì°¨íŠ¸ ìƒì„± ë¡œì§ ì¶”ê°€)"""
    st.title("ğŸ“¥ ë‚´ë³´ë‚´ê¸°")

    # ê²°ê³¼ ì²´í¬
    if not SessionManager.has_results():
        st.warning("âš ï¸ ë¨¼ì € 'ìë™ ë¶„ì„' í˜ì´ì§€ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”")
        st.info("ğŸ’¡ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ¤– ìë™ ë¶„ì„' í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”")
        return

    results = SessionManager.get_results()
    analysis_type = results.get('type')

    st.markdown("### ğŸ“¦ ë‹¤ìš´ë¡œë“œ ì˜µì…˜")

    col1, col2 = st.columns(2)

    # CSV ë‹¤ìš´ë¡œë“œ
    with col1:
        st.markdown("#### ğŸ“„ CSV ë‹¤ìš´ë¡œë“œ")

        if analysis_type == 'ecommerce':
            clustered_df = results['clustered_df']
            csv = clustered_df.to_csv(index=False, encoding='utf-8-sig')

            st.download_button(
                label="ğŸ“Š ê³ ê° ì„¸ë¶„í™” CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"rfm_analysis_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )

            st.info(f"ì´ {len(clustered_df):,}ê°œ ê³ ê° ë°ì´í„°")

        elif analysis_type == 'review':
            analyzer = results['analyzer']
            text_col = results['text_col']

            display_cols = [text_col, 'sentiment']
            if 'rating' in analyzer.df.columns:
                display_cols.insert(1, 'rating')

            csv = analyzer.df[display_cols].to_csv(index=False, encoding='utf-8-sig')

            st.download_button(
                label="ğŸ’¬ ë¦¬ë·° ê°ì„± ë¶„ì„ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"review_analysis_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )

            st.info(f"ì´ {len(analyzer.df):,}ê°œ ë¦¬ë·°")

        elif analysis_type == 'sales':
            daily = results['daily']
            top_products = results['top_products']

            # CSV ì¤€ë¹„ (ì¼ë³„ + ìƒí’ˆ ë°ì´í„°)
            csv_daily = daily.to_csv(index=False, encoding='utf-8-sig')
            csv_products = top_products.to_csv(index=False, encoding='utf-8-sig')

            st.download_button(
                label="ğŸ“Š ì¼ë³„ ë§¤ì¶œ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_daily,
                file_name=f"sales_daily_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )

            st.download_button(
                label="ğŸ“¦ ìƒí’ˆë³„ ë§¤ì¶œ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_products,
                file_name=f"sales_products_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )

            st.info(f"ì¼ë³„ ë°ì´í„°: {len(daily):,}ì¼ | ìƒí’ˆ ë°ì´í„°: {len(top_products):,}ê°œ")

    # HTML ë¦¬í¬íŠ¸
    with col2:
        st.markdown("#### ğŸ“Š HTML ë¦¬í¬íŠ¸")

        if st.button("ğŸ“‘ ë¦¬í¬íŠ¸ ìƒì„±", use_container_width=True):
            with st.spinner("ğŸ“Š ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ë§Œë“œëŠ” ì¤‘..."):
                try:
                    generator = HTMLReportGenerator()
                    visualizer = Visualizer() # ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ì¸ìŠ¤í„´ìŠ¤
                    
                    # [NEW] GPT ë¶„ì„ ë‚´ìš© ìˆ˜ì§‘
                    gpt_content = ""
                    if 'rfm_strategy' in st.session_state:
                        gpt_content += "### ğŸ“¢ ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ\n\n" + st.session_state['rfm_strategy'] + "\n\n---\n\n"
                    if 'rfm_simulation' in st.session_state:
                        gpt_content += "### ğŸ’° ë§¤ì¶œ ì„±ì¥ ì‹œë®¬ë ˆì´ì…˜\n\n" + st.session_state['rfm_simulation']
                    
                    # [NEW] ì°¨íŠ¸ ì¬ìƒì„± ë¡œì§
                    charts = []

                    if analysis_type == 'ecommerce':
                        # E-commerce ì°¨íŠ¸ 4ì¢… ì¬ìƒì„±
                        charts.append(visualizer.plot_rfm_heatmap(results['cluster_summary']))
                        charts.append(visualizer.plot_cluster_bar_chart(results['cluster_summary']))
                        charts.append(visualizer.plot_customer_value_pyramid(results['cluster_summary']))
                        charts.append(visualizer.plot_cluster_distribution_pie(results['cluster_summary']))

                        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
                        from modules.insight_generator import InsightGenerator
                        insight_gen = InsightGenerator()
                        insights = insight_gen.generate_rfm_insights(
                            results['rfm_df'],
                            results['cluster_summary']
                        )

                        html_report = generator.generate_report(
                            analysis_type='ecommerce',
                            data_info={
                                'rows': len(results['clustered_df']),
                                'columns': len(results['clustered_df'].columns),
                                'customers': len(results['clustered_df'])
                            },
                            insights=insights,
                            charts=charts, # ìƒì„±ëœ ì°¨íŠ¸ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                            gpt_analysis=gpt_content
                        )

                        st.download_button(
                            label="ğŸ“¥ E-commerce ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                            data=html_report,
                            file_name=f"ecommerce_report_{pd.Timestamp.now().strftime('%Y%m%d')}.html",
                            mime="text/html",
                            use_container_width=True
                        )

                    elif analysis_type == 'review':
                        analyzer = results['analyzer']
                        
                        # ë¦¬ë·° ì°¨íŠ¸ ì¬ìƒì„±
                        charts.append(visualizer.plot_sentiment_distribution(analyzer.df))
                        
                        keywords = results.get('keywords', {})
                        if keywords:
                            charts.append(visualizer.plot_keywords_comparison(keywords))

                        # ì›Œë“œí´ë¼ìš°ë“œ ë°ì´í„°ê°€ ìˆë‹¤ë©´ (ì´ê±´ ì´ë¯¸ì§€ë¼ ë³µì¡í•  ìˆ˜ ìˆì–´ ì¼ë‹¨ ìƒëµí•˜ê±°ë‚˜ ë¹ˆë„ìˆ˜ ì°¨íŠ¸ë¡œ ëŒ€ì²´)
                        # ì—¬ê¸°ì„œëŠ” ê°ì„± ë¶„í¬ì™€ í‚¤ì›Œë“œ ì°¨íŠ¸ 2ê°œë§Œ ë„£ìŒ

                        sentiment_counts = analyzer.df['sentiment'].value_counts().to_dict()
                        total = len(analyzer.df)
                        positive_pct = (sentiment_counts.get('positive', 0) / total * 100) if total > 0 else 0
                        negative_pct = (sentiment_counts.get('negative', 0) / total * 100) if total > 0 else 0

                        insights = {
                            'key_findings': [
                                f"ì´ {total:,}ê°œì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
                                f"ê¸ì • ë¦¬ë·° ë¹„ìœ¨: {positive_pct:.1f}%",
                                f"ë¶€ì • ë¦¬ë·° ë¹„ìœ¨: {negative_pct:.1f}%"
                            ],
                            'action_items': [
                                "ê¸ì • ë¦¬ë·°ì˜ í‚¤ì›Œë“œë¥¼ ë§ˆì¼€íŒ…ì— í™œìš©í•˜ì„¸ìš”.",
                                "ë¶€ì • ë¦¬ë·°ì˜ ë¬¸ì œì ì„ ê°œì„ í•˜ì„¸ìš”."
                            ]
                        }
                        
                        # GPT ë‚´ìš© ì¶”ê°€ (ë¦¬ë·°ìš©)
                        if results.get('use_gpt'):
                             gpt_content += "### ğŸ¤– GPT ê°ì„± ë¶„ì„ ìš”ì•½\n\nGPTë¥¼ í™œìš©í•˜ì—¬ ë¶€ì • ë¦¬ë·°ì— ëŒ€í•œ ì •ë°€ ë¶„ì„ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤."

                        html_report = generator.generate_report(
                            analysis_type='review',
                            data_info={
                                'rows': len(analyzer.df),
                                'columns': len(analyzer.df.columns)
                            },
                            insights=insights,
                            charts=charts, # ìƒì„±ëœ ì°¨íŠ¸ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                            gpt_analysis=gpt_content
                        )

                        st.download_button(
                            label="ğŸ“¥ ë¦¬ë·° ë¶„ì„ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                            data=html_report,
                            file_name=f"review_report_{pd.Timestamp.now().strftime('%Y%m%d')}.html",
                            mime="text/html",
                            use_container_width=True
                        )

                    elif analysis_type == 'sales':
                        # íŒë§¤ ë¶„ì„ ì°¨íŠ¸ 3ì¢… ì¬ìƒì„±
                        daily = results['daily']
                        top_products = results['top_products']
                        pareto_df = results['pareto_df']

                        # ì´ë™í‰ê·  ì»¬ëŸ¼ ì°¾ê¸°
                        ma_cols = [col for col in daily.columns if 'ma_' in col]

                        charts.append(visualizer.plot_sales_trend(
                            daily,
                            date_column='date',
                            sales_column='sales',
                            ma_columns=ma_cols if ma_cols else None,
                            title='ì¼ë³„ ë§¤ì¶œ íŠ¸ë Œë“œ',
                            currency='ì›'
                        ))

                        charts.append(visualizer.plot_top_products_bar(
                            top_products,
                            product_column='product',
                            sales_column='sales',
                            top_n=20,
                            title='ìƒí’ˆë³„ ë§¤ì¶œ ìˆœìœ„ TOP 20',
                            currency='ì›'
                        ))

                        charts.append(visualizer.plot_pareto_chart(
                            pareto_df,
                            product_column='product',
                            sales_column='sales',
                            cumulative_pct_column='cumulative_pct',
                            top_n=30,
                            threshold=80.0,
                            title='íŒŒë ˆí†  ë¶„ì„ - ë§¤ì¶œ ê¸°ì—¬ë„',
                            currency='ì›'
                        ))

                        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
                        pareto_summary = results['pareto_summary']
                        total_sales = daily['sales'].sum()
                        avg_sales = daily['sales'].mean()

                        insights = {
                            'key_findings': [
                                f"ì´ ë§¤ì¶œ: {total_sales:,.0f}ì› (í‰ê·  ì¼ ë§¤ì¶œ: {avg_sales:,.0f}ì›)",
                                f"ë¶„ì„ ê¸°ê°„: {len(daily):,}ì¼",
                                f"ì „ì²´ ìƒí’ˆ ìˆ˜: {pareto_summary['total_products']}ê°œ",
                                f"ìƒìœ„ 20% ìƒí’ˆì´ ë§¤ì¶œì˜ {pareto_summary['top_20_pct_contribution']:.1f}% ê¸°ì—¬"
                            ],
                            'action_items': [
                                "í•µì‹¬ ìƒí’ˆ(ìƒìœ„ 20%)ì— ëŒ€í•œ ì¬ê³  ê´€ë¦¬ ê°•í™”",
                                "íŒŒë ˆí†  80% ë‹¬ì„± ìƒí’ˆ ì§‘ì¤‘ ë§ˆì¼€íŒ…",
                                "ì €ì„±ê³¼ ìƒí’ˆì— ëŒ€í•œ í”„ë¡œëª¨ì…˜ ê²€í† ",
                                "ì„±ì¥ë¥  ì¶”ì„¸ ëª¨ë‹ˆí„°ë§ ë° ì˜ˆì¸¡"
                            ]
                        }

                        html_report = generator.generate_report(
                            analysis_type='sales',
                            data_info={
                                'rows': len(daily),
                                'columns': len(top_products)
                            },
                            insights=insights,
                            charts=charts,
                            gpt_analysis=gpt_content
                        )

                        st.download_button(
                            label="ğŸ“¥ íŒë§¤ ë¶„ì„ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                            data=html_report,
                            file_name=f"sales_report_{pd.Timestamp.now().strftime('%Y%m%d')}.html",
                            mime="text/html",
                            use_container_width=True
                        )

                    st.success("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")

                except Exception as e:
                    st.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    st.exception(e)

# ==================== ë©”ì¸ ====================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # CSS ë¡œë“œ
    load_custom_css()

    # ì„¸ì…˜ ì´ˆê¸°í™”
    SessionManager.init_session()

    # ì‚¬ì´ë“œë°”: ë„¤ë¹„ê²Œì´ì…˜
    with st.sidebar:
        st.markdown("## ğŸ“Š Auto-Insight")
        st.markdown("---")

        # í˜ì´ì§€ ì„ íƒ
        page = st.radio(
            "ë©”ë‰´",
            ["ğŸ  ì‹œì‘í•˜ê¸°", "ğŸ¤– ìë™ ë¶„ì„", "ğŸ” ìƒì„¸ íƒìƒ‰", "ğŸ“¥ ë‚´ë³´ë‚´ê¸°"],
            key="page_selector"
        )

        SessionManager.set_current_page(page)

        st.markdown("---")

        # ìƒˆë¡œ ì‹œì‘í•˜ê¸° ë²„íŠ¼
        if st.button("ğŸ”„ ìƒˆë¡œ ì‹œì‘í•˜ê¸°", use_container_width=True):
            SessionManager.clear_all()
            st.rerun()

        # í™˜ê²½ ì •ë³´ (ë””ë²„ê¹…ìš©)
        if st.checkbox("ğŸ”§ í™˜ê²½ ì •ë³´ í‘œì‹œ", key="show_env"):
            Environment.show_environment_info()

    # í˜ì´ì§€ ë¼ìš°íŒ…
    if page == "ğŸ  ì‹œì‘í•˜ê¸°":
        page_start()
    elif page == "ğŸ¤– ìë™ ë¶„ì„":
        page_auto_analysis()
    elif page == "ğŸ” ìƒì„¸ íƒìƒ‰":
        page_explore()
    elif page == "ğŸ“¥ ë‚´ë³´ë‚´ê¸°":
        page_export()


if __name__ == "__main__":
    main()
