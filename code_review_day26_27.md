# DAY 26-27 ë¹„íŒì  ì½”ë“œ ë¦¬ë·°

## ì‘ì„±ì¼: 2025-02-04

---

## âš ï¸ ì¹˜ëª…ì  ë¬¸ì œ (Critical Issues)

### 1. **ColumnMapper: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìœ„í—˜** (column_mapper.py:540-554)
```python
for user_col in df.columns:
    try:
        analysis = self.analyze_column_data(df, user_col)  # â† ë§¤ë²ˆ ì „ì²´ ì»¬ëŸ¼ ë¶„ì„
        type_scores = self.infer_column_type(df, user_col, analysis)
```

**ë¬¸ì œì :**
- `hybrid_map_columns()` í˜¸ì¶œ ì‹œ **ëª¨ë“  ì»¬ëŸ¼ì„ ì „ë¶€ ë¶„ì„**
- 100ê°œ ì»¬ëŸ¼ DataFrameì´ë©´ **100ë²ˆ ë°˜ë³µ**
- ê° ì»¬ëŸ¼ë§ˆë‹¤ ë‚ ì§œ íŒŒì‹± ì‹œë„ (pd.to_datetime 10ê°œ ìƒ˜í”Œ)
- **ëŒ€ìš©ëŸ‰ ë°ì´í„° (1000+ ì»¬ëŸ¼)ì—ì„œ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥**

**ì˜í–¥:**
- 1000ê°œ ì»¬ëŸ¼ Ã— 10ê°œ ìƒ˜í”Œ = 10,000ë²ˆ íŒŒì‹± ì—°ì‚°
- ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: 10~30ì´ˆ (ì‚¬ìš©ì ê²½í—˜ ì €í•˜)

**í•´ê²° ë°©ì•ˆ:**
- ì»¬ëŸ¼ ìˆ˜ ì œí•œ ë˜ëŠ” ì§„í–‰ë°” í‘œì‹œ
- ìºì‹± ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€
- ë³‘ë ¬ ì²˜ë¦¬ (multiprocessing)

---

### 2. **GPTAnalyzer: filter_negative íŒŒë¼ë¯¸í„° ë¯¸ì‚¬ìš©** (gpt_analyzer.py:130-149)
```python
def analyze_sentiment_batch(self, reviews: List[str], max_reviews: int = 100,
                            filter_negative: bool = False) -> List[Dict]:
    """ë¶€ì • ë¦¬ë·°ë§Œ ë¶„ì„ (ë¹„ìš© ìµœì í™”)"""
    # ...
    # filter_negative íŒŒë¼ë¯¸í„°ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ!
```

**ë¬¸ì œì :**
- `filter_negative=True`ë¡œ í˜¸ì¶œí•´ë„ **ì•„ë¬´ ë™ì‘ ì•ˆ í•¨**
- `_filter_negative_reviews()` ë©”ì„œë“œëŠ” ì‘ì„±í–ˆì§€ë§Œ **í˜¸ì¶œí•˜ì§€ ì•ŠìŒ**
- ë¹„ìš© ì ˆê° ê¸°ëŠ¥ì´ **ì‹¤ì œë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ**

**í•´ê²° ë°©ì•ˆ:**
```python
if filter_negative:
    # DataFrameì„ ë°›ì•„ì•¼ í•˜ë¯€ë¡œ ì¸í„°í˜ì´ìŠ¤ ë³€ê²½ í•„ìš”
    reviews = self._filter_negative_reviews(df, ...)
```

---

## ğŸ› ì‹¬ê°í•œ ë²„ê·¸ (Major Bugs)

### 3. **ColumnMapper: íƒ€ì… ìš°ì„ ìˆœìœ„ ì¶©ëŒ** (column_mapper.py:436-443)
```python
# ìš°ì„ ìˆœìœ„ 1: ë‚ ì§œ (ê°€ì¥ ëª…í™•í•œ íƒ€ì…)
if analysis['is_date']:
    scores['date'] = self.SCORE_HIGH
    scores['id'] = 0  # â† ë‹¤ë¥¸ íƒ€ì… ëª¨ë‘ 0ìœ¼ë¡œ ì„¤ì •
    scores['numeric'] = 0
    scores['rating'] = 0
    scores['text'] = 0
    return scores  # ì¡°ê¸° ë°˜í™˜
```

**ë¬¸ì œì :**
- ë‚ ì§œë¡œ ì¸ì‹ë˜ë©´ **ë¬´ì¡°ê±´ ë‚ ì§œë§Œ 100% ê°€ëŠ¥**ìœ¼ë¡œ íŒì •
- ì‹¤ì œë¡œëŠ” **ë‚ ì§œì´ë©´ì„œ IDì¼ ìˆ˜ ìˆìŒ** (ì˜ˆ: '2024-01-01-001' í˜•ì‹ ì£¼ë¬¸ë²ˆí˜¸)
- ë„ˆë¬´ **ì—„ê²©í•œ ìš°ì„ ìˆœìœ„**ë¡œ ìœ ì—°ì„± ë¶€ì¡±

**ì‹œë‚˜ë¦¬ì˜¤:**
- ì»¬ëŸ¼: `order_date_id` = `['2024-01-01', '2024-01-02', ...]`
- ê³ ìœ ê°’ 100% (is_id=True)
- ë‚ ì§œ íŒŒì‹± ê°€ëŠ¥ (is_date=True)
- ê²°ê³¼: **ë¬´ì¡°ê±´ dateë¡œë§Œ ì¸ì‹**, ID ê°€ëŠ¥ì„± ë¬´ì‹œ

**í•´ê²° ë°©ì•ˆ:**
- ì¡°ê¸° ë°˜í™˜ ëŒ€ì‹  **ì ìˆ˜ ê°€ì¤‘ì¹˜ ì¡°ì •**
- ë‚ ì§œ 90ì , ID 30ì  (ë‚®ì§€ë§Œ 0ì€ ì•„ë‹˜)

---

### 4. **GPTAnalyzer: ë¹„ìš© ì¶”ì  ì •í™•ë„ ë‚®ìŒ** (gpt_analyzer.py:72-75)
```python
# gpt-4o-mini ê°€ê²©: $0.15/1M input, $0.6/1M output
input_cost = (response.usage.prompt_tokens / 1_000_000) * 0.15
output_cost = (response.usage.completion_tokens / 1_000_000) * 0.6
```

**ë¬¸ì œì :**
- **í•˜ë“œì½”ë”©ëœ ê°€ê²©** (ëª¨ë¸ë³„ ê°€ê²© ë³€ê²½ ì‹œ ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš”)
- **ëª¨ë¸ ë³€ê²½ ì‹œ ê°€ê²© ë™ê¸°í™” ì•ˆ ë¨**
  - `GPTAnalyzer(model="gpt-4")`ë¡œ ë³€ê²½í•´ë„ **gpt-4o-mini ê°€ê²©ìœ¼ë¡œ ê³„ì‚°**
  - ì‹¤ì œ ë¹„ìš©ì˜ **1/10 ì´í•˜ë¡œ í‘œì‹œë¨** (ìœ„í—˜!)

**í•´ê²° ë°©ì•ˆ:**
```python
PRICING = {
    'gpt-4o-mini': (0.15, 0.6),
    'gpt-4': (30.0, 60.0),
    'gpt-4-turbo': (10.0, 30.0)
}
input_price, output_price = PRICING.get(self.model, (0, 0))
```

---

## âš¡ ì„±ëŠ¥ ë¬¸ì œ (Performance Issues)

### 5. **ColumnMapper: ì´ì¤‘ ë£¨í”„ O(NÃ—M) ë³µì¡ë„** (column_mapper.py:558-585)
```python
for std_col, config in self.standard_columns.items():  # Mê°œ
    for user_col in df.columns:  # Nê°œ
        for alias in config['names']:  # ~10ê°œ
            score = self.calculate_similarity(user_col, alias)
```

**ë³µì¡ë„:**
- ì‹œê°„ ë³µì¡ë„: **O(N Ã— M Ã— 10)**
- 100ê°œ ì‚¬ìš©ì ì»¬ëŸ¼ Ã— 4ê°œ í‘œì¤€ ì»¬ëŸ¼ Ã— 10ê°œ ë³„ì¹­ = **4,000ë²ˆ ìœ ì‚¬ë„ ê³„ì‚°**

**ë¬¸ì œì :**
- FuzzyWuzzyëŠ” **Levenshtein ê±°ë¦¬ ê³„ì‚° (O(len1 Ã— len2))**
- ì»¬ëŸ¼ëª…ì´ ê¸¸ë©´ (í‰ê·  20ì) â†’ 4,000 Ã— 400 = **160ë§Œë²ˆ ë¬¸ì ë¹„êµ**

**í•´ê²° ë°©ì•ˆ:**
- ì»¬ëŸ¼ëª… ì •ê·œí™” ìºì‹± (normalize ê²°ê³¼ ì €ì¥)
- ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ ë©”ëª¨ì´ì œì´ì…˜
- ë³‘ë ¬ ì²˜ë¦¬ (ProcessPoolExecutor)

---

### 6. **ProgressTracker: ë¶ˆí•„ìš”í•œ time.sleep()** (progress_tracker.py:82-83)
```python
# ë”œë ˆì´ (ì‹œê°ì  íš¨ê³¼)
if self.delay > 0 and self.current_step < len(self.steps) - 1:
    time.sleep(self.delay)  # â† ê¸°ë³¸ 0.3ì´ˆ
```

**ë¬¸ì œì :**
- **ì‹¤ì œ ë¶„ì„ ì‹œê°„ì„ ì¸ìœ„ì ìœ¼ë¡œ ëŠ˜ë¦¼** (5ë‹¨ê³„ Ã— 0.3ì´ˆ = **1.5ì´ˆ ë‚­ë¹„**)
- ì‚¬ìš©ì ê²½í—˜ **ì˜¤íˆë ¤ ì €í•˜**
  - ë¶„ì„ì´ 1ì´ˆë©´ ëë‚˜ëŠ”ë° 2.5ì´ˆë¡œ ëŠë ¤ì§
- í”„ë¡œê·¸ë ˆìŠ¤ëŠ” **ì¦‰ê° ì—…ë°ì´íŠ¸**ê°€ ì¢‹ìŒ

**í•´ê²° ë°©ì•ˆ:**
- `delay=0.0`ìœ¼ë¡œ ê¸°ë³¸ê°’ ë³€ê²½
- UI í”„ë ˆì„ì›Œí¬ê°€ ìë™ìœ¼ë¡œ ì• ë‹ˆë©”ì´ì…˜ ì²˜ë¦¬
- ë¶ˆí•„ìš”í•œ ì¸ìœ„ì  ë”œë ˆì´ ì œê±°

---

## ğŸ’¡ ì½”ë“œ í’ˆì§ˆ ì´ìŠˆ (Code Quality Issues)

### 7. **ColumnMapper: Magic Number ê³¼ë‹¤** (column_mapper.py:20-38)
```python
MIN_SIMILARITY_THRESHOLD = 50  # â† ì™œ 50ì¸ê°€?
ID_UNIQUE_RATIO_THRESHOLD = 0.9  # â† ì™œ 90%ì¸ê°€?
DATE_PARSE_RATIO_THRESHOLD = 0.7  # â† ì™œ 70%ì¸ê°€?
TEXT_LENGTH_LONG = 50
SCORE_HIGH = 90
SCORE_MEDIUM_HIGH = 80
```

**ë¬¸ì œì :**
- **ì„ê³„ê°’ ê·¼ê±° ë¶ˆëª…í™•** (ì™œ 50? ì™œ 0.9?)
- ì£¼ì„ì— **ì„¤ëª… ì—†ìŒ**
- A/B í…ŒìŠ¤íŠ¸ë‚˜ **ì‹¤í—˜ì  ê·¼ê±° ì—†ìŒ**

**ê°œì„  ë°©ì•ˆ:**
```python
# ì‹¤í—˜ ê²°ê³¼: 50ì  ë¯¸ë§Œì€ ì˜¤íƒë¥  35% (í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 100ê°œ ê¸°ì¤€)
MIN_SIMILARITY_THRESHOLD = 50
# íŒŒì¼ëŸ¿ ë°ì´í„°: ID ì»¬ëŸ¼ì˜ í‰ê·  ê³ ìœ ê°’ ë¹„ìœ¨ = 0.92
ID_UNIQUE_RATIO_THRESHOLD = 0.9
```

---

### 8. **GPTAnalyzer: ì—ëŸ¬ ë©”ì‹œì§€ ë¶ˆì¹œì ˆ** (gpt_analyzer.py:202-208)
```python
except (json.JSONDecodeError, KeyError) as e:
    logger.error(f"GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ (ë°°ì¹˜ {batch_num}/{total_batches}): {str(e)}")
    results.extend([{"sentiment": "neutral", "confidence": 0.5, "reason": "ë¶„ì„ ì‹¤íŒ¨"}] * len(batch))
```

**ë¬¸ì œì :**
- ì‚¬ìš©ìì—ê²Œ **"ë¶„ì„ ì‹¤íŒ¨"ë§Œ í‘œì‹œ** (ì›ì¸ ëª¨ë¦„)
- ë””ë²„ê¹… íŒíŠ¸ ì—†ìŒ
- **ì¬ì‹œë„ ì—¬ë¶€** ë¶ˆëª…í™•

**ê°œì„  ë°©ì•ˆ:**
```python
results.extend([{
    "sentiment": "neutral",
    "confidence": 0.5,
    "reason": f"GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ (ë°°ì¹˜ {batch_num})",
    "error_detail": str(e)[:100],  # ì—ëŸ¬ ì„¸ë¶€ì‚¬í•­
    "retry_suggested": True
}] * len(batch))
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë¶€ì¡± (Test Coverage Issues)

### 9. **ColumnMapper: ì—£ì§€ ì¼€ì´ìŠ¤ ë¯¸í…ŒìŠ¤íŠ¸**
```
âŒ í…ŒìŠ¤íŠ¸ë˜ì§€ ì•Šì€ ì¼€ì´ìŠ¤:
- ì»¬ëŸ¼ 1000ê°œ ì´ìƒ (ëŒ€ìš©ëŸ‰ ë°ì´í„°)
- ëª¨ë“  ì»¬ëŸ¼ ì´ë¦„ì´ ë™ì¼ (duplicate column names)
- ìœ ë‹ˆì½”ë“œ/ì´ëª¨ì§€ ì»¬ëŸ¼ëª… (ì˜ˆ: 'ê³ ê°â¤ï¸', 'å¹³å‡ä»·æ ¼')
- ì»¬ëŸ¼ëª… 100ì ì´ìƒ (ë§¤ìš° ê¸´ ì´ë¦„)
- ë¹ˆ DataFrame (0í–‰)
- íŠ¹ìˆ˜ ë¬¸ìë§Œ (ì˜ˆ: '!!!', '$$$')
```

**ìœ„í—˜ë„:**
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ **ì˜ˆìƒì¹˜ ëª»í•œ í¬ë˜ì‹œ** ê°€ëŠ¥

---

### 10. **GPTAnalyzer: ì‹¤ì œ API í…ŒìŠ¤íŠ¸ ì—†ìŒ**
```python
# test_day27_gpt_optimization.py
if not api_key:
    print("[SKIP] OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì—†ìŒ")
    return True  # â† ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ SKIPë¨!
```

**ë¬¸ì œì :**
- **ì‹¤ì œ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸ ì—†ìŒ**
- Rate Limit í•¸ë“¤ë§ **ê²€ì¦ ì•ˆ ë¨**
- Exponential backoff **ì‘ë™ ë¯¸í™•ì¸**

**í•´ê²° ë°©ì•ˆ:**
- Mock í…ŒìŠ¤íŠ¸ ì¶”ê°€ (`unittest.mock`)
- CI/CDì—ì„œ API í‚¤ë¡œ í†µí•© í…ŒìŠ¤íŠ¸

---

## ğŸ” ë³´ì•ˆ ì´ìŠˆ (Security Issues)

### 11. **GPTAnalyzer: API í‚¤ ë¡œê¹… ìœ„í—˜** (gpt_analyzer.py:44)
```python
if not self.api_key:
    raise ValueError("API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤...")
# â† API í‚¤ê°€ ë¡œê·¸ì— ë…¸ì¶œë  ìˆ˜ ìˆìŒ
```

**ë¬¸ì œì :**
- ë””ë²„ê¹… ëª¨ë“œì—ì„œ `logger.debug(f"API key: {self.api_key}")` ì‹¤ìˆ˜ ê°€ëŠ¥
- **ë¯¼ê° ì •ë³´ ë…¸ì¶œ ìœ„í—˜**

**í•´ê²° ë°©ì•ˆ:**
```python
# API í‚¤ ë§ˆìŠ¤í‚¹
masked_key = f"{self.api_key[:8]}...{self.api_key[-4:]}"
logger.info(f"Initialized with key: {masked_key}")
```

---

## ğŸ“Š ìš”ì•½

| êµ¬ë¶„ | ê°œìˆ˜ | ìš°ì„ ìˆœìœ„ |
|------|------|----------|
| ì¹˜ëª…ì  ë¬¸ì œ | 2 | P0 (ì¦‰ì‹œ ìˆ˜ì •) |
| ì‹¬ê°í•œ ë²„ê·¸ | 2 | P1 (ê³§ ìˆ˜ì •) |
| ì„±ëŠ¥ ë¬¸ì œ | 2 | P2 (ìµœì í™” í•„ìš”) |
| ì½”ë“œ í’ˆì§ˆ | 2 | P3 (ë¦¬íŒ©í† ë§) |
| í…ŒìŠ¤íŠ¸ ë¶€ì¡± | 2 | P3 (ê°œì„  ê¶Œì¥) |
| ë³´ì•ˆ ì´ìŠˆ | 1 | P1 (ê³§ ìˆ˜ì •) |
| **ì´ê³„** | **11ê°œ** | |

---

## âœ… ì˜í•œ ì 

1. âœ… **Exponential backoff êµ¬í˜„** (í‘œì¤€ íŒ¨í„´)
2. âœ… **ì¤‘ë³µ ë§¤í•‘ ë°©ì§€** (alternatives ì¶”ì )
3. âœ… **ë¡œê¹… ì¶”ê°€** (ë””ë²„ê¹… ìš©ì´)
4. âœ… **í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì‹œìŠ¤í…œ** (ì»¬ëŸ¼ëª… 60% + ë°ì´í„° 40%)
5. âœ… **ë¹„ìš© ì¶”ì  ê¸°ëŠ¥** (í† í°, ê¸ˆì•¡ ê³„ì‚°)
6. âœ… **ë‚ ì§œ íŒŒì‹± ìµœì í™”** (dateutil â†’ pd.to_datetime)

---

## ğŸ¯ ê°œì„  ìš°ì„ ìˆœìœ„

### P0 (ì¦‰ì‹œ ìˆ˜ì • í•„ìš”) - âœ… ì™„ë£Œ
1. âœ… **filter_negative íŒŒë¼ë¯¸í„° ë¯¸ì‚¬ìš© ìˆ˜ì •** â†’ ì‹¤ì œ í•„í„°ë§ êµ¬í˜„
   - `analyze_sentiment_batch`ì— `df`, `rating_column`, `text_column` íŒŒë¼ë¯¸í„° ì¶”ê°€
   - `filter_negative=True`ì¼ ë•Œ `_filter_negative_reviews()` í˜¸ì¶œ
   - ë¡œê¹… ì¶”ê°€: "ë¶€ì • ë¦¬ë·° í•„í„°ë§ ì™„ë£Œ: Xê°œ"

2. âœ… **ëŒ€ìš©ëŸ‰ ì»¬ëŸ¼ ì²˜ë¦¬ ìµœì í™”** â†’ ì§„í–‰ë°” ë˜ëŠ” ì œí•œ
   - `hybrid_map_columns`ì— `max_columns=200` íŒŒë¼ë¯¸í„° ì¶”ê°€
   - 200ê°œ ì´ˆê³¼ ì‹œ ê²½ê³  ë¡œê·¸ ì¶œë ¥
   - ì„±ëŠ¥ ë³´í˜¸ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„

### P1 (ë‹¤ìŒ ë²„ì „ì—ì„œ ìˆ˜ì •) - âœ… ì™„ë£Œ
3. âœ… **ë¹„ìš© ê³„ì‚° ëª¨ë¸ë³„ ë™ê¸°í™”** â†’ PRICING ë”•ì…”ë„ˆë¦¬
   - `PRICING` í´ë˜ìŠ¤ ë³€ìˆ˜ ì¶”ê°€ (5ê°œ ëª¨ë¸ ì§€ì›)
   - `__init__`ì—ì„œ ëª¨ë¸ë³„ ê°€ê²© ì„¤ì • (`self.input_price`, `self.output_price`)
   - ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ì€ gpt-4o-mini ê°€ê²©ìœ¼ë¡œ fallback
   - ë¡œê¹…: "Model: {model} ($X/M input, $Y/M output)"

4. âœ… **íƒ€ì… ìš°ì„ ìˆœìœ„ ì¶©ëŒ ìˆ˜ì •** â†’ ë‚ ì§œì´ë©´ì„œ IDì¼ ìˆ˜ ìˆìŒ
   - ë‚ ì§œ íƒ€ì… ì¡°ê¸° ë°˜í™˜ ì œê±°
   - `is_id=True`ì´ë©´ ID ì ìˆ˜ 30ì  ë¶€ì—¬ (0ì´ ì•„ë‹˜)
   - ìœ ì—°ì„± í™•ë³´: ë‚ ì§œ(90ì ) + ID(30ì ) ëª¨ë‘ ê°€ëŠ¥

### P2 (ì„±ëŠ¥ ê°œì„ )
5. **ìœ ì‚¬ë„ ê³„ì‚° ìºì‹±** â†’ ë©”ëª¨ì´ì œì´ì…˜
6. **time.sleep() ì œê±°** â†’ delay=0.0

### P3 (ì½”ë“œ í’ˆì§ˆ)
7. **Magic Number ì£¼ì„ ì¶”ê°€** â†’ ê·¼ê±° ëª…ì‹œ
8. **ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì¶”ê°€** â†’ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 90% ì´ìƒ
