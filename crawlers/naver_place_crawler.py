"""
Naver Place Review Crawler
ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python naver_place_crawler.py --place-id 1234567890 --count 100 --output reviews.csv
"""

import argparse
import time
import random
import pandas as pd
import undetected_chromedriver as uc
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime
from tqdm import tqdm
from pathlib import Path


class NaverPlaceCrawler:
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° í¬ë¡¤ëŸ¬"""

    def __init__(self, headless: bool = True, delay: float = 1.0):
        """
        Args:
            headless: ë¸Œë¼ìš°ì €ë¥¼ ë³´ì´ì§€ ì•Šê²Œ ì‹¤í–‰
            delay: ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)
        """
        self.delay = delay
        self.reviews = []

        # Chrome ì˜µì…˜ ì„¤ì • (undetected_chromedriverìš©)
        options = uc.ChromeOptions()
        if headless:
            options.add_argument('--headless=new')  # ìƒˆë¡œìš´ headless ëª¨ë“œ
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--disable-blink-features=AutomationControlled')

        # WebDriver ì´ˆê¸°í™” (undetected_chromedriver ì‚¬ìš©)
        self.driver = uc.Chrome(options=options, version_main=None)
        self.wait = WebDriverWait(self.driver, 15)  # ëŒ€ê¸° ì‹œê°„ ì¦ê°€

    def crawl_reviews(self, place_id: str, max_reviews: int = 100) -> pd.DataFrame:
        """
        í”Œë ˆì´ìŠ¤ ë¦¬ë·° í¬ë¡¤ë§

        Args:
            place_id: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ID
            max_reviews: ìˆ˜ì§‘í•  ìµœëŒ€ ë¦¬ë·° ìˆ˜

        Returns:
            pd.DataFrame: ë¦¬ë·° ë°ì´í„°í”„ë ˆì„
        """
        # ì—¬ëŸ¬ URL íŒ¨í„´ ì‹œë„
        urls = [
            f"https://m.place.naver.com/restaurant/{place_id}/review/visitor",
            f"https://m.place.naver.com/place/{place_id}/review/visitor",
            f"https://pcmap.place.naver.com/restaurant/{place_id}/review/visitor",
        ]

        print(f"ğŸª í”Œë ˆì´ìŠ¤ ID {place_id}ì˜ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘...")
        print(f"ëª©í‘œ: {max_reviews}ê°œ ë¦¬ë·° ìˆ˜ì§‘")

        success = False
        for url in urls:
            print(f"\nì‹œë„ ì¤‘: {url}")
            try:
                self.driver.get(url)
                print("â³ í˜ì´ì§€ ë¡œë”© ì¤‘...")
                # ëœë¤ ëŒ€ê¸° (10-15ì´ˆ) - ì‚¬ëŒì²˜ëŸ¼ ë³´ì´ê¸°
                wait_time = random.uniform(10, 15)
                time.sleep(wait_time)

                # ë¦¬ë·° íƒ­ í™•ì¸
                print("ğŸ“„ í˜ì´ì§€ ë¡œë”© ì™„ë£Œ")
                print(f"í˜„ì¬ URL: {self.driver.current_url}")
                print(f"í˜ì´ì§€ ì œëª©: {self.driver.title}")

                # iframe í™•ì¸ ë° ì „í™˜
                try:
                    iframes = self.driver.find_elements(By.TAG_NAME, 'iframe')
                    if iframes:
                        print(f"ğŸ” {len(iframes)}ê°œì˜ iframe ë°œê²¬, ì²« ë²ˆì§¸ iframeìœ¼ë¡œ ì „í™˜ ì‹œë„...")
                        self.driver.switch_to.frame(iframes[0])
                        print("âœ… iframeìœ¼ë¡œ ì „í™˜ ì™„ë£Œ")
                        time.sleep(2)
                except Exception as e:
                    print(f"â„¹ï¸ iframe ì—†ìŒ ë˜ëŠ” ì „í™˜ ë¶ˆí•„ìš”: {str(e)}")

                # ë¦¬ë·° ìš”ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸
                test_elements = self.driver.find_elements(By.CSS_SELECTOR, 'li, div, span')
                if test_elements:
                    print(f"âœ… í˜ì´ì§€ì— {len(test_elements)}ê°œì˜ ìš”ì†Œ ë°œê²¬")

                    # ë””ë²„ê¹…ìš© ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    try:
                        screenshot_path = Path(__file__).parent / 'output' / f'debug_screenshot_{place_id}.png'
                        screenshot_path.parent.mkdir(exist_ok=True)
                        self.driver.save_screenshot(str(screenshot_path))
                        print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
                    except:
                        pass

                    success = True
                    break
                else:
                    print("âš ï¸ í˜ì´ì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒ URL ì‹œë„...")
                    self.driver.switch_to.default_content()
            except Exception as e:
                print(f"âŒ URL ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                continue

        if not success:
            print("\nâŒ ëª¨ë“  URL ì‹œë„ ì‹¤íŒ¨")
            # ìµœì¢… ìŠ¤í¬ë¦°ìƒ· ì €ì¥
            try:
                screenshot_path = Path(__file__).parent / 'output' / f'debug_failed_{place_id}.png'
                screenshot_path.parent.mkdir(exist_ok=True)
                self.driver.save_screenshot(str(screenshot_path))
                print(f"ğŸ“¸ ì‹¤íŒ¨ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
            except:
                pass
            return pd.DataFrame()

        try:
            # ìŠ¤í¬ë¡¤í•˜ë©° ë¦¬ë·° ìˆ˜ì§‘
            pbar = tqdm(total=max_reviews, desc="ë¦¬ë·° ìˆ˜ì§‘ ì¤‘")
            last_review_count = 0
            no_change_count = 0

            while len(self.reviews) < max_reviews:
                # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ë¦¬ë·° íŒŒì‹±
                self._parse_reviews()

                current_count = len(self.reviews)
                pbar.n = min(current_count, max_reviews)
                pbar.refresh()

                # ë” ì´ìƒ ìƒˆë¡œìš´ ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if current_count == last_review_count:
                    no_change_count += 1
                    if no_change_count >= 3:
                        print(f"\në” ì´ìƒ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ {current_count}ê°œ)")
                        break
                else:
                    no_change_count = 0

                last_review_count = current_count

                if current_count >= max_reviews:
                    break

                # ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í¬ë¡¤ (ë‹¨ê³„ì ìœ¼ë¡œ)
                scroll_pause = random.uniform(0.5, 1.5)
                for i in range(3):  # 3ë‹¨ê³„ë¡œ ë‚˜ëˆ ì„œ ìŠ¤í¬ë¡¤
                    scroll_position = (i + 1) * (self.driver.execute_script("return document.body.scrollHeight") // 3)
                    self.driver.execute_script(f"window.scrollTo(0, {scroll_position});")
                    time.sleep(scroll_pause)

                print("ğŸ’¤ ìŠ¤í¬ë¡¤ í›„ ëŒ€ê¸° ì¤‘...")
                time.sleep(random.uniform(3, 6))  # 3-6ì´ˆ ëœë¤ ëŒ€ê¸°

                # "ë”ë³´ê¸°" ë²„íŠ¼ í´ë¦­ ì‹œë„
                try:
                    more_button = self.driver.find_element(By.CSS_SELECTOR,
                        'a.fvwqf, button.fvwqf, a[class*="more"], button[class*="more"]')
                    if more_button.is_displayed():
                        more_button.click()
                        print("ğŸ’¤ ë”ë³´ê¸° í´ë¦­ í›„ ëŒ€ê¸° ì¤‘...")
                        time.sleep(random.uniform(2, 4))  # 2-4ì´ˆ ëœë¤
                except:
                    pass

            pbar.close()

            # ì¤‘ë³µ ì œê±° (ë¦¬ë·° í…ìŠ¤íŠ¸ ê¸°ì¤€)
            df = pd.DataFrame(self.reviews)
            if len(df) > 0:
                df = df.drop_duplicates(subset=['review'], keep='first')
                df = df.head(max_reviews)  # ìµœëŒ€ ê°œìˆ˜ë§Œí¼ë§Œ
                print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
                return df
            else:
                print("\nâš ï¸ ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()

        except Exception as e:
            print(f"\nâŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}")
            if self.reviews:
                df = pd.DataFrame(self.reviews)
                df = df.drop_duplicates(subset=['review'], keep='first')
                print(f"âš ï¸ ë¶€ë¶„ ìˆ˜ì§‘: {len(df)}ê°œ ë¦¬ë·°")
                return df
            return pd.DataFrame()

    def _parse_reviews(self):
        """í˜„ì¬ í˜ì´ì§€ì˜ ë¦¬ë·° íŒŒì‹±"""
        try:
            # ë‹¤ì–‘í•œ CSS ì„ íƒì ì‹œë„
            review_selectors = [
                'li.pui__X35jYm',  # ìµœì‹  êµ¬ì¡°
                'li[class*="review"]',
                'div.review_li',
                'li.YeINN',
                'div.place_section_content ul li',  # ì¶”ê°€ ì„ íƒì
                'li[data-review-id]',  # ì¶”ê°€ ì„ íƒì
            ]

            review_elements = []
            for selector in review_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements:
                        print(f"âœ… '{selector}' ì„ íƒìë¡œ {len(elements)}ê°œ ìš”ì†Œ ë°œê²¬")
                        review_elements = elements
                        break
                    else:
                        print(f"âš ï¸ '{selector}' ì„ íƒìë¡œ ìš”ì†Œ ì—†ìŒ")
                except Exception as e:
                    print(f"âŒ '{selector}' ì„ íƒì ì˜¤ë¥˜: {str(e)}")
                    continue

            if not review_elements:
                print("âŒ ë¦¬ë·° ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤...")
                # í˜ì´ì§€ ì†ŒìŠ¤ ì¼ë¶€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                page_source_sample = self.driver.page_source[:500]
                print(f"í˜ì´ì§€ ì†ŒìŠ¤ ìƒ˜í”Œ: {page_source_sample}")
                return

            parsed_count = 0
            for element in review_elements:
                try:
                    # ì´ë¯¸ ìˆ˜ì§‘í•œ ë¦¬ë·°ì¸ì§€ í™•ì¸ (í…ìŠ¤íŠ¸ë¡œ ì²´í¬)
                    review_text = self._extract_text(element)

                    if not review_text:
                        continue

                    if any(r['review'] == review_text for r in self.reviews):
                        continue

                    # í‰ì  ì¶”ì¶œ
                    rating = self._extract_rating(element)

                    # ì‘ì„±ì
                    author = self._extract_author(element)

                    # ì‘ì„±ì¼
                    date = self._extract_date(element)

                    # ë°©ë¬¸ í˜•íƒœ (ì„ íƒ)
                    visit_type = self._extract_visit_type(element)

                    self.reviews.append({
                        'place_id': None,  # ë‚˜ì¤‘ì— ì¶”ê°€
                        'author': author,
                        'rating': rating,
                        'review': review_text,
                        'date': date,
                        'visit_type': visit_type,
                        'crawled_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    })
                    parsed_count += 1

                except Exception as e:
                    print(f"âš ï¸ ë¦¬ë·° íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                    continue

            if parsed_count > 0:
                print(f"âœ… {parsed_count}ê°œ ìƒˆë¡œìš´ ë¦¬ë·° íŒŒì‹± ì™„ë£Œ")

        except Exception as e:
            pass

    def _extract_text(self, element) -> str:
        """ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        selectors = [
            'span.pui__xtsQN-',  # ìµœì‹ 
            'div.pui__vn15t2',
            'span[class*="review"]',
            'div.review_text',
            'span.zPfVt',
            'a.pui__xtsQN-',  # "ë”ë³´ê¸°" ë§í¬ ì•ˆì˜ í…ìŠ¤íŠ¸
            'div[class*="text"]',
        ]

        for selector in selectors:
            try:
                text_elem = element.find_element(By.CSS_SELECTOR, selector)
                text = text_elem.text.strip()
                if text and len(text) > 5:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    return text
            except:
                continue

        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
        try:
            text = element.text.strip()
            # ë¦¬ë·° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì§§ìœ¼ë©´ ì œì™¸)
            lines = text.split('\n')
            for line in lines:
                line = line.strip()
                if 10 <= len(line) <= 1000:  # ì ì ˆí•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸
                    return line
        except:
            pass

        return ""

    def _extract_rating(self, element) -> int:
        """í‰ì  ì¶”ì¶œ (1~5ì )"""
        selectors = [
            'div.pui__star-wrap span.pui__nR0cX6',  # ë³„ì  ê°œìˆ˜
            'em.pui__nR0cX6',
            'div[class*="star"]',
            'span.star',
        ]

        for selector in selectors:
            try:
                rating_elem = element.find_element(By.CSS_SELECTOR, selector)
                # aria-labelì—ì„œ ì¶”ì¶œ ì‹œë„
                aria_label = rating_elem.get_attribute('aria-label')
                if aria_label and '5' in aria_label:
                    # "5ì  ë§Œì ì— 4ì " ê°™ì€ í˜•ì‹
                    import re
                    match = re.search(r'(\d+)ì ', aria_label)
                    if match:
                        return int(match.group(1))

                # classì—ì„œ ì¶”ì¶œ ì‹œë„
                class_name = rating_elem.get_attribute('class')
                if 'star' in class_name:
                    # ë³„ ê°œìˆ˜ ì„¸ê¸°
                    stars = element.find_elements(By.CSS_SELECTOR, 'em.pui__nR0cX6')
                    if stars:
                        return len(stars)
            except:
                continue

        return 5  # ê¸°ë³¸ê°’

    def _extract_author(self, element) -> str:
        """ì‘ì„±ì ì¶”ì¶œ"""
        selectors = [
            'span.pui__gx7M46',
            'div.pui__-KNYym strong',
            'span[class*="author"]',
            'strong.reviewer',
        ]

        for selector in selectors:
            try:
                author_elem = element.find_element(By.CSS_SELECTOR, selector)
                author = author_elem.text.strip()
                if author:
                    return author
            except:
                continue

        return "ìµëª…"

    def _extract_date(self, element) -> str:
        """ì‘ì„±ì¼ ì¶”ì¶œ"""
        selectors = [
            'time.pui__9SOu_O',
            'span.pui__-KNYym time',
            'time',
            'span[class*="date"]',
        ]

        for selector in selectors:
            try:
                date_elem = element.find_element(By.CSS_SELECTOR, selector)
                date = date_elem.text.strip()
                if date:
                    return date
            except:
                continue

        return ""

    def _extract_visit_type(self, element) -> str:
        """ë°©ë¬¸ í˜•íƒœ ì¶”ì¶œ (ë°©ë¬¸/í¬ì¥/ë°°ë‹¬)"""
        try:
            # ë°©ë¬¸ í˜•íƒœ í‘œì‹œ ì°¾ê¸°
            badges = element.find_elements(By.CSS_SELECTOR, 'span.pui__badge, span[class*="badge"]')
            for badge in badges:
                text = badge.text.strip()
                if text in ['ë°©ë¬¸', 'í¬ì¥', 'ë°°ë‹¬']:
                    return text
        except:
            pass

        return "ë°©ë¬¸"  # ê¸°ë³¸ê°’

    def close(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° í¬ë¡¤ëŸ¬')
    parser.add_argument('--place-id', type=str, required=True, help='ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ID')
    parser.add_argument('--count', type=int, default=100, help='ìˆ˜ì§‘í•  ë¦¬ë·° ê°œìˆ˜ (ê¸°ë³¸: 100)')
    parser.add_argument('--output', type=str, default=None, help='ì¶œë ¥ CSV íŒŒì¼ëª…')
    parser.add_argument('--delay', type=float, default=1.0, help='ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)')
    parser.add_argument('--headless', action='store_true', help='í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰')

    args = parser.parse_args()

    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    if args.output is None:
        output_dir = Path(__file__).parent / 'output'
        output_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = output_dir / f'naver_place_{args.place_id}_{timestamp}.csv'
    else:
        output_file = args.output

    # í¬ë¡¤ë§ ì‹¤í–‰
    crawler = NaverPlaceCrawler(headless=args.headless, delay=args.delay)

    try:
        df = crawler.crawl_reviews(args.place_id, args.count)

        if len(df) > 0:
            # place_id ì¶”ê°€
            df['place_id'] = args.place_id

            # CSV ì €ì¥
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")

            # í†µê³„ ì¶œë ¥
            print("\nğŸ“Š ìˆ˜ì§‘ í†µê³„:")
            print(f"  - í‰ê·  í‰ì : {df['rating'].mean():.2f}")
            if 'rating' in df.columns:
                print(f"  - 5ì  ë¦¬ë·°: {len(df[df['rating'] == 5])}ê°œ ({len(df[df['rating'] == 5])/len(df)*100:.1f}%)")
                print(f"  - 1-2ì  ë¦¬ë·°: {len(df[df['rating'] <= 2])}ê°œ ({len(df[df['rating'] <= 2])/len(df)*100:.1f}%)")
        else:
            print("âš ï¸ ìˆ˜ì§‘ëœ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except KeyboardInterrupt:
        print("\n\nì¤‘ë‹¨ë¨. ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤...")
        if crawler.reviews:
            df = pd.DataFrame(crawler.reviews)
            df['place_id'] = args.place_id
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")

    finally:
        crawler.close()


if __name__ == "__main__":
    main()


# ì‚¬ìš© ì˜ˆì‹œ:
# python naver_place_crawler.py --place-id 1234567890 --count 200 --headless
