"""
Naver Movie Review Crawler
ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python naver_movie_crawler.py --movie-id 12345 --count 1000 --output reviews.csv
"""

import argparse
import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime
from tqdm import tqdm
from pathlib import Path


class NaverMovieCrawler:
    """ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° í¬ë¡¤ëŸ¬"""
    
    def __init__(self, headless: bool = True, delay: float = 1.0):
        """
        Args:
            headless: ë¸Œë¼ìš°ì €ë¥¼ ë³´ì´ì§€ ì•Šê²Œ ì‹¤í–‰
            delay: ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)
        """
        self.delay = delay
        self.reviews = []
        
        # Chrome ì˜µì…˜ ì„¤ì •
        chrome_options = Options()
        if headless:
            chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        # WebDriver ì´ˆê¸°í™”
        self.driver = webdriver.Chrome(
            service=Service(ChromeDriverManager().install()),
            options=chrome_options
        )
    
    def crawl_reviews(self, movie_id: str, max_reviews: int = 100) -> pd.DataFrame:
        """
        ì˜í™” ë¦¬ë·° í¬ë¡¤ë§
        
        Args:
            movie_id: ë„¤ì´ë²„ ì˜í™” ID
            max_reviews: ìˆ˜ì§‘í•  ìµœëŒ€ ë¦¬ë·° ìˆ˜
        
        Returns:
            pd.DataFrame: ë¦¬ë·° ë°ì´í„°í”„ë ˆì„
        """
        base_url = f"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code={movie_id}&type=after&page="
        
        print(f"ğŸ¬ ì˜í™” ID {movie_id}ì˜ ë¦¬ë·° í¬ë¡¤ë§ ì‹œì‘...")
        print(f"ëª©í‘œ: {max_reviews}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
        
        page = 1
        pbar = tqdm(total=max_reviews, desc="ë¦¬ë·° ìˆ˜ì§‘ ì¤‘")
        
        while len(self.reviews) < max_reviews:
            try:
                # í˜ì´ì§€ ë¡œë“œ
                url = base_url + str(page)
                self.driver.get(url)
                time.sleep(self.delay)
                
                # ë¦¬ë·° ìš”ì†Œ ì°¾ê¸°
                review_elements = self.driver.find_elements(By.CSS_SELECTOR, '.score_result li')
                
                if not review_elements:
                    print(f"\në” ì´ìƒ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤. (í˜ì´ì§€ {page})")
                    break
                
                # ê° ë¦¬ë·° íŒŒì‹±
                for element in review_elements:
                    if len(self.reviews) >= max_reviews:
                        break
                    
                    try:
                        # í‰ì 
                        score_elem = element.find_element(By.CSS_SELECTOR, '.star_score em')
                        score = int(score_elem.text)
                        
                        # ë¦¬ë·° í…ìŠ¤íŠ¸
                        review_elem = element.find_element(By.CSS_SELECTOR, '.score_reple p')
                        review_text = review_elem.text.strip()
                        
                        # ì‘ì„±ì
                        author_elem = element.find_element(By.CSS_SELECTOR, '.score_reple a')
                        author = author_elem.text.strip()
                        
                        # ì‘ì„±ì¼
                        date_elem = element.find_element(By.CSS_SELECTOR, '.score_reple em:nth-of-type(2)')
                        date = date_elem.text.strip()
                        
                        # ê³µê° ìˆ˜
                        like_elem = element.find_element(By.CSS_SELECTOR, '.sympathy_button')
                        like_text = like_elem.text.replace('ê³µê°', '').strip()
                        likes = int(like_text) if like_text else 0
                        
                        self.reviews.append({
                            'movie_id': movie_id,
                            'author': author,
                            'score': score,
                            'review': review_text,
                            'date': date,
                            'likes': likes,
                            'crawled_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        })
                        
                        pbar.update(1)

                    except (ValueError, AttributeError) as e:
                        # ê°œë³„ ë¦¬ë·° íŒŒì‹± ì‹¤íŒ¨ëŠ” ë¬´ì‹œ (ì˜ˆìƒ ê°€ëŠ¥í•œ ì—ëŸ¬ë§Œ)
                        continue
                    except Exception as e:
                        # ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ëŠ” ê²½ê³  ì¶œë ¥
                        import warnings
                        warnings.warn(f"ë¦¬ë·° íŒŒì‹± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)[:100]}")
                        continue
                
                page += 1
                
            except Exception as e:
                print(f"\nâš ï¸  í˜ì´ì§€ {page} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                break
        
        pbar.close()
        
        # DataFrame ë³€í™˜
        df = pd.DataFrame(self.reviews)
        print(f"\nâœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(df)}ê°œ ë¦¬ë·° ìˆ˜ì§‘")
        
        return df
    
    def close(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° í¬ë¡¤ëŸ¬')
    parser.add_argument('--movie-id', type=str, required=True, help='ë„¤ì´ë²„ ì˜í™” ID')
    parser.add_argument('--count', type=int, default=100, help='ìˆ˜ì§‘í•  ë¦¬ë·° ê°œìˆ˜ (ê¸°ë³¸: 100)')
    parser.add_argument('--output', type=str, default=None, help='ì¶œë ¥ CSV íŒŒì¼ëª…')
    parser.add_argument('--delay', type=float, default=1.0, help='ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)')
    parser.add_argument('--headless', action='store_true', help='í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    if args.output is None:
        output_dir = Path(__file__).parent / 'output'
        output_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = output_dir / f'naver_movie_{args.movie_id}_{timestamp}.csv'
    else:
        output_file = args.output
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    crawler = NaverMovieCrawler(headless=args.headless, delay=args.delay)
    
    try:
        df = crawler.crawl_reviews(args.movie_id, args.count)
        
        # CSV ì €ì¥
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")
        
        # í†µê³„ ì¶œë ¥
        print("\nğŸ“Š ìˆ˜ì§‘ í†µê³„:")
        print(f"  - í‰ê·  í‰ì : {df['score'].mean():.2f}")
        print(f"  - ê¸ì • ë¦¬ë·° (8ì  ì´ìƒ): {len(df[df['score'] >= 8])}ê°œ ({len(df[df['score'] >= 8])/len(df)*100:.1f}%)")
        print(f"  - ë¶€ì • ë¦¬ë·° (4ì  ì´í•˜): {len(df[df['score'] <= 4])}ê°œ ({len(df[df['score'] <= 4])/len(df)*100:.1f}%)")
    
    except KeyboardInterrupt:
        print("\n\nì¤‘ë‹¨ë¨. ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤...")
        if crawler.reviews:
            df = pd.DataFrame(crawler.reviews)
            df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    finally:
        crawler.close()


if __name__ == "__main__":
    main()


# ì‚¬ìš© ì˜ˆì‹œ:
# python naver_movie_crawler.py --movie-id 215095 --count 500 --headless
# (215095 = ë²”ì£„ë„ì‹œ4 ì˜í™” ID ì˜ˆì‹œ)
